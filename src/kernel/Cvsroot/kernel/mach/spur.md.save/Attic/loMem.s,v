head     8.8;
branch   ;
access   ;
symbols  symm:8.8 spur:8.8 newlib:8.0;
locks    ; strict;
comment  @# @;


8.8
date     89.11.27.10.33.01;  author jhh;  state Exp;
branches ;
next     8.7;

8.7
date     89.08.17.17.25.09;  author jhh;  state Exp;
branches ;
next     8.6;

8.6
date     89.06.19.14.01.10;  author jhh;  state Exp;
branches ;
next     8.5;

8.5
date     89.03.15.17.47.10;  author mendel;  state Exp;
branches ;
next     8.4;

8.4
date     89.01.11.09.51.31;  author mendel;  state Exp;
branches ;
next     8.3;

8.3
date     88.11.30.10.26.28;  author mendel;  state Exp;
branches ;
next     8.2;

8.2
date     88.11.15.13.41.39;  author dougj;  state Exp;
branches ;
next     8.1;

8.1
date     88.11.14.12.36.54;  author dougj;  state Exp;
branches ;
next     8.0;

8.0
date     88.11.11.18.05.14;  author douglis;  state Stable;
branches ;
next     1.43;

1.43
date     88.10.28.18.01.12;  author mendel;  state Exp;
branches ;
next     1.42;

1.42
date     88.10.20.09.19.31;  author mendel;  state Exp;
branches ;
next     1.41;

1.41
date     88.10.13.17.19.14;  author mendel;  state Exp;
branches ;
next     1.40;

1.40
date     88.10.05.08.39.14;  author mendel;  state Exp;
branches ;
next     1.39;

1.39
date     88.09.30.09.19.18;  author mendel;  state Exp;
branches ;
next     1.38;

1.38
date     88.09.16.15.24.41;  author dougj;  state Exp;
branches ;
next     1.37;

1.37
date     88.09.16.15.20.48;  author dougj;  state Exp;
branches ;
next     1.36;

1.36
date     88.09.16.15.16.21;  author mendel;  state Exp;
branches ;
next     1.35;

1.35
date     88.09.13.10.33.38;  author mendel;  state Exp;
branches ;
next     1.34;

1.34
date     88.09.12.09.40.25;  author mendel;  state Exp;
branches ;
next     1.33;

1.33
date     88.09.09.16.02.13;  author nelson;  state Exp;
branches ;
next     1.32;

1.32
date     88.09.07.15.08.02;  author mendel;  state Exp;
branches ;
next     1.31;

1.31
date     88.09.02.11.51.18;  author nelson;  state Exp;
branches ;
next     1.30;

1.30
date     88.08.27.14.25.36;  author nelson;  state Exp;
branches ;
next     1.29;

1.29
date     88.08.26.11.51.49;  author nelson;  state Exp;
branches ;
next     1.28;

1.28
date     88.08.23.10.18.41;  author mendel;  state Exp;
branches ;
next     1.27;

1.27
date     88.08.21.14.50.06;  author mendel;  state Exp;
branches ;
next     1.26;

1.26
date     88.08.21.14.37.26;  author nelson;  state Exp;
branches ;
next     1.25;

1.25
date     88.08.18.18.42.16;  author nelson;  state Exp;
branches ;
next     1.24;

1.24
date     88.08.17.12.00.11;  author nelson;  state Exp;
branches ;
next     1.23;

1.23
date     88.08.10.13.27.10;  author nelson;  state Exp;
branches ;
next     1.22;

1.22
date     88.08.09.18.38.01;  author nelson;  state Exp;
branches ;
next     1.21;

1.21
date     88.08.01.15.05.58;  author mendel;  state Exp;
branches ;
next     1.20;

1.20
date     88.07.31.22.37.15;  author mendel;  state Exp;
branches ;
next     1.19;

1.19
date     88.07.29.11.25.06;  author nelson;  state Exp;
branches ;
next     1.18;

1.18
date     88.07.23.12.49.58;  author nelson;  state Exp;
branches ;
next     1.17;

1.17
date     88.07.20.18.29.10;  author nelson;  state Exp;
branches ;
next     1.16;

1.16
date     88.07.19.17.08.46;  author nelson;  state Exp;
branches ;
next     1.15;

1.15
date     88.07.16.15.39.01;  author nelson;  state Exp;
branches ;
next     1.14;

1.14
date     88.07.15.12.25.44;  author nelson;  state Exp;
branches ;
next     1.13;

1.13
date     88.07.15.11.31.08;  author nelson;  state Exp;
branches ;
next     1.12;

1.12
date     88.07.07.16.01.46;  author nelson;  state Exp;
branches ;
next     1.11;

1.11
date     88.07.05.15.09.37;  author nelson;  state Exp;
branches ;
next     1.10;

1.10
date     88.06.30.15.31.42;  author nelson;  state Exp;
branches ;
next     1.9;

1.9
date     88.06.14.09.56.16;  author nelson;  state Exp;
branches ;
next     1.8;

1.8
date     88.06.11.17.50.56;  author nelson;  state Exp;
branches ;
next     1.7;

1.7
date     88.06.09.10.18.08;  author nelson;  state Exp;
branches ;
next     1.6;

1.6
date     88.06.07.21.05.12;  author nelson;  state Exp;
branches ;
next     1.5;

1.5
date     88.06.03.10.57.04;  author nelson;  state Exp;
branches ;
next     1.4;

1.4
date     88.05.25.23.11.07;  author nelson;  state Exp;
branches ;
next     1.3;

1.3
date     88.05.25.23.02.41;  author nelson;  state Exp;
branches ;
next     1.2;

1.2
date     88.05.24.22.54.41;  author nelson;  state Exp;
branches ;
next     1.1;

1.1
date     88.05.23.22.48.42;  author nelson;  state Exp;
branches ;
next     ;


desc
@@


8.8
log
@Multiple changes over a couple of months
@
text
@/* loMem.s --
 *
 *	The first thing that is loaded into the kernel.  Handles traps,
 *	faults, errors and interrupts.
 *
 * Copyright (C) 1985 Regents of the University of California
 * All rights reserved.
 *
 * rcs = $Header: /sprite/src/kernel/mach/spur.md/RCS/loMem.s,v 8.7 89/08/17 17:25:09 jhh Exp $ SPRITE (Berkeley)
 */

#include "reg.h"
#include "machConst.h"
#include "machAsmDefs.h"

/*
 * SAVED WINDOW STACK CONVENTIONS
 *
 * When user processes trap into the kernel the kernel saves all of the
 * user registers and then switches to its own window stack.  The only
 * exception is in the underflow and overflow routines which have to
 * use the user's stack since it is still in user mode.  The act of saving
 * the user's registers requires that the user's saved window stack always
 * has enough space left on the saved window stack to save the remaining
 * windows in the users register stack.  If when the kernel is trying to save
 * state or handle overflow or underflow faults the user's SWP is bogus
 * then the kernel switches over to the kernel's saved window stack and the
 * user process is killed.  If the SWP is bogus when an interrupt occurs, then
 * the user process is not killed until after the interrupt is handled.  All
 * memory between min_swp_offset and max_swp_offset is wired down.
 *
 * The swp is considered valid if it obeys the constraint
 *
 *	min_wired_addr <= swp <= max_wired_addr - 8 * saved_window_size
 *
 * In order to keep things simple more space is allocated only by the window 
 * underflow and overflow routines.  However, when a user process traps into
 * the kernel windows can be saved on its window stack when the switch is
 * made from the user to the kernel stack.  In order to ensure that the
 * constraints are always upheld there needs to be slop at the high end.  
 * Thus, more space is allocated by the window overflow handler if after an
 * overflow
 *
 * 	swp >= max_wired_addr - 16 * saved_window_size
 *
 * This ensures that an entire bank of windows can be saved because of
 * miscellaneous kernel calls between calls to the window overflow handler
 * yet the valid condition will still be held.
 *
 * There also needs to be slop at the low end in order to handle returns
 * from signal handlers.  The act of returning from a signal handler will
 * cause a window underflow off of the user stack.  Since it doesn't allocate
 * more space until an underflow occurs in user mode (we can't do it in kernel
 * mode because it could cause deadlock) one window of slop is required.
 * Thus more space is allocated by the window underflow handler if after
 * an underflow
 *
 *	swp == min_wired_addr + 1.
 *
 * Of course the other option would be to check the bounds of the window
 * stack whenever we put stuff on or take stuff off but by putting slop
 * at the low and high ends we only have to check in the overflow and
 * underflow handlers.
 *
 * SPILL STACK CONVENTIONS
 *
 * When user processes trap into the kernel the kernel switches over
 * to its own spill stack before doing any C calls.  A separate stack is
 * used instead of the user stack because it is real easy to manage 
 * separate spill stacks and we have no idea if the user spill stack is
 * good or not.
 *
 * SWITCHING TO KERNEL MODE
 *
 * Certain traps (eg. window overflow traps) occur in user mode.  If for
 * some reason kernel mode needs to be entered (an error or need to allocate
 * more window memory) then a gross sequence has to be undertaken.  We
 * want to switch to kernel mode but we can't modify the kpsw because we
 * are in user mode.  The only way to get to kernel mode is to do a return from
 * trap and then immediately do a compare trap to get back in.  After these
 * two instructions we are back in the window that we were in when we wanted
 * to switch to kernel mode.  Unfortunately the compare trap will trash
 * CUR_PC_REG and NEXT_PC_REG which tell us where to continue when we
 * truly return to the user process.  Thus CUR_PC_REG and NEXT_PC_REG 
 * have to be saved in the window before the return_trap-cmp_trap sequence.  
 * Now the act of returning from the trap means that interrupts are enabled.   
 * Therefore I need to save CUR_PC_REG and NEXT_PC_REG in a place where 
 * they won't get trashed if an interrupt comes in.  The place to put them 
 * is in NON_INTR_TEMP1 through NON_INTR_TEMP3 because these are left 
 * untouched by the interrupt handling code.
 *
 * SAVING THE INSERT REGISTER
 *
 * All of these trap handlers try to be transparent to the process that 
 * caused the trapped.  This means that all global variables are saved
 * and restored when they are modified.  One of these globals is the insert
 * register.  Since the insert register may be used by C routines that are
 * called and is used by ParseInstruction, it is saved and restored to/from
 * local registers before and after calls to these routines.  It can't
 * be saved to global memory because traps can be nested.
 */

/*
 * Temporary local registers. 
 */
	.set rt1, 17
	.set rt2, 18
	.set rt3, 19
	.set rt4, 20
	.set rt5, 21
	.set rt6, 22
	.set rt7, 23
	.set rt8, 24
	.set rt9, 25

/*
 * Defining starting KPSW for processors.
 */
#ifdef WITH_IBUFFER
#ifdef WITH_PREFETCH	/* WITH_IBUFFER and WITH_PREFETCH */
#define	DEFAULT_KPSW   (MACH_KPSW_PREFETCH_ENA | MACH_KPSW_IBUFFER_ENA | \
			MACH_KPSW_VIRT_DFETCH_ENA|MACH_KPSW_VIRT_IFETCH_ENA |\
			MACH_KPSW_FAULT_TRAP_ENA | MACH_KPSW_ERROR_TRAP_ENA |\
			MACH_KPSW_ALL_TRAPS_ENA)
#else	/* WITH_IBUFFER but no WITH_PREFETCH */
#define	DEFAULT_KPSW	(MACH_KPSW_IBUFFER_ENA | MACH_KPSW_VIRT_DFETCH_ENA | \				MACH_KPSW_VIRT_IFETCH_ENA | MACH_KPSW_FAULT_TRAP_ENA |\
			MACH_KPSW_ERROR_TRAP_ENA | MACH_KPSW_ALL_TRAPS_ENA)
#endif
#else	/* no WITH_IBUFFER */
#define	DEFAULT_KPSW	(MACH_KPSW_VIRT_DFETCH_ENA|MACH_KPSW_VIRT_IFETCH_ENA|\
			MACH_KPSW_FAULT_TRAP_ENA | MACH_KPSW_ERROR_TRAP_ENA |\
			MACH_KPSW_ALL_TRAPS_ENA)
#endif

/*
 * C structures and routines that are called from here.
 */
	.globl _proc_RunningProcesses
	.globl _machCurStatePtrs
	.globl _machStatePtrOffset
	.globl _machSpecialHandlingOffset
	.globl _machMaxSysCall
	.globl _machKcallTableOffset
	.globl _machNumArgs
	.globl _machDebugState
	.globl _MachInterrupt
	.globl _MachUserError
	.globl _MachVMPCFault 
	.globl _MachVMDataFault 
	.globl _MachSigReturn
	.globl _MachGetWinMem
	.globl _MachUserAction
	.globl _machNonmaskableIntrMask
	.globl _machIntrMask 
	.globl _machDbgInterruptMask
	.globl _machTrapTableOffset
	.globl _machInterruptAddr
	.globl _machDebugStatePtrs
	.globl _machMapSlotIdToPnum
	.globl _machMasterProcessor
	.globl _machFirstProcState
	.globl _machRefreshCount
	.globl _machLEDValues
	.globl _machIdleCountPtr
/*
 * The KPSW value to set and 
/*
 * Trap table.  The hardware jumps to virtual 0x1000 when any type of trap
 * occurs.
 */
	.org 0x1000
	jump PowerUp		/* Reset - Jump to powerup sequencer. */
	Nop

	.org 0x1010
	jump ErrorTrap		/* Error */
	Nop

	.org 0x1020
	jump WinOvFlow		/* Window overflow */
	invalidate_ib

	.org 0x1030
	jump WinUnFlow		/* Window underflow */
	invalidate_ib

	.org 0x1040
	jump FaultIntr		/* Fault or interrupt */
	invalidate_ib

	.org 0x1050
	jump FPUExcept		/* FPU Exception */
	Nop

	.org 0x1060
	jump Illegal		/* Illegal op, kernel mode access violation */
	Nop

	.org 0x1070
	jump Fixnum		/* Fixnum, fixnum_or_char, generation */
	Nop

	.org 0x1080
	jump Overflow		/* Integer overflow */
	Nop

	.org 0x1090
	jump CmpTrap		/* Compare trap instruction */
	invalidate_ib


	.org 0x1100
	/*
	 * This entry needs to be at the same place in 
	 * both the physical and virtual space.  If it's moved
	 * here, it needs to move in loMem.s as well.
	 */
        .globl _debugger_active_address
_debugger_active_address:

/*
 ****************************************************************************
 *
 * BEGIN: SPECIAL LOW MEMORY OBJECTS
 *
 * Objects that need to be accessed with immediate fields have to be stored
 * between 0x1000 and 0x2000 because there are only 13 useable bits
 * (the 14th bit is a sign bit).
 *
 ****************************************************************************
 */
/*
 * Store addresses of things that need to be loaded into registers through
 * the use of immediate constants.  For example if we want to get a hold
 * of what _machCurStatePtrs points to we can't do it normally by the 
 * instruction
 *
 * 	ld_32	rt1, r0, $_machCurStatePtrs
 *
 * because the address of _machCurStatePtr will be longer than 13 bits.  
 * However if we put _machCurStatePtr in low memory then we can get to
 * it directly.
 *
 * Other options are LD_PC_RELATIVE or LD_CONSTANT.
 */
/*
 * The following data structures are index by processor number.  Currently
 * only room for 8 processors is defined.
 *
 * _machCurStatePtrs - Pointers to the Mach_State structure of the process
 * running on each processor.
 */
_machCurStatePtrs: 		.long 0; .long 0; .long 0; .long 0
				.long 0; .long 0; .long 0; .long 0
/*
 * Pointers to the state save upon entry to the debugger for each processor.
 */

_machDebugStatePtrs:		.long _machDebugState; .long 0; .long 0; .long 0
				.long 0; .long 0; .long 0; .long 0
/*
 * Pointers to the debugger's save window stack. Since there's only one 
 * debugger we need only one stack.
 */
debugSWStackBasePtr:	.long MACH_DEBUG_STACK_BOTTOM
/*
 * Pointers to the end of the debugger's spill stack.
 */
debugSpillStackEndPtr:	.long (MACH_DEBUG_STACK_BOTTOM +MACH_SPECIAL_STACK_SIZE)
/*
 * _machMapSlotToPnum is index by slot ID and performs the mapping of 
 * slot ids into processor numbers.
 */
_machMapSlotIdToPnum: 		.long 0; .long 0; .long 0; .long 0;
				.long 0; .long 0; .long 0; .long 0;
				.long 0; .long 0; .long 0; .long 0;
				.long 0; .long 0; .long 0; .long 0;
refreshCountLeds:		.long 0x1000; .long 0x7000; .long 0x1000;
				.long 0x7000
idleCountLeds:			.long 0xe00; .long 0xd00; .long 0xb00; 
				.long 0x700; .long 0xb00; .long 0xd00;
				.long 0xe00; .long 0xf00
ledAddrs:			.long 0x20000
runningProcesses: 		.long _proc_RunningProcesses
firstProcStatePtr:		.long _machFirstProcState
numArgsPtr:			.long _machNumArgs
_machStatePtrOffset:		.long 0
_machSpecialHandlingOffset:	.long 0
_machMaxSysCall	:		.long 0
_machKcallTableOffset:		.long 0
_machTrapTableOffset:		.long 0
_machDbgInterruptMask:		.long 0
_machIntrMask:			.long 0
_machNonmaskableIntrMask:	.long 0
_machMasterProcessor:		.long 0
_machRefreshTimerValue:		.long -40000
_machRefreshIntrMask:		.long MACH_TIMER_T2_INTR
feStatusReg:			.long 0
_machInterruptAddr:		.long 0
_machIdleCountPtr:		.long 0; .long 0; .long 0; .long 0;
				.long 0; .long 0; .long 0; .long 0
_machLEDValues:			.long 0; .long 0; .long 0; .long 0;
				.long 0; .long 0; .long 0; .long 0
_machRefreshCount:		.long 0; .long 0; .long 0; .long 0;
				.long 0; .long 0; .long 0; .long 0
_machDebugSlave:		.long 0
_machTimerIntrMask:		.long MACH_TIMER_T1_INTR

/*
 * The instruction to execute on return from a signal handler.  Is here
 * because the value is loaded into a register and it is quicker if
 * is done as an immediate.
 */
SigReturnAddr:
	cmp_trap	always, r0, r0, $MACH_SIG_RETURN_TRAP	
	Nop

/*
 * Jump table to return the operands from an instruction.  Also here
 * because is jumped to through an immediate constant.
 */
OpRecov:
	add_nt		r31,  r0, $0
	add_nt		r31,  r1, $0
	add_nt		r31,  r2, $0
	add_nt		r31,  r3, $0
	add_nt		r31,  r4, $0
	add_nt		r31,  r5, $0
	add_nt		r31,  r6, $0
	add_nt		r31,  r7, $0
	add_nt		r31,  r8, $0
	add_nt		r31,  r9, $0
	add_nt		r31, r10, $0
	add_nt		r31, r11, $0
	add_nt		r31, r12, $0
	add_nt		r31, r13, $0
	add_nt		r31, r14, $0
	add_nt		r31, r15, $0
	add_nt		r31, r16, $0
	add_nt		r31, r17, $0
	add_nt		r31, r18, $0
	add_nt		r31, r19, $0
	add_nt		r31, r20, $0
	add_nt		r31, r21, $0
	add_nt		r31, r22, $0
	add_nt		r31, r23, $0
	add_nt		r31, r24, $0
	add_nt		r31, r25, $0
	add_nt		r31, r26, $0
	add_nt		r31, r27, $0
	add_nt		r31, r28, $0
	add_nt		r31, r29, $0
	add_nt		r31, r30, $0

/*
 * Jump table to set a register.  r9 contains the value to set.
 */
SetReg:
	add_nt		r0, r9, $0
	add_nt		r1, r9, $0
	add_nt		r2, r9, $0
	add_nt		r3, r9, $0
	add_nt		r4, r9, $0
	add_nt		r5, r9, $0
	add_nt		r6, r9, $0
	add_nt		r7, r9, $0
	add_nt		r8, r9, $0
	add_nt		r9, r9, $0
	add_nt		r10, r9, $0
	add_nt		r11, r9, $0
	add_nt		r12, r9, $0
	add_nt		r13, r9, $0
	add_nt		r14, r9, $0
	add_nt		r15, r9, $0
	add_nt		r16, r9, $0
	add_nt		r17, r9, $0
	add_nt		r18, r9, $0
	add_nt		r19, r9, $0
	add_nt		r20, r9, $0
	add_nt		r21, r9, $0
	add_nt		r22, r9, $0
	add_nt		r23, r9, $0
	add_nt		r24, r9, $0
	add_nt		r25, r9, $0
	add_nt		r26, r9, $0
	add_nt		r27, r9, $0
	add_nt		r28, r9, $0
	add_nt		r29, r9, $0
	add_nt		r30, r9, $0
	add_nt		r31, r9, $0

/*
 ****************************************************************************
 *
 * END: SPECIAL LOW MEMORY OBJECTS
 *
 ****************************************************************************
 */

.org	0x2000
	.globl start
start:
/*
 * The initial boot code.  This is where we start executing in physical mode
 * after we are down loaded.  Our job is to:
 *
 *	1) Initialize VM.
 *	2) Jump to virtual mode
 *	3) Initialize the swp, cwp and spill sp.
 *	4) Jump to the main routine.
 *
 * The following code assumes that the initial kernel does not take more
 * than 4 Mbytes of memory since it starts the kernel page tables at
 * 4 Mbytes.
 *
 *	KERN_PT_FIRST_PAGE	The physical page where the page tables start.
 *	KERN_NUM_PAGES		The number of physical pages in the kernel.
 *	KERN_PT_BASE		The address of the kernel's page tables.
 *	KERN_PT2_BASE		The address of the 2nd level kernel
 *				page tables.
 */

#define	KERN_PT_FIRST_PAGE	1024

#define	KERN_NUM_PAGES		1024
#define	KERN_PT_BASE	(MACH_MEM_SLOT_MASK | (KERN_PT_FIRST_PAGE * VMMACH_PAGE_SIZE))
#define	KERN_PT2_BASE	(KERN_PT_BASE + ((VMMACH_SEG_PT_SIZE / 4) * VMMACH_KERN_PT_QUAD))

/*
 * Initialize the kernel page tables.  In the code that follows registers have 
 * the following meaning:
 *
 *	r1:	The base address of the second-level page tables.
 *	r2:	The number of page table pages.
 *	r3:	The page table entry.
 *	r4:	The page table increment.
 *
 * First initialize the second level page tables so that they map
 * all of the kernel page tables.
 */

#ifdef PATCH_IBUFFER
	/*
	 * Clear out r10 in all windows. 
	 */
	rd_special	r1, cwp
	wr_special	cwp,r0,$0	/* Window 0,1 */
	Nop
	add_nt		r10,r0,$0
	add_nt		r26,r0,$0
	wr_special	cwp,r0,$8	/* Window 2,3 */
	Nop
	add_nt		r10,r0,$0
	add_nt		r26,r0,$0
	wr_special	cwp,r0,$16	/* Window 4,5 */
	Nop
	add_nt		r10,r0,$0
	add_nt		r26,r0,$0
	wr_special	cwp,r0,$24	/* Window 6,7 */
	Nop
	add_nt		r10,r0,$0
	add_nt		r26,r0,$0
	wr_special	cwp, r1, $0
	Nop
#endif

	LD_CONSTANT(r1, KERN_PT2_BASE)
	add_nt		r2, r0, $VMMACH_NUM_PT_PAGES
	LD_CONSTANT(r3, MACH_MEM_SLOT_MASK | (KERN_PT_FIRST_PAGE << VMMACH_PAGE_FRAME_SHIFT) | VMMACH_RESIDENT_BIT | VMMACH_CACHEABLE_BIT | VMMACH_KRW_URO_PROT | VMMACH_REFERENCED_BIT | VMMACH_MODIFIED_BIT)
	LD_CONSTANT(r4, 1 << VMMACH_PAGE_FRAME_SHIFT)

1:
	st_32		r3, r1, $0
	add_nt		r1, r1, $4
	add_nt		r3, r3, r4
	sub		r2, r2, $1
	cmp_br_delayed	gt, r2, $0, 1b
	Nop


/*
 * Next initialize the kernel page table to point to 4 Mbytes of mapped
 * code.
 */
	LD_CONSTANT(r1, KERN_PT_BASE)
	add_nt		r2, r0, $KERN_NUM_PAGES
	LD_CONSTANT(r3, MACH_MEM_SLOT_MASK | (MACH_FIRST_PHYS_PAGE << VMMACH_PAGE_FRAME_SHIFT) | VMMACH_RESIDENT_BIT | VMMACH_CACHEABLE_BIT | VMMACH_KRW_URO_PROT | VMMACH_REFERENCED_BIT | VMMACH_MODIFIED_BIT)
1:
	st_32		r3, r1, $0
	add_nt		r1, r1, $4
	add_nt		r3, r3, r4
	sub		r2, r2, $1
	cmp_br_delayed	gt, r2, $0, 1b
	Nop

/*
 * Initialize the PTEVA.
 */
	LD_CONSTANT(r1, VMMACH_KERN_PT_BASE >> VMMACH_PAGE_SHIFT)
	ST_PT_BASE(r1)
/*
 * Initialize the RPTEVA.
 */
	ST_RPT_BASE(r1)
/*
 * Initialize the 0th segment register.
 */
	ST_GSN(r0, MACH_GSN_0)
/*
 * Initialize the RPTM register.
 */
	LD_CONSTANT(r1, KERN_PT2_BASE)
	ST_RPTM(r1, MACH_RPTM_0)
/*
 * Clear out the cache.
 */
	LD_CONSTANT(r1, 0x03000000)
	LD_CONSTANT(r2, (0x03000000 | VMMACH_CACHE_SIZE))
1:
	st_32		r0, r1, $0
	add_nt		r1, r1, $VMMACH_CACHE_LINE_SIZE
	cmp_br_delayed	lt, r1, r2, 1b
	Nop

/*
 * Clear snoop tags.
 */
	LD_CONSTANT(r1, 0x04000000)
	LD_CONSTANT(r2, (0x04000000 | VMMACH_CACHE_SIZE))
1:
	st_32		r0, r1, $0
	add_nt		r1, r1, $VMMACH_CACHE_LINE_SIZE
	cmp_br_delayed	lt, r1, r2, 1b
	Nop

/*
 * Initialize the cwp, swp and SPILL_SP to their proper values.
 */
	wr_special	cwp, r0, $4
	Nop
	LD_CONSTANT(r1, MACH_STACK_BOTTOM)
	wr_special	swp, r1, $0
	LD_CONSTANT(SPILL_SP, MACH_CODE_START)

/*
 * Clear out the upsw.
 */
	wr_special	upsw, r0, $0

/*
 * Clear out the interrupt mask register so that no interrupts are enabled.
 */
	WRITE_STATUS_REGS(MACH_INTR_MASK_0, r0)

/*
 * Clear the fe status register.
 */
	add_nt		r1, r0, $-1
	WRITE_STATUS_REGS(MACH_FE_STATUS_0, r1)

/*
 * Now jump to virtual mode through the following sequence:
 *
 *	1) Disable instruction buffer just in case it is on.
 *	2) Invalidate the instruction buffer.
 *	3) Make a good kpsw.
 *	4) Call the main function while setting the kpsw to put is in
 *	   virtual mode in the nop slot of the call.
 */
	wr_kpsw		r0, $0
	invalidate_ib
	add_nt		r1, r0, $(DEFAULT_KPSW)
	LD_PC_RELATIVE(r2, mainAddr)
	jump_reg	r2, $0
	wr_kpsw		r1, $0
	jump		ErrorTrap
	Nop
mainAddr:	.long	_main
/*
 *---------------------------------------------------------------------------
 *
 * WinOvFlow --
 *
 *	Window overflow fault handler.  If in user mode then the swp is
 *	validated first.  If it is invalid then the trapping process is 
 *	killed.  Also if in user mode more memory will be wired down if not
 * 	enough is wired already.
 */
WinOvFlow:
	rd_kpsw		SAFE_TEMP1			
	and		SAFE_TEMP1, SAFE_TEMP1, $MACH_KPSW_CUR_MODE
	cmp_br_delayed	eq, SAFE_TEMP1, r0, winOvFlow_SaveWindow
	Nop
	VERIFY_SWP(winOvFlow_SaveWindow)	/* Verify that the SWP is OK.*/
	/*
	 * The SWP is bogus.  Act as if we were able to do the overflow
	 * so when we trap back in to kill the user process we won't take
	 * another overflow.
	 */
	rd_special	r1, swp
	wr_special	swp, r1, $MACH_SAVED_WINDOW_SIZE
	USER_ERROR(MACH_USER_BAD_SWP_TRAP)
	/* DOESN'T RETURN */
winOvFlow_SaveWindow:
	/*
	 * Actually save the window.
	 */
	add_nt		SAFE_TEMP2, r1, $0	/* Save r1 */
	rd_special	VOL_TEMP1, cwp
	wr_special	cwp, VOL_TEMP1, $4	/* Move forward one window. */
	Nop
	rd_special	r1, swp
	and		r1, r1, $~7		/* Eight byte align swp */
	wr_special	swp, r1, $MACH_SAVED_WINDOW_SIZE
	add_nt		r1, r1, $MACH_SAVED_WINDOW_SIZE

	st_40		r10, r1, $0
#ifdef PATCH_IBUFFER
	add_nt		r10,r0,$0
#endif
	st_40		r11, r1, $8
	st_40		r12, r1, $16
	st_40		r13, r1, $24
	st_40		r14, r1, $32
	st_40		r15, r1, $40
	st_40		r16, r1, $48
	st_40		r17, r1, $56
	st_40		r18, r1, $64
	st_40		r19, r1, $72
	st_40		r20, r1, $80
	st_40		r21, r1, $88
	st_40		r22, r1, $96
	st_40		r23, r1, $104
	st_40		r24, r1, $112
	st_40		r25, r1, $120
	rd_special	r1, cwp
	wr_special	cwp, r1, $-4		/* Move back one window. */
	Nop

	add_nt		r1, SAFE_TEMP2, $0	/* Restore r1 */

	/* 
	 * See if we have to allocate more memory.  We need to allocate more
	 * if
	 *
	 *	swp > max_swp - 2 * MACH_SAVED_REG_SET_SIZE
	 */
	cmp_br_delayed	eq, SAFE_TEMP1, r0, winOvFlow_Return	/* No need to */
	Nop							/* check from */
								/* kernel mode*/
	LD_MACH_CUR_STATE_PTR(VOL_TEMP1)
	rd_special	VOL_TEMP2, swp
	ld_32		VOL_TEMP1, VOL_TEMP1, $MACH_MAX_SWP_OFFSET
	sub		VOL_TEMP1, VOL_TEMP1, $(2 * MACH_SAVED_REG_SET_SIZE)
	cmp_br_delayed	ule, VOL_TEMP2, VOL_TEMP1, winOvFlow_Return
	Nop
	/*
	 * Allocate more memory.
	 */
	add_nt		NON_INTR_TEMP1, CUR_PC_REG, $0
#ifdef PATCH_IBUFFER
	/*
	 * Patch for IBUFFER.
	 *	Clear CUR_PC_REG so we can detect when interrupt trap
	 *	handling messes up.
	 */
	add_nt		CUR_PC_REG, r0, $0
#endif
	add_nt		NON_INTR_TEMP2, NEXT_PC_REG, $0
	invalidate_ib
	rd_special	VOL_TEMP1, pc
	return_trap	VOL_TEMP1, $12
	Nop
	cmp_trap	always, r0, r0, $MACH_GET_WIN_MEM_TRAP
	Nop

winOvFlow_Return:
#ifdef PATCH_IBUFFER
	/*
	 * Patch for IBUFFER.
	 *	1) Clear CUR_PC_REG so we can detect when interrupt trap
	 *	   handling messes up.
	 *	2) invalidate Ibuffer so we don't get hit when we return.
	 */
	add_nt		SAFE_TEMP1, CUR_PC_REG, $0
	add_nt		CUR_PC_REG, r0, $0
	jump_reg	SAFE_TEMP1, $0
#else
	jump_reg	CUR_PC_REG, $0
#endif
	return_trap	NEXT_PC_REG, $0

/*
 *----------------------------------------------------------------------------
 *
 * WinUnFlow --
 *
 *	Window underflow fault handler.  If in user mode then the swp is 
 *	validated first.  If it is invalid then the trapping process is 
 *	killed.  Also if in user mode more memory is wired down if 
 *	the trapping process doesn't have the memory behind the new swp wired
 *	down.
 *
 *----------------------------------------------------------------------------
 */
WinUnFlow:
	rd_kpsw		SAFE_TEMP1
	and		SAFE_TEMP1, SAFE_TEMP1, $MACH_KPSW_CUR_MODE
	cmp_br_delayed	eq, SAFE_TEMP1, r0, winUnFlow_RestoreWindow
	Nop
	VERIFY_SWP(winUnFlow_RestoreWindow)
	/*
	 * We have a bogus SWP.  Act as if we took an underflow so when we
	 * return to user mode to try to kill the process we won't try to
	 * take an underflow.  As it turns out it shouldn't matter because
	 * the return trap in the USER_ERROR macro will be done with all
	 * traps disabled which means that the underflow will be ignored.
	 * However, its better to be safe than sorry.
	 */
	rd_special	VOL_TEMP1, swp
	wr_special	swp, VOL_TEMP1, $-MACH_SAVED_WINDOW_SIZE
	USER_ERROR(MACH_USER_BAD_SWP_TRAP)
	/* DOESN'T RETURN */
winUnFlow_RestoreWindow:
	add_nt		SAFE_TEMP2, r1, $0	/* Save r1 */
	rd_special	r1, swp
	and		r1, r1, $~7		/* Eight byte align swp */
	rd_special	VOL_TEMP1, cwp
	wr_special	cwp, VOL_TEMP1,  $-8	/* move back two windows */
	Nop


	ld_40		r10, r1,   $0
	ld_40		r11, r1,   $8
	ld_40		r12, r1,  $16
	ld_40		r13, r1,  $24
	ld_40		r14, r1,  $32
	ld_40		r15, r1,  $40
	ld_40		r16, r1,  $48
	ld_40		r17, r1,  $56
	ld_40		r18, r1,  $64
	ld_40		r19, r1,  $72
	ld_40		r20, r1,  $80
	ld_40		r21, r1,  $88
	ld_40		r22, r1,  $96
	ld_40		r23, r1, $104
	ld_40		r24, r1, $112
	ld_40		r25, r1, $120
	wr_special	swp, r1, $-MACH_SAVED_WINDOW_SIZE
	rd_special	r1, cwp
	wr_special	cwp,  r1, $8	/* move back ahead two windows */
	Nop
	add_nt		r1, SAFE_TEMP2, $0	/* Restore r1 */
	/*
	 * See if need more memory.  We need more if 
	 *
	 * 	swp <= min_swp + MACH_SAVED_WINDOW_SIZE
	 */
	cmp_br_delayed	eq, SAFE_TEMP1, $0, winUnFlow_Return	/* No need to */
	Nop							/* check from */
								/* kernel mode*/
	LD_MACH_CUR_STATE_PTR(VOL_TEMP1)
	rd_special	VOL_TEMP2, swp
	ld_32		VOL_TEMP1, VOL_TEMP1, $MACH_MIN_SWP_OFFSET
	Nop
	add_nt		VOL_TEMP1, VOL_TEMP1, $MACH_SAVED_WINDOW_SIZE
	cmp_br_delayed	ugt, VOL_TEMP2, VOL_TEMP1, winUnFlow_Return
	Nop
	/*
	 * Need to get more memory for window underflow.
	 */
	add_nt		NON_INTR_TEMP1, CUR_PC_REG, $0
#ifdef PATCH_IBUFFER
	/*
	 * Patch for IBUFFER.
	 *	Clear CUR_PC_REG so we can detect when interrupt trap
	 *	handling messes up.
	 */
	add_nt		CUR_PC_REG, r0, $0
#endif
	add_nt		NON_INTR_TEMP2, NEXT_PC_REG, $0
	invalidate_ib
	rd_special	VOL_TEMP1, pc	/* Return from traps and then */
	return_trap	VOL_TEMP1, $12	/*   take the compare trap to */
	Nop				/*   get back in in kernel mode. */
	cmp_trap	always, r0, r0, $MACH_GET_WIN_MEM_TRAP
	Nop

winUnFlow_Return:
#ifdef PATCH_IBUFFER
	/*
	 * Patch for IBUFFER.
	 *	1) Clear CUR_PC_REG so we can detect when interrupt trap
	 *	   handling messes up.
	 *	2) invalidate Ibuffer so we don't get hit when we return.
	 */
	add_nt		SAFE_TEMP1, CUR_PC_REG, $0
	add_nt		CUR_PC_REG, r0, $0
	invalidate_ib
	jump_reg	SAFE_TEMP1, $0
#else
	jump_reg	CUR_PC_REG, $0
#endif
	return_trap	NEXT_PC_REG, $0
	Nop

/*
 *---------------------------------------------------------------------------
 *
 * FPUExcept --
 *
 *	FPU Exception handler.  Currently we take either a user or kernel error
 *	whichever is appropriate.
 *
 *---------------------------------------------------------------------------
 */
FPUExcept:
	rd_kpsw		VOL_TEMP1
	and		VOL_TEMP1, VOL_TEMP1, $MACH_KPSW_PREV_MODE
	cmp_br_delayed	eq, VOL_TEMP1, $0, fpuExcept_KernError
	Nop
	USER_ERROR(MACH_USER_FPU_EXCEPT_TRAP)
	/* DOESN'T RETURN */
fpuExcept_KernError:
	CALL_DEBUGGER(r0, MACH_KERN_FPU_EXCEPT)

/*
 *---------------------------------------------------------------------------
 *
 * Illegal --
 *
 *	Illegal instruction handler.  Currently we take either a user or 
 * 	kernel error whichever is appropriate.
 *
 *---------------------------------------------------------------------------
 */
Illegal:
	rd_kpsw		VOL_TEMP1
	and		VOL_TEMP1, VOL_TEMP1, $MACH_KPSW_PREV_MODE
	cmp_br_delayed	eq, VOL_TEMP1, $0, illegal_KernError
	Nop
	USER_ERROR(MACH_USER_ILLEGAL_TRAP)
	/* DOESN'T RETURN */
illegal_KernError:
	CALL_DEBUGGER(r0, MACH_KERN_ILLEGAL)

/*
 *---------------------------------------------------------------------------
 *
 * Fixnum --
 *
 *	Fixnum Exception handler.  Currently we take either a user or kernel
 *	error whichever is appropriate.
 *
 *---------------------------------------------------------------------------
 */
Fixnum:
	rd_kpsw		VOL_TEMP1
	and		VOL_TEMP1, VOL_TEMP1, $MACH_KPSW_PREV_MODE
	cmp_br_delayed	eq, VOL_TEMP1, $0, fixnum_KernError
	Nop
	USER_ERROR(MACH_USER_FIXNUM_TRAP)
	/* DOESN'T RETURN */
fixnum_KernError:
	CALL_DEBUGGER(r0, MACH_KERN_FIXNUM)

/*
 *---------------------------------------------------------------------------
 *
 * Overflow --
 *
 *	Overflow fault handler.  Currently we take either a user or kernel
 *	error whichever is appropriate.
 *
 *---------------------------------------------------------------------------
 */
Overflow:
	rd_kpsw		VOL_TEMP1
	and		VOL_TEMP1, VOL_TEMP1, $MACH_KPSW_PREV_MODE
	cmp_br_delayed	eq, VOL_TEMP1, $0, overflow_KernError
	Nop
	USER_ERROR(MACH_USER_OVERFLOW_TRAP)
	/* DOESN'T RETURN */
overflow_KernError:
	CALL_DEBUGGER(r0, MACH_KERN_OVERFLOW)


/*
 *---------------------------------------------------------------------------
 *
 * PowerUp --
 *
 *	Jump to power up sequencer.
 *
 *---------------------------------------------------------------------------
 */
PowerUp: 			/* Jump to power up sequencer */

/*
 *---------------------------------------------------------------------------
 *
 * Error --
 *
 *	Error handler.  Just call the debugger.
 *
 *---------------------------------------------------------------------------
 */
ErrorTrap:	
	SWITCH_TO_KERNEL_STACKS()
	CALL_DEBUGGER(r0, MACH_ERROR)

/*
 *---------------------------------------------------------------------------
 *
 * FaultIntr --
 *
 *	Handle a fault or an interrupt.
 *
 *---------------------------------------------------------------------------
 */
faultIntr_Const1:
	.long	MACH_KPSW_USE_CUR_PC
faultIntr_Const3:
	.long	MACH_FAULT_TRY_AGAIN
faultIntr_Const4:
	.long	MACH_FAULT_ILL_CACHE_OP
FaultIntr:
faultIntr_NormFault:
	/*
	 * On this type of trap we are supposed to return to the current 
	 * PC.
	 */
	rd_kpsw		KPSW_REG
	/*
 	 * Disable ibuffer in kernel. 
	 */
	and	VOL_TEMP1,KPSW_REG,$~(MACH_KPSW_IBUFFER_ENA|MACH_KPSW_PREFETCH_ENA);
	wr_kpsw	VOL_TEMP1,$0
	LD_PC_RELATIVE(SAFE_TEMP1, faultIntr_Const1)
	or		KPSW_REG, KPSW_REG, SAFE_TEMP1
	/*
	 * Read and clear the fault/error status register.
	 */
	READ_STATUS_REGS(MACH_FE_STATUS_0, SAFE_TEMP1)
	st_32		SAFE_TEMP1, r0, $feStatusReg
	WRITE_STATUS_REGS(MACH_FE_STATUS_0, SAFE_TEMP1)
	/*
	 * If no bits are set then it must be an interrupt.
	 */
	cmp_br_delayed	ne, SAFE_TEMP1, r0, noInterrupt
	Nop
	jump 	 Interrupt
	Nop
noInterrupt:
	/*
	 * If any of the bits FEStatus<19:16> are set then is one of the
	 * four VM faults.  Store the fault type in a safe temporary and
	 * call the VMFault handler.
	 */
	extract		VOL_TEMP1, SAFE_TEMP1, $2
	and		VOL_TEMP1, VOL_TEMP1, $0xf
	cmp_br_delayed	eq, VOL_TEMP1, r0, noFault
	Nop
	jump		VMFault
	Nop
noFault:
	/*
	 * Handle the bus retry error.
	 */
	LD_PC_RELATIVE(SAFE_TEMP2, faultIntr_Const3)
	and		VOL_TEMP1, SAFE_TEMP1, SAFE_TEMP2
	cmp_br_delayed	eq, VOL_TEMP1, r0, 1f
	nop
#ifdef PATCH_IBUFFER
	/*
	 * Patch for IBUFFER.
	 *	Clear CUR_PC_REG so we can detect when interrupt trap
	 *	handling messes up.
	 */
	add_nt		SAFE_TEMP1,CUR_PC_REG,$0
	add_nt		CUR_PC_REG,r0,$0
	jump_reg	SAFE_TEMP1, $0
#else
	jump_reg	CUR_PC_REG, $0
#endif
	return_trap	NEXT_PC_REG, $0

1:
	/*
	 * If a user does an illegal cache op on a non-cachable page, we
	 * get a MACH_FAULT_ILL_CACHE_OP even if the user has no access to 
	 * the page. 
	 */

	LD_PC_RELATIVE(SAFE_TEMP2, faultIntr_Const4)
	and		VOL_TEMP1, SAFE_TEMP1, SAFE_TEMP2
	cmp_br_delayed	eq, VOL_TEMP1, r0, 2f
	Nop

	/*
	 * If the fault came from user mode map it into a protection fault.
	 */
	and		VOL_TEMP1, KPSW_REG, $MACH_KPSW_PREV_MODE
	cmp_br_delayed	eq, VOL_TEMP1, $0, 2f
	Nop
	add_nt		VOL_TEMP1,r0,$(MACH_FAULT_PROTECTION >> 16)
	jump		VMFault
	Nop

2:
	/*
	 * Can't handle any of these types of faults.
	 */
	SWITCH_TO_KERNEL_STACKS()

	CALL_DEBUGGER(r0, MACH_BAD_FAULT)
#ifdef FAST_REFRESH
/*
 * Perform a fast refresh.
 */
fastRefresh:
	/*
	 * Refresh the dynamic registers by reading and writting them.
	 */
	rd_special	VOL_TEMP1, upsw
	rd_special	VOL_TEMP2, swp
	wr_special	upsw, VOL_TEMP1, $0
	wr_special	swp, VOL_TEMP2, $0
	rd_insert	VOL_TEMP1 
	wr_insert	VOL_TEMP1
	/*
	 * Increment the refresh count levaing the count in VOL_TEMP3 and
	 * the processor number (pnum*4) in OUTPUT_REG2.
	 */
	extract		VOL_TEMP1,KPSW_REG,$3
	sll		OUTPUT_REG2,VOL_TEMP1,$2
	ld_32_ro	VOL_TEMP3,OUTPUT_REG2,$_machRefreshCount
	add_nt		VOL_TEMP3,VOL_TEMP3,$1
	st_32		VOL_TEMP3,OUTPUT_REG2,$_machRefreshCount 
	ld_32		VOL_TEMP2,r0,$_machRefreshTimerValue
	/*
	 * Reload the counter.
	 */
        st_external     VOL_TEMP2, r0, $MACH_T_20|MACH_CO_WR_REG
        extract         VOL_TEMP1, VOL_TEMP2, $1
        st_external     VOL_TEMP1, r0, $MACH_T_21|MACH_CO_WR_REG
        extract         VOL_TEMP1, VOL_TEMP2, $2
        st_external     VOL_TEMP1, r0, $MACH_T_22|MACH_CO_WR_REG
        extract         VOL_TEMP1, VOL_TEMP2, $3
        st_external     VOL_TEMP1, r0, $MACH_T_23|MACH_CO_WR_REG
	/*
	 * Start the counter.
	 */
	ld_external	VOL_TEMP1, r0, $MACH_MODE_REG|MACH_CO_RD_REG
	nop
	or		VOL_TEMP1, VOL_TEMP1, $MACH_MODE_T2_ENABLE
	st_external	VOL_TEMP1, r0, $MACH_MODE_REG|MACH_CO_WR_REG
	/*
	 * Compute the new values for leds. This new value is equal to 
	 *	machLEDValues | idleCountLeds[(*machIdleCountPtr>>6)&0x3] |
	 *	refreshCountLeds[refreshCount>>6)&0x3]
	 */
	ld_32		VOL_TEMP2,OUTPUT_REG2,$_machLEDValues
	ld_32		VOL_TEMP1,OUTPUT_REG2,$_machIdleCountPtr
	extract		VOL_TEMP3,VOL_TEMP3,$1
	sll		VOL_TEMP3,VOL_TEMP3,$2
	ld_32		VOL_TEMP1,VOL_TEMP1,$0
	and		VOL_TEMP3,VOL_TEMP3,$(0x3<<2)
	ld_32		VOL_TEMP3,VOL_TEMP3,$refreshCountLeds
	extract		VOL_TEMP1,VOL_TEMP1,$1
	srl		VOL_TEMP1,VOL_TEMP1,$1
	and		VOL_TEMP1,VOL_TEMP1,$(0x7<<2)
	ld_32		VOL_TEMP1,VOL_TEMP1,$idleCountLeds
	or		VOL_TEMP2,VOL_TEMP2,VOL_TEMP3
	or		VOL_TEMP1,VOL_TEMP2,VOL_TEMP1
	/*
	 * Go into physical data fetch with the address of the LEDs in
	 * VOL_TEMP3 and the new value in VOL_TEMP1.  We read the contents
	 * of the DIP switches into VOL_TEMP1 upon exit of phsyical mode.
	 */
	and		VOL_TEMP2,KPSW_REG, $~MACH_KPSW_VIRT_DFETCH_ENA
	ld_32		VOL_TEMP3,r0,$ledAddrs
	wr_kpsw		VOL_TEMP2, $0
	/*
	 * Store into LEDS.
	 */
	st_32		VOL_TEMP1,VOL_TEMP3,$0
	/*
	 * Read from DIP switches at address twice the address of the LEDs
	 */
	ld_32		VOL_TEMP1,VOL_TEMP3,VOL_TEMP3
	/*
	 * If switch 0x4 is set continue with full interrupt sequence.
	 */
	and		VOL_TEMP1,VOL_TEMP1,$0x4
	cmp_br_delayed	ne,r0,VOL_TEMP1,intrCont
	wr_kpsw		KPSW_REG, $0
	/*
	 * If there are any more interrupt to process continue with full
	 * interrupt sequence.
	 */
	cmp_br_delayed	ne,r0,OUTPUT_REG1,intrCont
	/*
	 * Return from interupt.  Move the MACH_KPSW_PREV_MODE of the KPSW 
	 * into the MACH_KPSW_CUR_MODE.
	 */
	and		VOL_TEMP1, KPSW_REG, $MACH_KPSW_PREV_MODE
	cmp_br_delayed	eq, VOL_TEMP1, r0, fastRefreshReturn
	Nop
	or		KPSW_REG, KPSW_REG, $MACH_KPSW_CUR_MODE
	wr_kpsw		KPSW_REG, $0
fastRefreshReturn:
	jump_reg	CUR_PC_REG,$0
	return_trap	NEXT_PC_REG, $0
#endif

/*
 *---------------------------------------------------------------------------
 *
 * Interrupt --
 *
 *	Handle an interrupt.
 *
 *---------------------------------------------------------------------------
 */
Interrupt:
	/*
	 * Read the interrupt status register and clear it.  The ISR is passed
	 * as an arg to the interrupt routine. Store the interrupt mask in
         * SAFE_TEMP3.
	 */
	READ_STATUS_REGS(MACH_INTR_STATUS_0, OUTPUT_REG1)
	READ_STATUS_REGS(MACH_INTR_MASK_0, SAFE_TEMP3)
	and		OUTPUT_REG1, OUTPUT_REG1, SAFE_TEMP3
	WRITE_STATUS_REGS(MACH_INTR_STATUS_0, OUTPUT_REG1)

#ifdef FAST_REFRESH
	ld_32		VOL_TEMP1,r0,$_machRefreshIntrMask
	nop
	and		VOL_TEMP1,VOL_TEMP1,OUTPUT_REG1
	cmp_br_delayed	ne,VOL_TEMP1,r0,fastRefresh
	xor		OUTPUT_REG1,OUTPUT_REG1,VOL_TEMP1
intrCont:
#endif 
#ifdef notdef
	/*
	 * Check to see if the interrupt happened on a test_and_set 
	 * instruction.  If so panic because this isn't supposed to
	 * happen.
	 */
	ld_32		VOL_TEMP1, CUR_PC_REG, r0
	nop
	extract		VOL_TEMP1, VOL_TEMP1, $3
	srl		VOL_TEMP1, VOL_TEMP1, $1
	and		VOL_TEMP1, VOL_TEMP1, $0xf0
	add_nt		VOL_TEMP2, r0, $0x30
	cmp_br_delayed	ge, VOL_TEMP1, VOL_TEMP2, interrupt_OK
	nop
	st_32		CUR_PC_REG, r0, $interruptPC
	or		KPSW_REG, KPSW_REG, $MACH_KPSW_ALL_TRAPS_ENA
	wr_kpsw		KPSW_REG, $0
	cmp_trap	always, r0, r0, $MACH_CALL_DEBUGGER_TRAP

interrupt_OK:

#endif

	/* 
	 * Save the address of the interrupt for profiling. 
	 */
	st_32		CUR_PC_REG, r0, $_machInterruptAddr 

	/*
	 * The second argument is the kpsw.
	 */
	add_nt		OUTPUT_REG2, KPSW_REG, r0
	/*
	 * Save the insert register in a safe temporary and then
	 * disable all but non-maskable interrupts.  Don't enable all traps
	 * until after we have verified that the user's swp isn't bogus.
	 */
	rd_insert	SAFE_TEMP1
	ld_32		SAFE_TEMP2, r0, $_machNonmaskableIntrMask
	nop
	WRITE_STATUS_REGS(MACH_INTR_MASK_0, SAFE_TEMP2)
	/*
	 * See if took the interrupt from user mode.
	 */
	and		VOL_TEMP2, KPSW_REG, $MACH_KPSW_PREV_MODE
	cmp_br_delayed	eq, VOL_TEMP2, $0, interrupt_KernMode
	Nop
	/*
	 * We took the interrupt from user mode.
	 */
	VERIFY_SWP(interrupt_GoodSWP)
	jump	interrupt_BadSWP
	Nop

interrupt_GoodSWP:
	SAVE_USER_STATE()
	SWITCH_TO_KERNEL_STACKS()
	wr_kpsw		KPSW_REG, $MACH_KPSW_ALL_TRAPS_ENA
	invalidate_ib
	call		_MachInterrupt
	Nop
#ifdef PATCH_IBUFFER
#if 0
	add_nt		OUTPUT_REG1,KPSW_REG,$0
	invalidate_ib
	call		_MachPatchUserModeIbuffer
	Nop
#endif
#endif
	/*
	 * Restore the insert register and the kpsw, enable interrupts and 
	 * then do a normal return from trap in case the user process needs to
	 * take some action. Insure that WRITE_STATUS_REGS is called with
	 * interrupts disabled.
	 */
	wr_insert	SAFE_TEMP1
	and		VOL_TEMP1, KPSW_REG, $~MACH_KPSW_INTR_TRAP_ENA
	wr_kpsw		VOL_TEMP1, $0
	WRITE_STATUS_REGS(MACH_INTR_MASK_0, SAFE_TEMP3)
	wr_kpsw		KPSW_REG, $0
	add_nt		RETURN_VAL_REG, r0, $MACH_NORM_RETURN
	jump		ReturnTrap
	Nop

interrupt_KernMode:
	/*
	 * Save all globals on the spill stack in case they get
	 * trashed.
	 */
	sub		SPILL_SP, SPILL_SP, $64
	st_40		r1, SPILL_SP, $0
	st_40		r2, SPILL_SP, $8
	st_40		r3, SPILL_SP, $16
	st_40		r5, SPILL_SP, $24
	st_40		r6, SPILL_SP, $32
	st_40		r7, SPILL_SP, $40
	st_40		r8, SPILL_SP, $48
	st_40		r9, SPILL_SP, $56
	/*
	 * Enable all traps and take the interrupt.
	 */
#ifdef PATCH_IBUFFER
	add_nt		VOL_TEMP1, r26, $0
#endif
	wr_kpsw		KPSW_REG, $MACH_KPSW_ALL_TRAPS_ENA
	invalidate_ib
	call 		_MachInterrupt
	Nop
#ifdef PATCH_IBUFFER
#if 0
	add_nt		OUTPUT_REG1,KPSW_REG,$0
	add_nt		OUTPUT_REG2,CUR_PC_REG,$0
	add_nt		OUTPUT_REG3,NEXT_PC_REG,$0
	add_nt		OUTPUT_REG4,VOL_TEMP1,$0
	invalidate_ib
	call		_MachPatchIbuffer
	Nop
	add_nt		CUR_PC_REG,r27,$0
#endif
#endif
	/*
	 * Restore the globals and the spill sp.
	 */
	ld_40		r1, SPILL_SP, $0
	ld_40		r2, SPILL_SP, $8
	ld_40		r3, SPILL_SP, $16
	ld_40		r5, SPILL_SP, $24
	ld_40		r6, SPILL_SP, $32
	ld_40		r7, SPILL_SP, $40
	ld_40		r8, SPILL_SP, $48
	ld_40		r9, SPILL_SP, $56
	nop
	add_nt		SPILL_SP, SPILL_SP, $64

	/*
	 * Restore insert register and kpsw, enable interrupts and return.
	 */
	wr_insert	SAFE_TEMP1
	and		VOL_TEMP1, KPSW_REG, $~MACH_KPSW_INTR_TRAP_ENA
	wr_kpsw		VOL_TEMP1, $0
	WRITE_STATUS_REGS(MACH_INTR_MASK_0, SAFE_TEMP3)
	or		KPSW_REG, KPSW_REG, $MACH_KPSW_ALL_TRAPS_ENA
	wr_kpsw		KPSW_REG, $0
#ifdef PATCH_IBUFFER
	/*
	 * Patch for IBUFFER.
	 *	Clear CUR_PC_REG so we can detect when interrupt trap
	 *	handling messes up.
	 */
	add_nt		SAFE_TEMP1,CUR_PC_REG,$0
	add_nt		CUR_PC_REG,r0,$0
	jump_reg	SAFE_TEMP1, $0
#else
	jump_reg	CUR_PC_REG, $0
#endif
	return		NEXT_PC_REG, $0

interrupt_BadSWP:
	/*
	 * We have a bogus user swp.  Switch over to the kernel's stacks
	 * and take the interrupt.  After taking the interrupt kill the user
	 * process.
	 */
	SWITCH_TO_KERNEL_STACKS()
	wr_kpsw		KPSW_REG, $MACH_KPSW_ALL_TRAPS_ENA
	invalidate_ib
	call		_MachInterrupt
	Nop
	WRITE_STATUS_REGS(MACH_INTR_MASK_0, SAFE_TEMP3)
#ifdef PATCH_IBUFFER
	/*
	 * Patch for IBUFFER.
	 *	Clear CUR_PC_REG so we can detect when interrupt trap
	 *	handling messes up.
	 */
	add_nt		CUR_PC_REG,r0,$0
#endif
        add_nt          OUTPUT_REG1, r0, $MACH_USER_BAD_SWP
	invalidate_ib
	call		_MachUserError
	Nop
	/* DOESN'T RETURN */

/*
 *---------------------------------------------------------------------------
 *
 * VMFault --
 *
 *	Handle virtual memory faults.  The current fault type was stored
 *	in VOL_TEMP1 before we were called.
 *
 *---------------------------------------------------------------------------
 */
VMFault:
	add_nt		SAFE_TEMP1, VOL_TEMP1, $0
	/*
	 * Check kernel or user mode.
	 */
	and		VOL_TEMP1, KPSW_REG, $MACH_KPSW_PREV_MODE
	cmp_br_delayed	eq, VOL_TEMP1, $0, vmFault_KernMode
	Nop
	/*
	 * Make sure that the saved window stack is OK.
	 */
	VERIFY_SWP(vmFault_GoodSWP)
	USER_SWP_ERROR()
	/* DOESN'T RETURN */

vmFault_GoodSWP:
	SAVE_USER_STATE()
	SWITCH_TO_KERNEL_STACKS()
#ifdef PATCH_IBUFFER
#if 0
	add_nt		OUTPUT_REG1,KPSW_REG,$0
	invalidate_ib
	call		_MachPatchUserModeIbufferOnFault
	Nop
	add_nt		CUR_PC_REG, r27,$0
#endif
#endif
	jump		vmFault_PC
	nop

vmFault_KernMode:
	/*
	 * Save all globals on the spill stack in case they get
	 * trashed.
	 */
	add_nt		SPILL_SP, SPILL_SP, $-64  /* Make sure of alignment */
	st_40		r1, SPILL_SP, $0
	st_40		r2, SPILL_SP, $8
	st_40		r3, SPILL_SP, $16
	st_40		r5, SPILL_SP, $24
	st_40		r6, SPILL_SP, $32
	st_40		r7, SPILL_SP, $40
	st_40		r8, SPILL_SP, $48
	st_40		r9, SPILL_SP, $56

#ifdef PATCH_IBUFFER
#if 0
	add_nt		OUTPUT_REG1,KPSW_REG,$0
	add_nt		OUTPUT_REG2,CUR_PC_REG,$0
	add_nt		OUTPUT_REG3,NEXT_PC_REG,$0
	add_nt		OUTPUT_REG4,r26,$0
	invalidate_ib
	call		_MachPatchIbufferOnFault
	Nop
	add_nt		CUR_PC_REG,r27,$0
#endif
#endif

vmFault_PC:
	/*
	 * Enable all traps.
	 */
	or		VOL_TEMP1, KPSW_REG, $MACH_KPSW_ALL_TRAPS_ENA
	wr_kpsw		VOL_TEMP1, $0
	cmp_br_delayed	eq, SAFE_TEMP1, $MACH_VM_FAULT_DIRTY_BIT, vmFault_GetDataAddr
	nop
	/*
	 * Handle the fault on the PC first by calling
	 * MachVMPCFault(faultType, PC, kpsw).
	 */
	add_nt		OUTPUT_REG1, SAFE_TEMP1, $0
	add_nt		OUTPUT_REG2, CUR_PC_REG, $0
	add_nt		OUTPUT_REG3, KPSW_REG, $0
	rd_insert	VOL_TEMP1
	invalidate_ib
	call		_MachVMPCFault
	nop
	wr_insert	VOL_TEMP1
	cmp_br_delayed	eq, RETURN_VAL_REG, $MACH_NORM_RETURN, vmFault_GetDataAddr
	nop
	/*
	 * We got some sort of error.  If it was a user error then make sure
	 * that we do a normal return from trap so that the signal will
	 * be taken when it returns.  Otherwise leave the error code
	 * alone so that the kernel debugger will be called.
	 */
	cmp_br_delayed	eq, RETURN_VAL_REG, $MACH_KERN_ACCESS_VIOL, 1f
	nop
	add_nt		RETURN_VAL_REG, r0, $MACH_NORM_RETURN
1:	jump		vmFault_Return
	nop

vmFault_GetDataAddr:
	/*
	 * See if is a load, store or test-and-set instruction.  These types
	 * of instructions have opcodes less than 0x30.  If we find one
	 * of these then we have to extract the data address.
	 */
	FETCH_CUR_INSTRUCTION(SAFE_TEMP2)
	Nop
	extract		VOL_TEMP1, SAFE_TEMP2, $3  	/* Opcode <31:25> ->  */
							#	 <07:01>
	srl		VOL_TEMP1, VOL_TEMP1, $1	/* Opcode <07:01> -> */
							#	 <06:00>
	and		VOL_TEMP1, VOL_TEMP1, $0xf0	/* Get upper 4 bits. */
	add_nt		VOL_TEMP2, r0, $0x30
	cmp_br_delayed	lt, VOL_TEMP1, VOL_TEMP2, vmFault_IsData
	Nop
	jump		vmFault_Return
	nop
vmFault_IsData:
	/*
	 * Get the data address by calling ParseInstruction.  We pass the
	 * address to return to in VOL_TEMP1 and the instruction where we
	 * faulted at in VOL_TEMP2.  Disable interrupts because this routine
	 * screws around with windows.
	 */
	add_nt		VOL_TEMP2, SAFE_TEMP2, $0
	rd_insert	SAFE_TEMP2
	rd_kpsw		SAFE_TEMP3
	and		VOL_TEMP3, SAFE_TEMP3, $~MACH_KPSW_INTR_TRAP_ENA
	wr_kpsw		VOL_TEMP3, $0
	/*
 	 * Restore the globals if we are coming from user mode.
	 */
	and		VOL_TEMP1, KPSW_REG, $MACH_KPSW_PREV_MODE
	cmp_br_delayed	eq, VOL_TEMP1, r0, vmFault_KernParse
	nop
	LD_MACH_CUR_STATE_PTR(VOL_TEMP1)
	nop
	ld_40		r1, VOL_TEMP1, $(MACH_TRAP_REGS_OFFSET + 8)
	ld_40		r2, VOL_TEMP1, $(MACH_TRAP_REGS_OFFSET + 16)
	ld_40		r3, VOL_TEMP1, $(MACH_TRAP_REGS_OFFSET + 24)
	ld_40		r4, VOL_TEMP1, $(MACH_TRAP_REGS_OFFSET + 32)
	ld_40		r5, VOL_TEMP1, $(MACH_TRAP_REGS_OFFSET + 40)
	ld_40		r6, VOL_TEMP1, $(MACH_TRAP_REGS_OFFSET + 48)
	ld_40		r7, VOL_TEMP1, $(MACH_TRAP_REGS_OFFSET + 56)
	ld_40		r8, VOL_TEMP1, $(MACH_TRAP_REGS_OFFSET + 64)
	ld_40		r9, VOL_TEMP1, $(MACH_TRAP_REGS_OFFSET + 72)
	nop

	rd_special	VOL_TEMP1, pc
	add_nt		VOL_TEMP1, VOL_TEMP1, $16
	jump		ParseInstruction
	Nop

	LD_MACH_CUR_STATE_PTR(VOL_TEMP1)
	add_nt		VOL_TEMP2,OUTPUT_REG3,OUTPUT_REG4

	ld_32		SPILL_SP, VOL_TEMP1, $MACH_KERN_STACK_END_OFFSET

	jump		vmFault_CallDataFault
	nop

vmFault_KernParse:
	/*
	 * Restore globals since they could have gotten trashed while we
	 * called the C routines.
	 */
	ld_40		r1, SPILL_SP, $0
	ld_40		r2, SPILL_SP, $8
	ld_40		r3, SPILL_SP, $16
	ld_40		r5, SPILL_SP, $24
	ld_40		r6, SPILL_SP, $32
	ld_40		r7, SPILL_SP, $40
	ld_40		r8, SPILL_SP, $48
	ld_40		r9, SPILL_SP, $56

	rd_special	VOL_TEMP1, pc
	add_nt		VOL_TEMP1, VOL_TEMP1, $16
	jump		ParseInstruction
	Nop
	add_nt		VOL_TEMP2,OUTPUT_REG3,OUTPUT_REG4

vmFault_CallDataFault:
	wr_insert	SAFE_TEMP2
	wr_kpsw		SAFE_TEMP3, $0

	/*
	 * We now have the data address in VOL_TEMP2.  Call
	 * MachVMDataFault(faultType, PC, dataAddr, kpsw)
	 */
	add_nt		OUTPUT_REG1, SAFE_TEMP1, $0
	add_nt		OUTPUT_REG2, CUR_PC_REG, $0
	add_nt		OUTPUT_REG3, VOL_TEMP2, $0
	add_nt		OUTPUT_REG4, KPSW_REG, $0
	rd_insert	VOL_TEMP1
	invalidate_ib
	call		_MachVMDataFault
	Nop
	wr_insert	VOL_TEMP1

vmFault_Return:
	and		VOL_TEMP1, KPSW_REG, $MACH_KPSW_PREV_MODE
	cmp_br_delayed	ne, VOL_TEMP1, r0, 1f
	nop
	/*
	 * Restore the globals and the spill sp.
	 */
	ld_40		r1, SPILL_SP, $0
	ld_40		r2, SPILL_SP, $8
	ld_40		r3, SPILL_SP, $16
	ld_40		r5, SPILL_SP, $24
	ld_40		r6, SPILL_SP, $32
	ld_40		r7, SPILL_SP, $40
	ld_40		r8, SPILL_SP, $48
	ld_40		r9, SPILL_SP, $56
	nop
	add_nt		SPILL_SP, SPILL_SP, $64
1:
#ifdef FLUSH_CACHE_ON_RETURN
        LD_CONSTANT(VOL_TEMP2, VMMACH_CACHE_SIZE); 
        add_nt          VOL_TEMP1, r0, $0;
2:      st_external     r0, VOL_TEMP1, $MACH_CO_FLUSH; 
        add_nt          VOL_TEMP1, VOL_TEMP1, $VMMACH_CACHE_LINE_SIZE; 
        cmp_br_delayed  lt, VOL_TEMP1, VOL_TEMP2, 2b; 
	nop
#endif
	jump		ReturnTrap
	Nop

/*
 *--------------------------------------------------------------------------
 *
 * CmpTrap --
 *
 *	Handle a cmp_trap trap.  This involves determining the trap type
 *	and vectoring to the right spot to handle the trap.
 *
 *--------------------------------------------------------------------------
 */
cmpTrap_Const1:
	.long	~MACH_KPSW_USE_CUR_PC
CmpTrap:
	/*
	 * On this type of trap we are supposed to return to next PC instead
	 * of cur PC.
	 */
	rd_kpsw		KPSW_REG
	/*
 	 * Disable ibuffer in kernel. 
	 */
	and	VOL_TEMP1,KPSW_REG,$~(MACH_KPSW_IBUFFER_ENA|MACH_KPSW_PREFETCH_ENA);
	wr_kpsw	VOL_TEMP1,$0
	LD_PC_RELATIVE(SAFE_TEMP1, cmpTrap_Const1)
	and		KPSW_REG, KPSW_REG, SAFE_TEMP1

	/*
 	 * Clear the FE_STATUS registers incase there is a fault pending
	 * causes by the fetch of the instuction after the cmp_trap.
	 */
	add_nt		SAFE_TEMP1,r0,$-1	
	WRITE_STATUS_REGS(MACH_FE_STATUS_0, SAFE_TEMP1)
	/*
	 * Get the trap number.
	 */
	FETCH_CUR_INSTRUCTION(SAFE_TEMP1)
	Nop
	and		SAFE_TEMP1, SAFE_TEMP1, $0x1ff 
	/*
	 * If is one of the special user traps then handle these 
	 * specially and as quickly as possible.
	 */
	cmp_br_delayed	lt, SAFE_TEMP1, $MACH_USER_RET_TRAP_TRAP, 1f
	nop
	jump		SpecialUserTraps
	nop
1:
	/* 
	 * See if are coming from kernel mode or not.
	 */
	and		VOL_TEMP1, KPSW_REG, $MACH_KPSW_PREV_MODE
	cmp_br_delayed	eq, VOL_TEMP1, $0, cmpTrap_CheckType
	Nop
	/*
	 * Verify the SWP for user processes.
	 */
	VERIFY_SWP(cmpTrap_SaveState)
	USER_SWP_ERROR()
	/* DOESN'T RETURN */

cmpTrap_SaveState:
	cmp_br_delayed	eq, SAFE_TEMP1, $MACH_SIG_RETURN_TRAP, cmpTrap_CallFunc
	Nop
	SAVE_USER_STATE()
	SWITCH_TO_KERNEL_STACKS()

cmpTrap_CheckType:
	cmp_br_delayed	gt, SAFE_TEMP1, $MACH_MAX_TRAP_TYPE, cmpTrap_BadTrapType
	Nop

cmpTrap_CallFunc:
	sll		VOL_TEMP1, SAFE_TEMP1, $3	/* Multiple by 8 to */
							/*   get offset */
	rd_special	VOL_TEMP2, pc
	add_nt		VOL_TEMP2, VOL_TEMP2, $16
	jump_reg	VOL_TEMP2, VOL_TEMP1
	Nop
	jump		BreakpointTrap
	Nop
	jump		SingleStepTrap
	Nop
	jump		CallDebuggerTrap
	Nop
	jump		cmpTrap_RefreshTrap
	Nop
	jump		SysCallTrap	
	Nop
	jump		SigReturnTrap
	Nop
	jump		GetWinMemTrap
	Nop
	jump		cmpTrap_SaveStateTrap
	nop
	jump		cmpTrap_RestoreStateTrap
	nop
	jump		cmpTrap_TestAndSetTrap
	nop
	jump		cmpTrap_UserCSTrap
	nop
	jump		cmpTrap_BadSWPTrap
	nop
	jump		cmpTrap_CmpTrapTrap
	nop
	jump		cmpTrap_FPUTrap
	Nop
	jump		cmpTrap_IllegalTrap
	Nop
	jump		cmpTrap_FixnumTrap
	Nop
	jump		cmpTrap_OverflowTrap
	Nop

cmpTrap_BadSWPTrap:
	add_nt		OUTPUT_REG1, r0, $MACH_USER_BAD_SWP
	jump		UserErrorTrap
	Nop

	/*
	 * A user context switch trap.  We were called as
	 *
	 *	UserCS(swpBaseAddr, swpMaxAddr, newSWP)
	 *	    Address	swpBaseAddr;	* Base of saved window stack.
	 *	    Address	swpMaxAddr;	* Max addr of saved window
	 *					* stack.
	 *	    Address	newSWP;		* The new swp.
	 */

cmpTrap_CmpTrapTrap:
	add_nt		OUTPUT_REG1, r0, $MACH_BAD_TRAP_TYPE
	jump		UserErrorTrap
	Nop

cmpTrap_FPUTrap:
	add_nt		OUTPUT_REG1, r0, $MACH_USER_FPU_EXCEPT
	jump		UserErrorTrap
	Nop

cmpTrap_IllegalTrap:
	add_nt		OUTPUT_REG1, r0, $MACH_USER_ILLEGAL
	jump		UserErrorTrap
	Nop

cmpTrap_FixnumTrap:
	add_nt		OUTPUT_REG1, r0, $MACH_USER_FIXNUM
	jump		UserErrorTrap
	Nop

cmpTrap_OverflowTrap:
	add_nt		OUTPUT_REG1, r0, $MACH_USER_OVERFLOW
	jump		UserErrorTrap
	Nop
cmpTrap_UserCSTrap:
	or		VOL_TEMP1, KPSW_REG, $MACH_KPSW_ALL_TRAPS_ENA
	wr_kpsw		VOL_TEMP1, $0
	add_nt		OUTPUT_REG1, INPUT_REG1, $0
	add_nt		OUTPUT_REG2, INPUT_REG2, $0
	add_nt		OUTPUT_REG3, INPUT_REG3, $0
	invalidate_ib
	call		_MachUserContextSwitch
	nop
	jump		ReturnTrap
	nop

	/*
	 * Save the user's state in the special page.
	 */
cmpTrap_SaveStateTrap:
	or		VOL_TEMP1, KPSW_REG, $MACH_KPSW_ALL_TRAPS_ENA
	wr_kpsw		VOL_TEMP1, $0
	invalidate_ib
	call		_MachSaveUserState
	nop
	jump		ReturnTrap
	nop

	/*
	 * Restore the user's state from the special page.
	 */
cmpTrap_RestoreStateTrap:
	or		VOL_TEMP1, KPSW_REG, $MACH_KPSW_ALL_TRAPS_ENA
	wr_kpsw		VOL_TEMP1, $0
	invalidate_ib
	call		_MachRestoreUserState
	nop
	jump		ReturnTrap
	nop

	/* 
	 * User level test and set.  We were passed the address to set.
	 */
cmpTrap_TestAndSetTrap:
	or		VOL_TEMP1, KPSW_REG, $MACH_KPSW_ALL_TRAPS_ENA
	wr_kpsw		VOL_TEMP1, $0
	add_nt		OUTPUT_REG1, INPUT_REG1, $0
	invalidate_ib
	call		_MachUserTestAndSet
	nop
	jump		ReturnTrap
	nop

cmpTrap_RefreshTrap:
	rd_special	VOL_TEMP1, upsw
	nop
	nop
	wr_special	upsw, VOL_TEMP1, $0
	rd_special	VOL_TEMP1, swp
	nop
	nop
	wr_special	swp, VOL_TEMP1, $0
	rd_insert	VOL_TEMP1 
	nop
	nop
	wr_insert	VOL_TEMP1
		/*
		 * Little hack to see if pnum in kpsw is bad. 
		 */
		extract	VOL_TEMP1,KPSW_REG,$3
		GET_PNUM_FROM_BOARD(VOL_TEMP2)
		cmp_trap  ne,VOL_TEMP2,VOL_TEMP1,$2
	wr_kpsw		KPSW_REG, $0
	invalidate_ib
	return_trap	NEXT_PC_REG, $0
	Nop

cmpTrap_BadUserTrap:
	/*
	 * Error handling user traps.
	 */
	add_nt		OUTPUT_REG1, r0, $MACH_BAD_TRAP_TYPE
	jump		UserErrorTrap
	Nop

cmpTrap_BadTrapType:
	/*
	 * A trap type greater than the maximum value was specified.  If
	 * in kernel mode call the debugger.  Otherwise call the user error
	 * routine.
	 */
	and		VOL_TEMP2, KPSW_REG, $MACH_KPSW_PREV_MODE
	cmp_br_delayed	eq, VOL_TEMP2, $0, cmpTrap_KernError
	Nop
	or		VOL_TEMP1, KPSW_REG, $MACH_KPSW_ALL_TRAPS_ENA
	wr_kpsw		VOL_TEMP1, $0
	add_nt		OUTPUT_REG1, r0, $MACH_BAD_TRAP_TYPE
	invalidate_ib
	call		_MachUserError
	Nop
	jump		ReturnTrap
	Nop

cmpTrap_KernError:
	CALL_DEBUGGER(r0, MACH_BAD_TRAP_TYPE)

/*
 *----------------------------------------------------------------------------
 *
 * BreakpointTrap --
 *
 *	Handle a breakpoint trap.
 *
 *----------------------------------------------------------------------------
 */
BreakpointTrap:
	/*
	 * We just took a breakpoint trap.  If this is a user trap then 
	 * call the user error routine.  Otherwise call the kernel debugger.
	 */
	and		VOL_TEMP1, KPSW_REG, $MACH_KPSW_PREV_MODE
	cmp_br_delayed	eq, VOL_TEMP1, $0, breakpoint_KernBP
	Nop
	/*
	 * Enable all traps and call the user error routine.
	 */
	or		VOL_TEMP1, KPSW_REG, $MACH_KPSW_ALL_TRAPS_ENA
	wr_kpsw		VOL_TEMP1, $0
	add_nt		OUTPUT_REG1, r0, $MACH_BREAKPOINT
	rd_insert	VOL_TEMP1
	invalidate_ib
	call		_MachUserError
	Nop
	wr_insert	VOL_TEMP1
	/*
	 * Do a return from trap.
	 */
	jump		ReturnTrap
	Nop

breakpoint_KernBP:
	CALL_DEBUGGER(r0, MACH_BREAKPOINT);

/*
 *----------------------------------------------------------------------------
 *
 * SingleStepTrap --
 *
 *	Handle a single step trap.
 *
 *----------------------------------------------------------------------------
 */
SingleStepTrap:
	/*
	 * We just took a single step trap.  If this is a user trap then 
	 * call the user error routine.  Otherwise call the kernel debugger.
	 */
	and		VOL_TEMP1, KPSW_REG, $MACH_KPSW_PREV_MODE
	cmp_br_delayed	eq, VOL_TEMP1, $0, singleStep_KernSS
	Nop
	/*
	 * Enable all traps and call the user error routine.
	 */
	or		VOL_TEMP1, KPSW_REG, $MACH_KPSW_ALL_TRAPS_ENA
	wr_kpsw		VOL_TEMP1, $0
	add_nt		OUTPUT_REG1, r0, $MACH_SINGLE_STEP
	rd_insert	VOL_TEMP1
	invalidate_ib
	call		_MachUserError
	Nop
	wr_insert	VOL_TEMP1
	/*
	 * Do a return from trap.
	 */
	jump		ReturnTrap
	Nop

singleStep_KernSS:
	CALL_DEBUGGER(r0, MACH_SINGLE_STEP);

/*
 *----------------------------------------------------------------------------
 *
 * CallDebuggerTrap --
 *
 *	Handle a call debugger trap.
 *
 *----------------------------------------------------------------------------
 */
CallDebuggerTrap:
	/*
	 * We just took a breakpoint trap.  If this is a user trap then 
	 * call the user error routine.  Otherwise call the kernel debugger.
	 */
	and		VOL_TEMP1, KPSW_REG, $MACH_KPSW_PREV_MODE
	cmp_br_delayed	eq, VOL_TEMP1, $0, callDebugger_KernBP
	Nop
	/*
	 * Enable all traps and call the user error routine.
	 */
	or		VOL_TEMP1, KPSW_REG, $MACH_KPSW_ALL_TRAPS_ENA
	wr_kpsw		VOL_TEMP1, $0
	add_nt		OUTPUT_REG1, r0, $MACH_CALL_DEBUGGER
	rd_insert	VOL_TEMP1
	invalidate_ib
	call		_MachUserError
	Nop
	wr_insert	VOL_TEMP1
	/*
	 * Do a return from trap.
	 */
	jump		ReturnTrap
	Nop

callDebugger_KernBP:
	add_nt		CUR_PC_REG, NEXT_PC_REG, $0
	add_nt		NEXT_PC_REG, r0, $0
	CALL_DEBUGGER(r0, MACH_CALL_DEBUGGER);

/*
 *----------------------------------------------------------------------------
 *
 * SysCallTrap -
 *
 *	Handle a system call trap.
 *
 *----------------------------------------------------------------------------
 */
SysCallTrap:
	/* 
	 * Enable all traps.
	 */
	or		VOL_TEMP1, KPSW_REG, $MACH_KPSW_ALL_TRAPS_ENA
	wr_kpsw		VOL_TEMP1, $0
	/*
	 * Get the type of system call.  It was stored in the callers 
	 * r16 before they trapped.
	 */
	LD_MACH_CUR_STATE_PTR(SAFE_TEMP1)
	Nop
	ld_32		SAFE_TEMP2, SAFE_TEMP1, $(MACH_TRAP_REGS_OFFSET + (8 * 16))
	/*
	 * Check number of kernel call for validity.
	 */
	ld_32		VOL_TEMP1, r0, $_machMaxSysCall
	Nop
	cmp_br_delayed	ule, SAFE_TEMP2, VOL_TEMP1, sysCallTrap_FetchArgs
	Nop
	/*
	 * Bad kernel call.  Take a user error and then do a normal return
	 * from trap.
	 */
	add_nt		OUTPUT_REG1, r0, $MACH_BAD_SYS_CALL
	invalidate_ib
	call		_MachUserError
	Nop
	jump		ReturnTrap
	Nop

sysCallTrap_FetchArgs:
	/*
	 * This is a good system call.  Fetch the arguments.  The first 5
	 * come from the input registers and the rest from the spill
	 * stack.  First fetch the first 5 regardless whether we need them
	 * or not since its so cheap.
	 */
	add_nt		OUTPUT_REG1, INPUT_REG1, $0
	add_nt		OUTPUT_REG2, INPUT_REG2, $0
	add_nt		OUTPUT_REG3, INPUT_REG3, $0
	add_nt		OUTPUT_REG4, INPUT_REG4, $0
	add_nt		OUTPUT_REG5, INPUT_REG5, $0
	/*
	 * Now find out how many args there truly are which is
	 *
	 * 	int numArgs = machNumArgs[sys_call_type]
	 *
	 * For this code the registers are used in the following way:
	 *
	 *	SAFE_TEMP1:	machCurStatePtr
	 *	SAFE_TEMP2:	sysCallType
	 *	SAFE_TEMP3:	numArgs
	 *	VOL_TEMP1:	user stack pointer
	 *	VOL_TEMP2:	sysCallType * 4
	 */
	ld_32		VOL_TEMP3, r0, $numArgsPtr
	Nop
	sll		VOL_TEMP2, SAFE_TEMP2, $2
	ld_32		SAFE_TEMP3, VOL_TEMP3, VOL_TEMP2
	Nop
	/*
	 * If num args is less than or equal to 5 then we are done.
	 */
	cmp_br_delayed	le, SAFE_TEMP3, $5, sysCallTrap_CallRoutine
	Nop
	/*
	 * Haven't fetched enough args so we have to copy them from the user's
	 * spill stack to the kernel's spill stack.  Set VOL_TEMP1 to be
	 * the user stack pointer + (numArgs - 5) * 8 to point to the base
	 * of the arguments on the spill stack.
	 */
	ld_32		VOL_TEMP1, SAFE_TEMP1, $(MACH_TRAP_REGS_OFFSET + (8 * MACH_SPILL_SP))
	sub		VOL_TEMP3, SAFE_TEMP3, $5
	sll		VOL_TEMP3, VOL_TEMP3, $3
	add		VOL_TEMP1, VOL_TEMP1, VOL_TEMP3
	/*
	 * Move back the kernel's spill sp to cover the args that we are
	 * about to copy onto it. 
	 */
	add_nt		NON_INTR_TEMP1, SPILL_SP, $0
	sub		SPILL_SP, SPILL_SP, VOL_TEMP3
	/*
	 * Now fetch the args.  This code fetches up to 7 more args by jumping
	 * into the right spot in the sequence.  The spot to jump is 
	 * equal to 16 * (12 - numArgs) where 16 is the number of bytes
	 * required for each move of data.  For the following code
	 * the register conventions are:
	 *
	 *	SAFE_TEMP1:	machCurStatePtr
	 *	SAFE_TEMP2:	sysCallType
	 *	SAFE_TEMP3:	(12 - numArgs) * 16
	 *	VOL_TEMP1:	User spill SP
	 *	VOL_TEMP2:	Temporary.
	 *	VOL_TEMP3:	Spill stack size.
	 *	NON_INTR_TEMP1:	Kernel SP
	 */
	add_nt		VOL_TEMP2, r0, $12
	sub		SAFE_TEMP3, VOL_TEMP2, SAFE_TEMP3
	sll		SAFE_TEMP3, SAFE_TEMP3, $3
	sll		SAFE_TEMP3, SAFE_TEMP3, $1
	rd_special	VOL_TEMP2, pc
	add_nt		VOL_TEMP2, SAFE_TEMP3, VOL_TEMP2
	jump_reg	VOL_TEMP2, $16
	Nop
	.globl	_MachFetchArgStart
_MachFetchArgStart:
	ld_32		VOL_TEMP2, VOL_TEMP1, $-56	/* 7 args */
	Nop
	st_32		VOL_TEMP2, NON_INTR_TEMP1, $-56
	Nop
	ld_32		VOL_TEMP2, VOL_TEMP1, $-48	/* 6 args */
	Nop
	st_32		VOL_TEMP2, NON_INTR_TEMP1, $-48
	Nop
	ld_32		VOL_TEMP2, VOL_TEMP1, $-40	/* 5 args */
	Nop
	st_32		VOL_TEMP2, NON_INTR_TEMP1, $-40
	Nop
	ld_32		VOL_TEMP2, VOL_TEMP1, $-32	/* 4 args */
	Nop
	st_32		VOL_TEMP2, NON_INTR_TEMP1, $-32
	Nop
	ld_32		VOL_TEMP2, VOL_TEMP1, $-24	/* 3 args */
	Nop
	st_32		VOL_TEMP2, NON_INTR_TEMP1, $-24
	Nop
	ld_32		VOL_TEMP2, VOL_TEMP1, $-16	/* 2 args */
	Nop
	st_32		VOL_TEMP2, NON_INTR_TEMP1, $-16
	Nop
	ld_32		VOL_TEMP2, VOL_TEMP1, $-8	/* 1 arg */
	Nop
	st_32		VOL_TEMP2, NON_INTR_TEMP1, $-8
	Nop
	.globl _MachFetchArgEnd
_MachFetchArgEnd:

sysCallTrap_CallRoutine:
	/*
	 * Now call the routine to handle the system call.  We do this
	 * by jumping through 
	 *
	 *	(proc_RunningProcesses[pnum]->kcallTable[sysCallType])()
	 */

	/* 
	 * VOL_TEMP3 <= proc_RunningProccesses[pnum]
	 */
	LD_CURRENT_PCB_PTR(VOL_TEMP3)
	/*
	 * VOL_TEMP2 <= offset of kcall table pointer in PCB
	 */
	ld_32		VOL_TEMP2, r0, $_machKcallTableOffset
	Nop						
	/*
	 * VOL_TEMP2 <= pointer to Oth entry in kcall table
	 */
	add_nt		VOL_TEMP3, VOL_TEMP3, VOL_TEMP2
	ld_32		VOL_TEMP2, VOL_TEMP3, $0
	Nop
	/*
	 * Call the routine.  Note that SPUR doesn't have a call_reg 
	 * instruction.  This forces us to advance the window by a call
	 * and then do a jump_reg.  Unfortunately this means that we can't use
	 * any temporaries in the current window so we have to use a global.
	 * The global that we use is r9.  However, since we restore user
	 * state before we return to user mode r9 will get restored.
	 */
	sll		VOL_TEMP3, SAFE_TEMP2, $2
	ld_32		r9, VOL_TEMP2, VOL_TEMP3
	Nop
	invalidate_ib
	call		1f
	Nop
1:
	rd_special	RETURN_ADDR_REG, pc
	add_nt		RETURN_ADDR_REG, RETURN_ADDR_REG, $8
	jump_reg	r9, $0
	Nop

SysCall_Return:
	/*
	 * Now we are back from the system call handler.  Store the return
	 * value into the return val reg for the parent, restore the kernels
	 * stack pointer and the kpsw and then do a normal return from
	 * trap.
	 */
	st_32		RETURN_VAL_REG, SAFE_TEMP1, $(MACH_TRAP_REGS_OFFSET + (8 * MACH_RETURN_VAL_REG))
	ld_32		SPILL_SP, SAFE_TEMP1, $MACH_KERN_STACK_END_OFFSET
	Nop
	add_nt		RETURN_VAL_REG, r0, $MACH_NORM_RETURN
	jump		ReturnTrap
	Nop

/*
 *----------------------------------------------------------------------------
 *
 * UserErrorTrap -
 *
 *	Handle a user error trap.  Before we were called the old CUR_PC_REG 
 *	and NEXT_PC_REG were saved in NON_INTR_TEMP2 and NON_INTR_TEMP3 
 *	respectively and the error type was stored in OUTPUT_REG1.
 *
 *----------------------------------------------------------------------------
 */
UserErrorTrap:
	add_nt		CUR_PC_REG, NON_INTR_TEMP1, $0
	add_nt		NEXT_PC_REG, NON_INTR_TEMP2, $0
	LD_MACH_CUR_STATE_PTR(VOL_TEMP1)
	Nop
	st_32		CUR_PC_REG, VOL_TEMP1, $MACH_TRAP_CUR_PC_OFFSET
	st_32		NEXT_PC_REG, VOL_TEMP1, $MACH_TRAP_NEXT_PC_OFFSET
	/*
	 * Enable all traps.
	 */
	or		VOL_TEMP1, KPSW_REG, $MACH_KPSW_ALL_TRAPS_ENA
	wr_kpsw		VOL_TEMP1, $0
	/*
	 * Call the user error handler.
	 */
	rd_insert	VOL_TEMP1
	invalidate_ib
	call		_MachUserError
	Nop
	wr_insert	VOL_TEMP1
	/*
	 * Do a normal return from trap.
	 */
	jump		ReturnTrap
	Nop

/*
 *----------------------------------------------------------------------------
 *
 * SigReturnTrap -
 *
 *	Return from signal trap.  The previous window contains
 *	the saved info when we called the signal handler.  Note that we
 *	have not switched to the kernel's stacks.  This is because we
 *	need to go back one window before we save user state.
 *
 *----------------------------------------------------------------------------
 */
sigReturnTrap_Const1:
	.long MACH_KPSW_USE_CUR_PC
SigReturnTrap:
	/*
	 * Switch over to the kernel stacks after saving the user's spill sp
	 * and the kpsw.  We don't need to save any other state because we
	 * will restore it from off of the user's spill stack.  We save the
	 * kpsw because we can't trust the kpsw on the user's stack.
	 */
	LD_MACH_CUR_STATE_PTR(VOL_TEMP1)
	Nop
	st_32		SPILL_SP, VOL_TEMP1, $(MACH_TRAP_REGS_OFFSET + (8 * 4))
	st_32		KPSW_REG, VOL_TEMP1, $MACH_TRAP_KPSW_OFFSET
	wr_special	upsw, r0, $0
	SWITCH_TO_KERNEL_STACKS()
	/*
	 * Reenable traps and call the routine to handle returns from 
	 * signals.
	 */
	or		VOL_TEMP1, KPSW_REG, $MACH_KPSW_ALL_TRAPS_ENA
	wr_kpsw		VOL_TEMP1, $0
	invalidate_ib
	call		_MachSigReturn
	Nop

	jump		ReturnTrap
	Nop


/*
 *----------------------------------------------------------------------------
 *
 * GetWinMemTrap --
 *
 *	Get more memory for the window stack.  The current and next PCs were
 *	stored in NON_INTR_TEMP1 and NON_INTR_TEMP2 respectively before
 *	we were trapped to.
 *
 *----------------------------------------------------------------------------
 */
getWinMemTrap_Const1:
	.long	MACH_KPSW_USE_CUR_PC
GetWinMemTrap:
	/*
	 * Enable all traps.
	 */
	or		VOL_TEMP1, KPSW_REG, $MACH_KPSW_ALL_TRAPS_ENA
	wr_kpsw		VOL_TEMP1, $0
	/*
	 * Call _MachGetWinMem()
	 */
	 invalidate_ib
	call		_MachGetWinMem
	Nop
	/*
	 * Store the current and next PCs into the saved state for this
	 * process because the ReturnTrap will restore the user state.
	 * Also store the kpsw that indicates that we should
	 * return to the current PC instead of the next one.
	 */

	LD_MACH_CUR_STATE_PTR(SAFE_TEMP1)
	Nop
	st_32		NON_INTR_TEMP1, SAFE_TEMP1, $MACH_TRAP_CUR_PC_OFFSET
	st_32		NON_INTR_TEMP2, SAFE_TEMP1, $MACH_TRAP_NEXT_PC_OFFSET
	LD_PC_RELATIVE(SAFE_TEMP2, getWinMemTrap_Const1)
	or		KPSW_REG, KPSW_REG, SAFE_TEMP2
	st_32		KPSW_REG, SAFE_TEMP1, $MACH_TRAP_KPSW_OFFSET
	/*
	 * Do a normal return from trap.
	 */
	add_nt		RETURN_VAL_REG, r0, $MACH_NORM_RETURN
	jump		ReturnTrap
	Nop

/*
 *----------------------------------------------------------------------------
 *
 * SpecialUserTraps --
 *
 *	Handle special user traps.  The compare trap type was passed in
 *	register SAFE_TEMP1.  There are three types of traps:
 *	
 *	1) Return from user trap hander trap
 *	2) One of FPU, illegal, fixnum and overflow
 *	3) Compare traps.
 *
 *----------------------------------------------------------------------------
 */

SpecialUserTraps:
	/*
	 * The trap to return from a user trap hander is handled differently
	 * then the other special user traps.
	 */
	cmp_br_delayed	eq, SAFE_TEMP1, $MACH_USER_RET_TRAP_TRAP, UserRetTrapTrap
	nop
	/*
	 * On the four traps that happened in user mode we stored the
	 * current pc and next pc in the temporaries and then we trapped
	 * back into the kernel.
	 */
	cmp_br_delayed	gt, SAFE_TEMP1, $MACH_USER_OVERFLOW_TRAP, 1f
	nop
	add_nt		CUR_PC_REG, NON_INTR_TEMP1, $0
	add_nt		NEXT_PC_REG, NON_INTR_TEMP2, $0
1:
/*
 * Recover the operands of the trapping instruction 
 */

	/*
	 * Enable traps and fetch the current instruction.  We have to
	 * enable all traps because fetching the instruction could cause
	 * a fault.
	 */
	or		VOL_TEMP1, KPSW_REG, $MACH_KPSW_ALL_TRAPS_ENA
	/*
	 * Leave all traps enabled but disable interrupts because are going
	 * to be mucking register windows in ParseInstruction
	 */
	and		VOL_TEMP1, VOL_TEMP1, $~MACH_KPSW_INTR_TRAP_ENA
	wr_kpsw		VOL_TEMP1, $0
	ld_32		VOL_TEMP2, CUR_PC_REG, $0
	
	rd_special	VOL_TEMP1, pc
	add_nt		VOL_TEMP1, VOL_TEMP1, $16
	jump		ParseInstruction
	nop
	/*
	 * We now have the operands.  Switch back to user mode.
	 */
	or		KPSW_REG, KPSW_REG, $(MACH_KPSW_CUR_MODE|MACH_KPSW_ALL_TRAPS_ENA)
	wr_kpsw		KPSW_REG, $0
	/*
	 * We are now in user mode so we can determine what trap handler
	 * to call for this trap.  We already have the trap type in
	 * SAFE_TEMP1.  Now we want to determine the traps offset into the
	 * trap table.  The first four entries of the table are for
	 * fpu, illegal, fixnum and overflow exceptions.  The following
	 * entry is the first compare trap type.  The following code
	 * sets SAFE_TEMP1 to be equal to the index into the trap table for
	 * the given trap type.
	 */
	add_nt		SAFE_TEMP2, SAFE_TEMP1, $0
	cmp_br_delayed	gt, SAFE_TEMP1, $MACH_USER_OVERFLOW_TRAP, 1f
	nop
	/*
	 * This is one of the 4 traps in addition to the compare traps.
	 */
	sub		SAFE_TEMP1, SAFE_TEMP1, $MACH_USER_FPU_EXCEPT_TRAP
	jump		2f
	nop
1:
	/* 
	 * We have a compare trap.
	 */
	add_nt		VOL_TEMP1, r0, $MACH_LAST_USER_CMP_TRAP
	cmp_br_delayed	gt, SAFE_TEMP1, VOL_TEMP1, specialUserTraps_Error
	nop
	add_nt		VOL_TEMP1, r0, $MACH_FIRST_USER_CMP_TRAP
	cmp_br_delayed	lt, SAFE_TEMP1, VOL_TEMP1, specialUserTraps_Error
	nop
	sub		SAFE_TEMP1, SAFE_TEMP1, $(MACH_FIRST_USER_CMP_TRAP - MACH_NUM_OTHER_USER_TRAPS)

2:
	/*
	 * Attempt to call the trap handler.  We do this by getting 
	 * a pointer to the trap table and then looking at the handler there.
	 * If the handler is non-zero then it is a valid handler.  Otherwise
	 * we have a bad user trap type.
	 */
	LD_MACH_CUR_STATE_PTR(VOL_TEMP1)
	ld_32		VOL_TEMP2, r0, $_machTrapTableOffset
	ld_32		VOL_TEMP1, VOL_TEMP1, $MACH_SPEC_PAGE_ADDR_OFFSET
	nop
	add		VOL_TEMP1, VOL_TEMP1, VOL_TEMP2
	/*
	 * VOL_TEMP1 now contains the address of the base of the trap table.
	 * See if there is anything to call.  Each entry is 8 bytes long
	 * so we shift SAFE_TEMP1 (the trap table index) by 3 to get the
	 * trap table offset.
	 */
	sll		SAFE_TEMP1, SAFE_TEMP1, $3
	ld_32		SAFE_TEMP1, VOL_TEMP1, SAFE_TEMP1
	Nop
	cmp_br_delayed	eq, SAFE_TEMP1, $0, specialUserTraps_Error
	nop
	/*
	 * We now know that we have a good handler to call.  Set up
	 * the args and call it.  We call the routine as:
	 *
	 *	Handler(curPC, nextPC, opcode, destReg, operands)
	 *	
	 * where operands is a pointer to the stack and the two 
	 * source operands.  
	 */
	add_nt		r25,SPILL_SP,$0              /* Follow C protocol */
	add_nt		OUTPUT_REG5,SAFE_TEMP1,$0    /* Put the handle
							pointer where we 
	                                                can get at it.  */
	add_nt		SPILL_SP, SPILL_SP, $-16      /* Make room on stack */

	st_40		OUTPUT_REG3, SPILL_SP, $0    /* First operand */
	st_40		OUTPUT_REG4, SPILL_SP, $8    /* Second operand */
	add_nt		OUTPUT_REG3, OUTPUT_REG1,$0  /* opcode */
	add_nt		OUTPUT_REG4, OUTPUT_REG2,$0  /* destReg */
	add_nt		OUTPUT_REG1, CUR_PC_REG, $0
	add_nt		OUTPUT_REG2, NEXT_PC_REG, $0
	invalidate_ib
	call		@@touserf
	nop
@@touser: 
	jump_reg	INPUT_REG5, $0
	add_nt		INPUT_REG5, SPILL_SP, $0


specialUserTraps_Error:
	/*
	 * We got an error trying to call the trap handler.  Trap back
	 * into the kernel after shifting our window back to the original
	 * window that we were executing in so we reenter kernel in a normal 
	 * trap state.  Since we are shifting our window back and we don't 
	 * want to lose the current and next PC's we put those in the
	 * non-intr-temp registers so they don't get trashed in case
	 * an interrupt sneaks in.
	 */
	add_nt		SPILL_SP, SPILL_SP, $-16
	st_32		SAFE_TEMP2, SPILL_SP, $0   /* Save the trap type */
	add_nt		NON_INTR_TEMP1, CUR_PC_REG, $0
	add_nt		NON_INTR_TEMP2, NEXT_PC_REG, $0
	invalidate_ib
	rd_special	VOL_TEMP1, pc
	return		VOL_TEMP1, $12
	nop
	/*
	 * We use r1 as the trap type.  Since we are in the window that 
	 * caused the error we can't use a local.
	 */
	st_40		r1, SPILL_SP, $8
	ld_32		r1, SPILL_SP, $0  /* Get the trap type back */
	/* 
	 * Set our first output register to the type of error and trap.
	 */
	nop
	cmp_br_delayed	ne, r1, $MACH_USER_FPU_EXCEPT_TRAP, 1f
	nop
	ld_40		r1, SPILL_SP, $8
	add_nt		SPILL_SP, SPILL_SP, $16
	cmp_trap	always, r0, r0, $MACH_FPU_ERROR_TRAP
1:
	cmp_br_delayed	ne, r1, $MACH_USER_ILLEGAL_TRAP, 1f
	nop
	ld_40		r1, SPILL_SP, $8
	add_nt		SPILL_SP, SPILL_SP, $16
	cmp_trap	always, r0, r0, $MACH_ILLEGAL_ERROR_TRAP
1:
	cmp_br_delayed	ne, r1, $MACH_USER_FIXNUM_TRAP, 1f
	nop
	ld_40		r1, SPILL_SP, $8
	add_nt		SPILL_SP, SPILL_SP, $16
	cmp_trap	always, r0, r0, $MACH_FIXNUM_ERROR_TRAP
1:
	cmp_br_delayed	ne, r1, $MACH_USER_OVERFLOW_TRAP, 1f
	nop
	ld_40		r1, SPILL_SP, $8
	add_nt		SPILL_SP, SPILL_SP, $16
	cmp_trap	always, r0, r0, $MACH_OVERFLOW_ERROR_TRAP
1:
	ld_40		r1, SPILL_SP, $8
	add_nt		SPILL_SP, SPILL_SP, $16
	cmp_trap	always, r0, r0, $MACH_CMP_TRAP_ERROR_TRAP

/*
 *----------------------------------------------------------------------------
 *
 * UserRetTrapTrap --
 *
 *	Return a value from a user trap handler.  We were passed the value
 *	to return in INPUT_REG1, the first pc in INPUT_REG2, the next pc in 
 *	INPUT_REG3 and the register to set in INPUT_REG4.  The window
 *	that we want to put the value in is three windows back.
 *
 *----------------------------------------------------------------------------
 */
UserRetTrapTrap:
	/*
	 * Enable all traps and disable interrupts so that we can pop a few
	 * windows.
	 */
	or		VOL_TEMP1, KPSW_REG, $MACH_KPSW_ALL_TRAPS_ENA
	and		VOL_TEMP1, VOL_TEMP1, $~MACH_KPSW_INTR_TRAP_ENA
	wr_kpsw		VOL_TEMP1, $0
	/*
	 * Pop the first window.  This will get us back into the window that
	 * the trap handler was executing in.
	 */
	invalidate_ib
	rd_special	VOL_TEMP1, pc
	return		VOL_TEMP1, $12
	nop
	/*
	 * Move our 4 values into our input registers and go back yet another
	 * window.
	 */
	add_nt		INPUT_REG1, OUTPUT_REG1, $0
	add_nt		INPUT_REG2, OUTPUT_REG2, $0
	add_nt		INPUT_REG3, OUTPUT_REG3, $0
	add_nt		INPUT_REG4, OUTPUT_REG4, $0
	rd_special	VOL_TEMP1, pc
	return		VOL_TEMP1, $12
	nop
	/*
	 * Now we are in the window after the one where the trap occured.  
	 * Store to the register in the previous window.  r9 is the value
	 * to set and r1 is the register to set.
	 */
	add_nt		VOL_TEMP1, r9, $0
	add_nt		VOL_TEMP2, r1, $0
	add_nt		r9, OUTPUT_REG1, $0
	add_nt		r1, OUTPUT_REG4, $0
	rd_special	VOL_TEMP3, pc
	return		VOL_TEMP3, $12
	nop
	sll		r1, r1, $2
	jump_reg	r1, $SetReg	
	jump		1f
1:
	/*
	 * Go back to the current next window.
	 */
	 invalidate_ib
	call		1f
	nop
1:
	add_nt		r9, VOL_TEMP1, $0
	add_nt		r1, VOL_TEMP2, $0
	/*
	 * We now can finally do a normal return.   If the next PC
	 * (OUTPUT_REG3) is zero then return to just the current PC.
	 */
	rd_kpsw		VOL_TEMP1
	or		VOL_TEMP1, VOL_TEMP1, $(MACH_KPSW_INTR_TRAP_ENA|MACH_KPSW_CUR_MODE)
	wr_kpsw		VOL_TEMP1, $0
	cmp_br_delayed	eq, OUTPUT_REG3, $0, 1f
	invalidate_ib
	jump_reg	OUTPUT_REG2, $0
	return		OUTPUT_REG3, $0
1:
	return		OUTPUT_REG2, $0
	nop

/*
 *----------------------------------------------------------------------------
 *
 * ReturnTrap -
 *
 *	Return from a trap handler.  We are called with all traps disabled
 *	and if we are a user process then we are running on the kernel's spill
 *	statck.   Assume that the type of return to do has been stored in
 *	RETURN_VAL_REG.  If it is not one of MACH_NORM_RETURN,
 *	MACH_FAILED_COPY or MACH_FAILED_ARG_FETCH then it is a kernel error
 *	value.
 *
 *----------------------------------------------------------------------------
 */
returnTrap_Const1:
	.long	MACH_KPSW_USE_CUR_PC

ReturnTrap:
	/*
	 * Restore the kpsw to that which we trapped with. Insure that the
	 * processor number field is correct.
	 */
	rd_kpsw		VOL_TEMP1
	extract		VOL_TEMP1,VOL_TEMP1,$3
	wr_insert	$3
	insert		KPSW_REG,KPSW_REG,VOL_TEMP1
	wr_kpsw		KPSW_REG, $0

	/*
	 * Check the return code from the fault handler.
	 */
	cmp_br_delayed	eq, RETURN_VAL_REG, $MACH_NORM_RETURN, returnTrap_NormReturn
	Nop
	cmp_br_delayed	eq, RETURN_VAL_REG, $MACH_FAILED_COPY, returnTrap_FailedCopy
	Nop
	cmp_br_delayed	eq, RETURN_VAL_REG, $MACH_FAILED_ARG_FETCH, returnTrap_FailedArgFetch
	Nop
	CALL_DEBUGGER(RETURN_VAL_REG, 0)

returnTrap_NormReturn:
	/*
	 * If we are not returning to user mode then just return.
	 */
	and		VOL_TEMP1, KPSW_REG, $MACH_KPSW_PREV_MODE
	cmp_br_delayed	eq, VOL_TEMP1, r0, returnTrap_Return
	Nop
	/*
	 * See if we have to take any special action for this process.
	 * This is determined by looking at 
	 * proc_RunningProcesses[pnum]->specialHandling.
	 */
	LD_CURRENT_PCB_PTR(VOL_TEMP3)
	ld_32		VOL_TEMP2, r0, $_machSpecialHandlingOffset
	Nop
	add_nt		VOL_TEMP3, VOL_TEMP3, VOL_TEMP2
	ld_32		VOL_TEMP3, VOL_TEMP3, $0
	Nop
	cmp_br_delayed	ne, VOL_TEMP3, $0, returnTrap_SpecialAction
	Nop
	/*
	 * See if we have to allocate more memory on the saved window
	 * stack.
	 */
	LD_MACH_CUR_STATE_PTR(VOL_TEMP1)
	Nop
        ld_32           VOL_TEMP2, VOL_TEMP1, $MACH_MAX_SWP_OFFSET
	ld_32		VOL_TEMP3, VOL_TEMP1, $MACH_TRAP_SWP_OFFSET
        sub             VOL_TEMP2, VOL_TEMP2, $(2 * MACH_SAVED_REG_SET_SIZE)
        cmp_br_delayed  ule, VOL_TEMP3, VOL_TEMP2, returnTrap_UserReturn
        Nop
        /*
         * Allocate more memory.
         */
	or              VOL_TEMP1, KPSW_REG, $MACH_KPSW_ALL_TRAPS_ENA
	wr_kpsw         VOL_TEMP1, $0
	invalidate_ib
	call		_MachGetWinMem
	nop
	add_nt		RETURN_VAL_REG, r0, $MACH_NORM_RETURN
	jump		ReturnTrap
	nop

returnTrap_UserReturn:
	/*
	 * Restore the user's state and put us back into user mode.
	 */
	RESTORE_USER_STATE()
	/*
	 * Put us back into user mode.
	 */
	or		KPSW_REG, KPSW_REG, $MACH_KPSW_CUR_MODE

returnTrap_Return:
	or		KPSW_REG, KPSW_REG, $MACH_KPSW_ALL_TRAPS_ENA
	wr_kpsw		KPSW_REG, $0
	/*
	 * If we are supposed to return to the next PC then set the current
	 * PC to the next PC and clear the next PC so that the return
	 * happens correctly.
	 */
	LD_PC_RELATIVE(VOL_TEMP2, returnTrap_Const1)
	and		VOL_TEMP1, KPSW_REG, VOL_TEMP2
	cmp_br_delayed	eq, VOL_TEMP1, VOL_TEMP2, 1f
	Nop
	add_nt		CUR_PC_REG, NEXT_PC_REG, $0
	add_nt		NEXT_PC_REG, r0, $0
1:
	/*
	 * If the 2nd PC in NEXT_PC_REG is zero then 
	 * we don't do the jump to the 2nd PC because there is none.
	 */
	cmp_br_delayed	eq, NEXT_PC_REG, $0, returnTrap_No2ndPC
	Nop
#ifdef PATCH_IBUFFER
	add_nt		SAFE_TEMP1, CUR_PC_REG, $0
	add_nt		CUR_PC_REG, r0, $0
	invalidate_ib
	jump_reg	SAFE_TEMP1, $0
#else
	jump_reg	CUR_PC_REG, $0
#endif
	return		NEXT_PC_REG, $0

returnTrap_No2ndPC:
#ifdef PATCH_IBUFFER
	add_nt		SAFE_TEMP1, CUR_PC_REG, $0
	add_nt		CUR_PC_REG, r0, $0
	invalidate_ib
	return		SAFE_TEMP1, $0
#else
	invalidate_ib
	return		CUR_PC_REG, $0
#endif
	Nop

/*
 * returnTrap_FailedCopy --
 *
 *	A copy to/from user space failed.
 */
returnTrap_FailedCopy:
	/*
	 * Enable all traps, go back to the previous window and return an
	 * error to the caller.
	 */
#ifdef PATCH_IBUFFER
	add_nt		CUR_PC_REG, r0, $0
#endif
	or		VOL_TEMP1, KPSW_REG, $MACH_KPSW_ALL_TRAPS_ENA
	wr_kpsw		VOL_TEMP1, $0
	invalidate_ib
	rd_special	VOL_TEMP1, pc
	return		VOL_TEMP1, $12
	Nop
	/*
	 * The error to return is 0x20000 for SYS_ARG_NOACCESS.  Since we only
	 * have 14 bits of immediate we have to insert a 2 into the 3rd byte.
	 */
	add_nt		RETURN_VAL_REG_CHILD, r0, $0
	rd_insert	VOL_TEMP1
	wr_insert	$2
	insert		RETURN_VAL_REG_CHILD, r0, $2
	wr_insert	VOL_TEMP1
	/*
	 * The spill stack before the call was stored in r25.  Restore the
	 * spill SP and then do a normal return.
	 */
	add_nt		SPILL_SP, r25, $0
	invalidate_ib
	return		RETURN_ADDR_REG, $8
	Nop

/*
 * returnTrap_FailedArgFetch --
 *
 *	The fetching of the user's args during a system call failed.
 */
returnTrap_FailedArgFetch:
	/*
	 * Enable all traps and go back to the previous window.
	 */
#ifdef PATCH_IBUFFER
	add_nt		CUR_PC_REG, r0, $0
#endif
	or		VOL_TEMP1, KPSW_REG, $MACH_KPSW_ALL_TRAPS_ENA
	wr_kpsw		VOL_TEMP1, $0
	invalidate_ib
	rd_special	VOL_TEMP1, pc
	return		VOL_TEMP1, $12
	Nop
	/*
	 * We are now back in the window that was doing the arg fetch.  Set
	 * the return value to SYS_ARG_NOACCESS and then jump to the code
	 * that does the system call return.  The error to return is 0x20000
	 * for SYS_ARG_NOACCESS.  Since we only have 14 bits of immediate we
	 * have to insert a 2 into the 3rd byte.
	 */
	add_nt		RETURN_VAL_REG, r0, $0
	rd_insert	VOL_TEMP1
	wr_insert	$2
	insert		RETURN_VAL_REG, r0, $2
	wr_insert	VOL_TEMP1
	jump		SysCall_Return
	Nop

/*
 * returnTrap_SpecialAction --
 *
 *	Need to take some special action for this process before returning
 *	to user mode.
 */
returnTrap_SpecialAction:
	/*
	 * Reenable all traps and then call the routine 
	 * that tells us what action to take.
	 */
	or		VOL_TEMP1, KPSW_REG, $MACH_KPSW_ALL_TRAPS_ENA
	wr_kpsw		VOL_TEMP1, $0
	invalidate_ib
	call		_MachUserAction
	Nop
	/*
	 * The user action routine will return TRUE (1) if we should call
	 * a signal handler or FALSE (0) otherwise.
	 */
	cmp_br_delayed	eq, RETURN_VAL_REG, $1, returnTrap_CallSigHandler
	Nop
	add_nt		RETURN_VAL_REG, r0, $MACH_NORM_RETURN
	jump		ReturnTrap
	Nop

/*
 * returnTrap_CallSigHandler --
 *
 *	Need to start the process off calling a signal handler.  When we
 *	are called all traps have already been enabled.
 */
returnTrap_CallSigHandler:
	/*
 	 * Insure that KPSW_REG has the correct processor number in it
	 * by reading it from the current kpsw.
	 */
	rd_kpsw		VOL_TEMP1
	extract		VOL_TEMP1,VOL_TEMP1,$3
	wr_insert	$3
	insert		KPSW_REG,KPSW_REG,VOL_TEMP1
	/*
	 * See if we have to allocate more memory on the saved window
	 * stack.
	 */
	LD_MACH_CUR_STATE_PTR(SAFE_TEMP1)
	Nop
        ld_32           VOL_TEMP1, SAFE_TEMP1, $MACH_MAX_SWP_OFFSET
	ld_32		VOL_TEMP2, SAFE_TEMP1, $MACH_TRAP_SWP_OFFSET
        sub             VOL_TEMP1, VOL_TEMP1, $(2 * MACH_SAVED_REG_SET_SIZE)
        cmp_br_delayed  ule, VOL_TEMP2, VOL_TEMP1, 1f
        Nop
        /*
         * Allocate more memory.
         */
	 invalidate_ib
	call		_MachGetWinMem
	nop
1:
	/*
	 * Disable all traps and restore the user's state.
	 */
	wr_kpsw		KPSW_REG, $0
	RESTORE_USER_STATE()
	/*
	 * Pass the correct args to the signal handler:
	 *
	 *	Handler(sigNum, sigCode, contextPtr)
	 */
	ld_32		INPUT_REG1, SAFE_TEMP1, $MACH_SIG_NUM_OFFSET
	ld_32		INPUT_REG2, SAFE_TEMP1, $MACH_SIG_CODE_OFFSET
	add_nt		INPUT_REG3, SPILL_SP, $0
	/*
	 * Set the signal handler executing in user mode.
	 * Assume that the user's signal handler will do a "return r10,r0,8".
	 */
	ld_32		VOL_TEMP1, SAFE_TEMP1, $MACH_NEW_CUR_PC_OFFSET
	add_nt		RETURN_ADDR_REG, r0, $(SigReturnAddr-8)
	or		KPSW_REG, KPSW_REG, $(MACH_KPSW_CUR_MODE|MACH_KPSW_ALL_TRAPS_ENA)
	jump_reg	VOL_TEMP1, $0
	wr_kpsw		KPSW_REG, $0

/*
 *----------------------------------------------------------------------------
 *
 * SaveState -
 *
 *	Save the state of the process in the given state struct.  Also push
 *	all of the windows, except for the current one, onto the saved
 *	window stack.  VOL_TEMP1 contains where to save the state to and 
 *	VOL_TEMP2 contains the return address.  
 *
 *----------------------------------------------------------------------------
 */
SaveState:
	/*
	 * Save kpsw, upsw, insert register and the current and next PCs 
	 * of the fault.
	 */
	st_32		KPSW_REG, VOL_TEMP1, $MACH_REG_STATE_KPSW_OFFSET
	rd_special	VOL_TEMP3, upsw
	st_32		VOL_TEMP3, VOL_TEMP1, $MACH_REG_STATE_UPSW_OFFSET
	and		CUR_PC_REG, CUR_PC_REG, $~3
	st_32		CUR_PC_REG, VOL_TEMP1, $MACH_REG_STATE_CUR_PC_OFFSET
	and		NEXT_PC_REG, NEXT_PC_REG, $~3
	st_32		NEXT_PC_REG, VOL_TEMP1, $MACH_REG_STATE_NEXT_PC_OFFSET
	rd_insert	VOL_TEMP3
	st_32		VOL_TEMP3, VOL_TEMP1, $MACH_REG_STATE_INSERT_OFFSET
#ifdef	PATCH_IBUFFER	
	st_32		r26, VOL_TEMP1, $0
#endif
	/*
	 * Clear the upsw so that kernel wont get lisp traps.
	 */
	wr_special	upsw, r0, $0

	/*
	 * Save all of the globals.
	 */

 	st_40		r0, VOL_TEMP1, $MACH_REG_STATE_REGS_OFFSET+0
 	st_40		r1, VOL_TEMP1, $MACH_REG_STATE_REGS_OFFSET+8
 	st_40		r2, VOL_TEMP1, $MACH_REG_STATE_REGS_OFFSET+16
 	st_40		r3, VOL_TEMP1, $MACH_REG_STATE_REGS_OFFSET+24
 	st_40		r4, VOL_TEMP1, $MACH_REG_STATE_REGS_OFFSET+32
 	st_40		r5, VOL_TEMP1, $MACH_REG_STATE_REGS_OFFSET+40
 	st_40		r6, VOL_TEMP1, $MACH_REG_STATE_REGS_OFFSET+48
 	st_40		r7, VOL_TEMP1, $MACH_REG_STATE_REGS_OFFSET+56
 	st_40		r8, VOL_TEMP1, $MACH_REG_STATE_REGS_OFFSET+64
 	st_40		r9, VOL_TEMP1, $MACH_REG_STATE_REGS_OFFSET+72

	/*
	 * Move where to save to into a global.
	 */
	add_nt		r1, VOL_TEMP1, $0

	/*
	 * Now go back to the previous window.  Enable all traps and
	 * disable interrupts so that we can take a window underflow
	 * fault if necessary.
	 */

	rd_kpsw		r5
	or		VOL_TEMP3, r5, $MACH_KPSW_ALL_TRAPS_ENA
	and		VOL_TEMP3, VOL_TEMP3, $(~MACH_KPSW_INTR_TRAP_ENA)
	wr_kpsw		VOL_TEMP3, $0
	invalidate_ib
	rd_special	VOL_TEMP3, pc
	return		VOL_TEMP3, $12
	Nop
	and		r2, r5, $~MACH_KPSW_ALL_TRAPS_ENA
	wr_kpsw		r2, $0

	/*
	 * Now we are in the previous window.  Save all of its registers
	 * into the state structure.
	 */
	st_40		r10, r1, $MACH_REG_STATE_REGS_OFFSET+80
	st_40		r11, r1, $MACH_REG_STATE_REGS_OFFSET+88
 	st_40		r12, r1, $MACH_REG_STATE_REGS_OFFSET+96
 	st_40		r13, r1, $MACH_REG_STATE_REGS_OFFSET+104
	st_40		r14, r1, $MACH_REG_STATE_REGS_OFFSET+112
 	st_40		r15, r1, $MACH_REG_STATE_REGS_OFFSET+120
 	st_40		r16, r1, $MACH_REG_STATE_REGS_OFFSET+128
 	st_40		r17, r1, $MACH_REG_STATE_REGS_OFFSET+136
 	st_40		r18, r1, $MACH_REG_STATE_REGS_OFFSET+144
 	st_40		r19, r1, $MACH_REG_STATE_REGS_OFFSET+152
 	st_40		r20, r1, $MACH_REG_STATE_REGS_OFFSET+160
 	st_40		r21, r1, $MACH_REG_STATE_REGS_OFFSET+168
 	st_40		r22, r1, $MACH_REG_STATE_REGS_OFFSET+176
 	st_40		r23, r1, $MACH_REG_STATE_REGS_OFFSET+184
 	st_40		r24, r1, $MACH_REG_STATE_REGS_OFFSET+192
 	st_40		r25, r1, $MACH_REG_STATE_REGS_OFFSET+200
 	st_40		r26, r1, $MACH_REG_STATE_REGS_OFFSET+208
	st_40		r27, r1, $MACH_REG_STATE_REGS_OFFSET+216
 	st_40		r28, r1, $MACH_REG_STATE_REGS_OFFSET+224
 	st_40		r29, r1, $MACH_REG_STATE_REGS_OFFSET+232
 	st_40		r30, r1, $MACH_REG_STATE_REGS_OFFSET+240
 	st_40		r31, r1, $MACH_REG_STATE_REGS_OFFSET+248

	/*
	 * Now push all of the windows before the current one onto the saved
	 * window stack.  Note that swp points to the last window
	 * saved so that we have to save from swp + 1 up through cwp - 1.
	 * r1 contains the swp, r2 the cwp and r3  the current value of the 
	 * swp shifted over to align with the cwp.
	 */
	rd_special	r1, swp
	and		r1, r1, $~7
	rd_special	r2, cwp
	and		r2, r2, $0x1c
	/*
	 * Set r3 to the swp aligned with the cwp so that we can use it for
	 * comparisons.
	 */
	and		r3, r1, $0x380
	srl		r3, r3, $1	/* Read the swp and then shift it so */
	srl		r3, r3, $1	/*    it aligns with the cwp.  That is */
	srl		r3, r3, $1	/*    swp<9:7> -> swp<4:2> */
	srl		r3, r3, $1
	srl 		r3, r3, $1

saveState_SaveRegs:
	add_nt		r3, r3, $4
	and		r3, r3, $0x1c
	cmp_br_delayed	eq, r3, r2, saveState_Done
	Nop
	wr_special	cwp, r3, $0	/* Set the cwp to the window to save. */
	Nop
					/* Increment the swp by one window. */
	add_nt		r1, r1, $MACH_SAVED_WINDOW_SIZE
	st_40		r10, r1, $0
	st_40		r11, r1, $8
	st_40		r12, r1, $16
	st_40		r13, r1, $24
	st_40		r14, r1, $32
	st_40		r15, r1, $40
	st_40		r16, r1, $48
	st_40		r17, r1, $56
	st_40		r18, r1, $64
	st_40		r19, r1, $72
	st_40		r20, r1, $80
	st_40		r21, r1, $88
	st_40		r22, r1, $96
	st_40		r23, r1, $104
	st_40		r24, r1, $112
	st_40		r25, r1, $120
	jump		saveState_SaveRegs
	Nop

saveState_Done:
	wr_special	cwp, r2, $0x4	/* Move back to the current window. */
	wr_special	swp, r1, $0	/* Update the swp. */
	/*
	 * Save the cwp and swp.
	 */
	st_32		r1, VOL_TEMP1, $MACH_REG_STATE_SWP_OFFSET
	st_32		r2, VOL_TEMP1, $MACH_REG_STATE_CWP_OFFSET
	/*
	 * Restore the kpsw and return to our caller.
	 */
	wr_kpsw		r5, $0
	jump_reg	VOL_TEMP2, $0
	Nop

/*
 *----------------------------------------------------------------------------
 *
 * RestoreState -
 *
 *	Restore the state of the process from the given state struct.
 *	window stack.  VOL_TEMP1 contains where to restore the state from
 *	and VOL_TEMP2 contains the return address.
 *
 *----------------------------------------------------------------------------
 */
RestoreState:
	/*
	 * Disable interrupts because we will be screwing around with the
	 * swp and cwp here.  The kpsw will be restored below when we
	 * restore the state.
	 */
	rd_kpsw		r8
	and		VOL_TEMP3, r8, $~MACH_KPSW_INTR_TRAP_ENA
	wr_kpsw		VOL_TEMP3, $0

#ifdef PATCH_IBUFFER
	/*
	 * Clear r10 in all windows to insure that all fault and interrupt
	 * locations are gone.
	 */
	rd_special	r1, cwp
	wr_special	cwp,r0,$0	/* Window 0,1 */
	Nop
	add_nt		r10,r0,$0
	add_nt		r26,r0,$0
	wr_special	cwp,r0,$8	/* Window 2,3 */
	Nop
	add_nt		r10,r0,$0
	add_nt		r26,r0,$0
	wr_special	cwp,r0,$16	/* Window 4,5 */
	Nop
	add_nt		r10,r0,$0
	add_nt		r26,r0,$0
	wr_special	cwp,r0,$24	/* Window 6,7 */
	Nop
	add_nt		r10,r0,$0
	add_nt		r26,r0,$0
	wr_special	cwp, r1, $0
	Nop
#endif
	/*
	 * Restore the cwp and swp.  This is a little tricky because
	 * the act of restoring them will switch windows so we can't rely
	 * on anything in our current window.
	 */
	add_nt		r1, VOL_TEMP1, $0
	add_nt		r9, VOL_TEMP2, $0
	ld_32		r2, r1, $MACH_REG_STATE_CWP_OFFSET
	ld_32		r3, r1, $MACH_REG_STATE_SWP_OFFSET
	wr_special	cwp, r2, $0
	wr_special	swp, r3, $0

	/*
	 * Now we are back in the window that we want to restore since the
	 * saved cwp points to the window that we saved in the reg state 
	 * struct.
	 */
  	ld_40		r10, r1, $MACH_REG_STATE_REGS_OFFSET+80
  	ld_40		r11, r1, $MACH_REG_STATE_REGS_OFFSET+88
  	ld_40		r12, r1, $MACH_REG_STATE_REGS_OFFSET+96
  	ld_40		r13, r1, $MACH_REG_STATE_REGS_OFFSET+104
  	ld_40		r14, r1, $MACH_REG_STATE_REGS_OFFSET+112
  	ld_40		r15, r1, $MACH_REG_STATE_REGS_OFFSET+120
  	ld_40		r16, r1, $MACH_REG_STATE_REGS_OFFSET+128
  	ld_40		r17, r1, $MACH_REG_STATE_REGS_OFFSET+136
  	ld_40		r18, r1, $MACH_REG_STATE_REGS_OFFSET+144
  	ld_40		r19, r1, $MACH_REG_STATE_REGS_OFFSET+152
  	ld_40		r20, r1, $MACH_REG_STATE_REGS_OFFSET+160
  	ld_40		r21, r1, $MACH_REG_STATE_REGS_OFFSET+168
  	ld_40		r22, r1, $MACH_REG_STATE_REGS_OFFSET+176
  	ld_40		r23, r1, $MACH_REG_STATE_REGS_OFFSET+184
  	ld_40		r24, r1, $MACH_REG_STATE_REGS_OFFSET+192
  	ld_40		r25, r1, $MACH_REG_STATE_REGS_OFFSET+200
  	ld_40		r26, r1, $MACH_REG_STATE_REGS_OFFSET+208
  	ld_40		r27, r1, $MACH_REG_STATE_REGS_OFFSET+216
  	ld_40		r28, r1, $MACH_REG_STATE_REGS_OFFSET+224
  	ld_40		r29, r1, $MACH_REG_STATE_REGS_OFFSET+232
  	ld_40		r30, r1, $MACH_REG_STATE_REGS_OFFSET+240
  	ld_40		r31, r1, $MACH_REG_STATE_REGS_OFFSET+248
	/*
	 * Go forward to the window that we are to execute in.
	 */
	wr_special	cwp, r2, $4
	Nop
	add_nt		VOL_TEMP1, r1, $0
	add_nt		VOL_TEMP2, r9, $0
	/*
	 * Restore the current PC, next PC, insert register, kpsw. 
	 */
	ld_32		KPSW_REG, VOL_TEMP1, $MACH_REG_STATE_KPSW_OFFSET
	/*
	 * Insert the current processor number into the KPSW_REG.
	 */
	GET_PNUM_FROM_BOARD(r1)
	wr_insert	$3
	insert		KPSW_REG, KPSW_REG, r1

	ld_32		r1, VOL_TEMP1, $MACH_REG_STATE_UPSW_OFFSET
	ld_32		r2, VOL_TEMP1, $MACH_REG_STATE_INSERT_OFFSET
	ld_32		CUR_PC_REG, VOL_TEMP1, $MACH_REG_STATE_CUR_PC_OFFSET
	ld_32		NEXT_PC_REG, VOL_TEMP1, $MACH_REG_STATE_NEXT_PC_OFFSET
	wr_insert	r2
	wr_special	upsw,r1,$0
	/*
	 * Restore the kpsw to that which we came in with.
	 */
	wr_kpsw		r8, $0
	/*
	 * Restore the globals.
	 */
	ld_40		r1, VOL_TEMP1, $MACH_REG_STATE_REGS_OFFSET+8
	ld_40		r2, VOL_TEMP1, $MACH_REG_STATE_REGS_OFFSET+16
	ld_40		r3, VOL_TEMP1, $MACH_REG_STATE_REGS_OFFSET+24
	ld_40		r4, VOL_TEMP1, $MACH_REG_STATE_REGS_OFFSET+32
	ld_40		r5, VOL_TEMP1, $MACH_REG_STATE_REGS_OFFSET+40
	ld_40		r6, VOL_TEMP1, $MACH_REG_STATE_REGS_OFFSET+48
	ld_40		r7, VOL_TEMP1, $MACH_REG_STATE_REGS_OFFSET+56
	ld_40		r8, VOL_TEMP1, $MACH_REG_STATE_REGS_OFFSET+64
	ld_40		r9, VOL_TEMP1, $MACH_REG_STATE_REGS_OFFSET+72

	/*
	 * Return to our caller.
	 */
	jump_reg	VOL_TEMP2, $0
	Nop

/*
 *----------------------------------------------------------------------------
 *
 * MachRefreshCCWells()
 *
 *	Cause a fault in order to refresh the CC wells.
 *
 *----------------------------------------------------------------------------
 */

	.globl _MachRefreshCCWells
_MachRefreshCCWells:
	cmp_trap	always,r0,r0,$MACH_REFRESH_TRAP
	invalidate_ib
	return		RETURN_ADDR_REG, $8
	nop

/*
 *----------------------------------------------------------------------------
 *
 * MachRunUserProc()
 *
 *	Start the user process executing.
 *
 *----------------------------------------------------------------------------
 */
	.globl _MachRunUserProc
_MachRunUserProc:
	/*
	 * Disable all traps and set the previous mode to be from user space.
	 */
	rd_kpsw		KPSW_REG
	or		KPSW_REG, KPSW_REG, $MACH_KPSW_PREV_MODE
	and		KPSW_REG, KPSW_REG, $(~MACH_KPSW_ALL_TRAPS_ENA)
	/*
	 * Do a normal return from trap.
	 */
	add_nt		RETURN_VAL_REG, r0, $MACH_NORM_RETURN
	jump		ReturnTrap
	Nop

/*
 *----------------------------------------------------------------------------
 *
 * Mach_ContextSwitch(fromProcPtr, toProcPtr) --
 *
 *	Switch the thread of execution to a new process.  fromProcPtr
 *	contains a pointer to the process to switch from and toProcPtr
 *	a pointer to the process to switch to.
 *
 *----------------------------------------------------------------------------
 */
	.globl	_Mach_ContextSwitch
_Mach_ContextSwitch:
	/*
	 * Setup the virtual memory context for the process.
	 */
	add_nt		OUTPUT_REG1, INPUT_REG2, $0
	invalidate_ib
	call		_VmMach_SetupContext
	Nop
	invalidate_ib
	/*
	 * Grab a pointer to the state structure to save to.  Note that
	 * the restore and save state routines do not touch any of the
	 * NON_INTR_TEMP registers.
	 */
	ld_32		NON_INTR_TEMP1, r0, $_machStatePtrOffset
	Nop
	add_nt		VOL_TEMP1, INPUT_REG1, NON_INTR_TEMP1
	ld_32		VOL_TEMP1, VOL_TEMP1, $0
	Nop
	/*
	 * Now compute where to save the registers to and call the routine
	 * to save state.  Note that SaveState saves our parent window back.
	 * Thus our locals and output regs will not get modified by saving
	 * and restoring state.
	 */
	add_nt		VOL_TEMP1, VOL_TEMP1, $MACH_SWITCH_REG_STATE_OFFSET
	rd_special	VOL_TEMP2, pc
	add_nt		VOL_TEMP2, VOL_TEMP2, $16
	jump		SaveState
	Nop
	/*
	 * Grab a pointer to the state structure to restore state from.
	 */
	add_nt		VOL_TEMP1, INPUT_REG2, NON_INTR_TEMP1
	ld_32		VOL_TEMP1, VOL_TEMP1, $0
	Nop
	/*
	 * This is now our current state structure address.
	 */
	ST_MACH_CUR_STATE_PTR(VOL_TEMP1, VOL_TEMP2)
	/*
	 * Now compute where to restore the registers from and call the routine
	 * to restore state.
	 */
	add_nt		VOL_TEMP1, VOL_TEMP1, $MACH_SWITCH_REG_STATE_OFFSET
	rd_special	VOL_TEMP2, pc
	add_nt		VOL_TEMP2, VOL_TEMP2, $16
	jump		RestoreState
	Nop
	/*
	 * We are now in the new process so return.
	 */
	invalidate_ib
	return		RETURN_ADDR_REG, $8
	Nop

/*
 *----------------------------------------------------------------------------
 *
 * Mach_DisableNonmaskableIntr --
 *
 *	Mach_DisableNonmaskableIntr()
 *
 *	Disable non-maskable interrupts.
 *
 * Results:
 *     	None.
 *
 * Side effects:
 *	Interrupts are disabled.
 *
 *----------------------------------------------------------------------------
 */
	.globl	_Mach_DisableNonmaskableIntr
_Mach_DisableNonmaskableIntr:
	rd_kpsw		VOL_TEMP1
	and		VOL_TEMP1, VOL_TEMP1, $(~MACH_KPSW_INTR_TRAP_ENA)
	wr_kpsw		VOL_TEMP1, $0
#ifdef PATCH_IBUFFER
	nop
	nop
#endif
	invalidate_ib
	return		RETURN_ADDR_REG, $8
	Nop

/*
 *----------------------------------------------------------------------------
 *
 * Mach_EnableNonmaskableIntr --
 *
 *	void Mach_EnableNonmaskableIntr()
 *
 *	Enable interrupts.
 *
 * Results:
 *     	None.
 *
 * Side effects:
 *	Interrupts are enabled.
 *
 *----------------------------------------------------------------------------
 */
	.globl	_Mach_EnableNonmaskableIntr
_Mach_EnableNonmaskableIntr:
	rd_kpsw		SAFE_TEMP2
	and		VOL_TEMP1, SAFE_TEMP2, $~MACH_KPSW_INTR_TRAP_ENA
	wr_kpsw		VOL_TEMP1, $0
	READ_STATUS_REGS(MACH_INTR_MASK_0, SAFE_TEMP1)
	ld_32		VOL_TEMP1, r0, $_machNonmaskableIntrMask
	nop
	or		SAFE_TEMP1, SAFE_TEMP1, VOL_TEMP1
	WRITE_STATUS_REGS(MACH_INTR_MASK_0, SAFE_TEMP1)
	or		VOL_TEMP1, SAFE_TEMP2, $MACH_KPSW_INTR_TRAP_ENA
	wr_kpsw		VOL_TEMP1, $0
#ifdef PATCH_IBUFFER
	nop
	nop
#endif
	invalidate_ib
	return		RETURN_ADDR_REG, $8
	Nop

/*
 *----------------------------------------------------------------------------
 *
 * Mach_DisableIntr --
 *
 *	Mach_DisableIntr()
 *
 *	Disable maskable interrupts.
 *
 * Results:
 *     	None.
 *
 * Side effects:
 *	Interrupts are disabled.
 *
 *----------------------------------------------------------------------------
 */
	.globl	_Mach_DisableIntr
_Mach_DisableIntr:
	rd_kpsw		SAFE_TEMP2
	and		VOL_TEMP1, SAFE_TEMP2, $(~MACH_KPSW_INTR_TRAP_ENA)
	wr_kpsw		VOL_TEMP1, $0
	ld_32		SAFE_TEMP1, r0, $_machNonmaskableIntrMask
	nop
	WRITE_STATUS_REGS(MACH_INTR_MASK_0, SAFE_TEMP1)
	wr_kpsw		SAFE_TEMP2, $0
#ifdef PATCH_IBUFFER
	nop
	nop
#endif
	invalidate_ib
	return		RETURN_ADDR_REG, $8
	Nop

/*
 *----------------------------------------------------------------------------
 *
 * Mach_EnableIntr --
 *
 *	void Mach_EnableIntr()
 *
 *	Enable all interrupts.
 *
 * Results:
 *     	None.
 *
 * Side effects:
 *	Interrupts are enabled.
 *
 *----------------------------------------------------------------------------
 */
	.globl	_Mach_EnableIntr
_Mach_EnableIntr:
	rd_kpsw		SAFE_TEMP2
	and		VOL_TEMP1, SAFE_TEMP2, $(~MACH_KPSW_INTR_TRAP_ENA)
	wr_kpsw		VOL_TEMP1, $0
	ld_32		SAFE_TEMP1, r0, $_machIntrMask
	nop
	WRITE_STATUS_REGS(MACH_INTR_MASK_0, SAFE_TEMP1)
	wr_kpsw		SAFE_TEMP2, $0
#ifdef PATCH_IBUFFER
	nop
	nop
#endif
	invalidate_ib
	return		RETURN_ADDR_REG, $8
	Nop

/*
 *----------------------------------------------------------------------------
 *
 * Mach_EnableTimerIntr --
 *
 *
 *	Enable timer interrupts. 
 *
 * Results:
 *     	None.
 *
 * Side effects:
 *	Interrupts are enabled.
 *
 *----------------------------------------------------------------------------
 */
	.globl	_Mach_EnableTimerIntr
_Mach_EnableTimerIntr:
	rd_kpsw		SAFE_TEMP2
	and		VOL_TEMP1, SAFE_TEMP2, $(~MACH_KPSW_INTR_TRAP_ENA)
	wr_kpsw		VOL_TEMP1, $0
	READ_STATUS_REGS(MACH_INTR_MASK_0, SAFE_TEMP1)
	ld_32		VOL_TEMP1, r0, $_machTimerIntrMask
	or		SAFE_TEMP1, SAFE_TEMP1, VOL_TEMP1
	WRITE_STATUS_REGS(MACH_INTR_MASK_0, SAFE_TEMP1)
	wr_kpsw		SAFE_TEMP2, $0
#ifdef PATCH_IBUFFER
	nop
	nop
#endif
	invalidate_ib
	return		RETURN_ADDR_REG, $8
	Nop

/*
 *----------------------------------------------------------------------------
 *
 * Mach_TestAndSet --
 *
 *	int Mach_TestAndSet(intPtr)
 *	    int *intPtr;
 *
 *	Test-and-set an integer.
 *
 * Results:
 *     	Returns 0 if *intPtr was zero and 1 if *intPtr was non-zero.  Also
 *	in all cases *intPtr is set to a non-zero value.
 *
 * Side effects:
 *	*intPtr set to a non-zero value if not there already.
 *
 *----------------------------------------------------------------------------
 */
	.globl	_Mach_TestAndSet
_Mach_TestAndSet:
	rd_kpsw		SAFE_TEMP1
	and		VOL_TEMP1, SAFE_TEMP1, $(~MACH_KPSW_INTR_TRAP_ENA)
	jump		1f
	wr_kpsw		VOL_TEMP1, $0
	.align		5	/* 32 byte alignment puts us at the head of
				 * a block. This should fix a bug with 
				 * test_and_set and prefeching. 
				 */
1:
	test_and_set	VOL_TEMP1, INPUT_REG1, $0
	nop
	nop
	nop
	nop
	nop
	wr_kpsw		SAFE_TEMP1, $0

	add_nt		RETURN_VAL_REG_CHILD, VOL_TEMP1, $0
	invalidate_ib
	return		RETURN_ADDR_REG, $8
	Nop


/*
 *----------------------------------------------------------------------------
 *
 * Mach_SetProcessorNumber --
 *
 *	void Mach_SetProcessorNumber(pnum)
 *	    int pnum;
 *
 *	Set the processor number of the current processor to pnum.
 *
 * Results:
 *
 * Side effects: kpsw is modified.
 *	
 *
 *----------------------------------------------------------------------------
 */
	.globl _Mach_SetProcessorNumber
_Mach_SetProcessorNumber:
	/*
	 * Update number stored in high byte or kpsw.
	 */
	rd_kpsw		SAFE_TEMP1
	wr_insert	$3
	insert		SAFE_TEMP1,SAFE_TEMP1,INPUT_REG1
	wr_kpsw		SAFE_TEMP1, $0
	invalidate_ib
	return		RETURN_ADDR_REG, $8
	Nop

/*
 * ParseInstruction --
 *
 *      Decode the trapping instruction and return it's opcode and operations.
 *	The address of the instruction is passed in r10 and the address to 
 *	jump to when done is passed in VOL_TEMP1, and the trapping instruction
 *      is passed in VOL_TEMP2.  The return values are:
 *      OUTPUT1 -- opcode
 *      OUTPUT2 -- destination register (for loads and operations)
 *		   condition code (for compares)
 *                 value to store (for stores)
 *      OUTPUT3 -- operand 1
 *      OUTPUT4 -- operand 2
 *
 *	SRC_REG:	r15 -- src register
 *	PREV_SRC_REG:	r31 -- src register in previous window.
 *	TRAP_INST:	r19 (VOL_TEMP2) -- Input: Trapping instruction.
 *	CALLER_TEMP1	r21 (SAFE_TEMP1) -- Temporary reserved for caller.
 *	CALLER_TEMP2	r22 (SAFE_TEMP2) -- Temporary reserved for caller.
 *	CALLER_TEMP3	r23 (SAFE_TEMP3) -- Temporary reserved for caller.
 *	PARSE_TEMP1:	r24 -- One temporary to use.
 *	SAVED_R15:	r25 -- Place to save r15.
	SAVED_CUR_PC    r31 -- Place to save CUR_PC
 */

#define	SRC_REG	         	r15
#define	PREV_SRC_REG		r31   /* These must be r15 and r31 to work with the tables */

#define	RET_ADDR		r18
#define	TRAP_INST		r19
#define	PARSE_TEMP1		r24
#define	SAVED_R15		r25
#define	SAVED_CUR_PC		r31


ParseInstruction:
	add_nt		SAVED_R15, r15, $0	/* Save r15 for recovering register values */
	add_nt		SAVED_CUR_PC,CUR_PC_REG,$0  /* Save CUR_PC across call */
	/*                 	
       	 * fetch the opcode
	 */
	extract		OUTPUT_REG1, TRAP_INST, $3	/* Opcode <31:25> -> <07:01> */
	srl		OUTPUT_REG1, OUTPUT_REG1, $1	/* Opcode <07:01> -> <06:00> */
	
	/*
	 * fetch the destination register or cc
	 */
	sll		OUTPUT_REG2, TRAP_INST, $3	/* Rdes <24:20> to <27:23> */
	sll		OUTPUT_REG2, OUTPUT_REG2, $1	/* <27:23> to <28:24> */
	extract		OUTPUT_REG2, OUTPUT_REG2, $3    /* <28:24> to <04:00> */
	and		OUTPUT_REG2, OUTPUT_REG2, $0x1f /* Pitch the extra bits  */
	/*
	* fetch the first operand 
	*/
	sll		SRC_REG, TRAP_INST, $1	/* s1 <19:15> to <20:16> */
	extract		SRC_REG, SRC_REG, $2	/* s1 <20:16> to <04:00> */
	and		SRC_REG, SRC_REG, $0x1f /* Pitch the extra bits */

	cmp_br_delayed	lt, SRC_REG,  $31, @@getf  
	nop
	jump		@@endf
	add_nt		SRC_REG, SAVED_R15, $0   /* get r31 directly */


/* Here, we get the value of the register (0-30) from the previous window.  
 * It's real tricky.  Basically, we go back to the previous window, execute
 * a single instruction out of a table (moving the proper register into r31),
 * then returning to this window.  It relies on a couple of architecture 
 * features.
 * First, SRC_REG (r15) in this window will be PREV_SRC_REG (r31) in the 
 * previous window.  Second, the jump_reg below will take us to the move table
 * while the jump in the delay slot will bring us back.  The instruction in the
 * move table is executed in the delay slot of the jump.  Got it?
 */
@@get:
	invalidate_ib
	rd_special	PARSE_TEMP1, pc         /* Back up one window */
	return		PARSE_TEMP1, $12
	Nop
	sll		PREV_SRC_REG, PREV_SRC_REG, $2	/* s1 = s1 * 4 */
	jump_reg	PREV_SRC_REG, $OpRecov /*Retrieve value of first op. */
	jump	        @@nextf  /* The instruction in table will be
				 * executed in the delay slot of this jump. */
@@next:
	invalidate_ib
	call 	       	@@endf			/* Get back to trap window.  */
	Nop

@@end:
	add_nt		OUTPUT_REG3,SRC_REG,$0


	/*  Now, we need to do a little decoding on the opcode to get the rest of 
         *  the operands.  We take different action depending on whether the opcode
         *  is a store, compare, or other operation.
         */

	/*
	 * It's a store if the op code is > 0x20 and < 0x30
	 */
#define ST_BASE       0x20
	add_nt		PARSE_TEMP1,OUTPUT_REG1,$-ST_BASE
	cmp_br_delayed  lt, PARSE_TEMP1, $0x20-ST_BASE, @@not_storef
	nop
	cmp_br_delayed  lt, PARSE_TEMP1, $0x30-ST_BASE, parse_store
	nop

	/*
	 * See if it's a compare
	 */
@@not_store:
#define CMP_BASE        0x50
#define CMP_BR_DELAYED  0x50
#define CMP_TRAP        0x51

	add_nt		PARSE_TEMP1,OUTPUT_REG1,$-CMP_BASE
	cmp_br_delayed  eq,PARSE_TEMP1,$CMP_BR_DELAYED-CMP_BASE,parse_cmp
	cmp_br_delayed  eq,PARSE_TEMP1,$CMP_TRAP-CMP_BASE,parse_cmp
	nop


	/*
	 * Assume load or op.  Check for register or immediate value.
	 */
parse_op:
	extract		PARSE_TEMP1, TRAP_INST, $1
	and		PARSE_TEMP1, PARSE_TEMP1, $0x40
	cmp_br_delayed  ne, PARSE_TEMP1, $0, @@immedf
	Nop
	jump		@@regf
	Nop

@@immed:
	/*
	 * 2nd operand is an immediate.
	 */
	and		OUTPUT_REG4, TRAP_INST, $0x1fff	/* Extract immediate val. */
	add_nt		PARSE_TEMP1, TRAP_INST, $0	/* Check for a  */
	srl		PARSE_TEMP1, PARSE_TEMP1, $1	/*   negative number */
	and		PARSE_TEMP1, PARSE_TEMP1, $0x1000 
	cmp_br_delayed	eq, PARSE_TEMP1, $0, parse_end
	Nop
	jump		parse_end
	add_nt		OUTPUT_REG4, OUTPUT_REG4, $~0x1fff	/* Sign extend */

	/*
	 * Second operand is a register.  Get it like we did the one above.
	 */
@@reg:	srl		SRC_REG,TRAP_INST,$1	/* Extract register number  */
	extract		SRC_REG,SRC_REG,$1
	and		SRC_REG,SRC_REG,$0x1f
	
	cmp_br_delayed	lt, SRC_REG,  $31, @@getf
	nop
	jump		@@endf
	add_nt		SRC_REG, SAVED_R15, $0   /* get r31 directly */

@@get:	rd_special	PARSE_TEMP1, pc         /* Back up one window */
	return		PARSE_TEMP1, $12
	Nop
	sll		PREV_SRC_REG, PREV_SRC_REG, $2	/* s1 = s1 * 4 */
	jump_reg	PREV_SRC_REG, $OpRecov  /* Retrieve value of 2nd op. */
	jump	        @@nextf  /* The instruction in table will be
			      /* executed in the delay slot of this jump. */
@@next:
	invalidate_ib
	call 	       	@@endf			/* Get back to trap window.  */
	Nop

@@end:
	jump		parse_end
	add_nt		OUTPUT_REG4,SRC_REG,$0

/*
 *   Compares have either a short (5 bit immediate) or a register as the second op
 *   and a word offset for a destination address.  
 */
parse_cmp:
	extract		SRC_REG, TRAP_INST, $1		/* Extract register or immediate val. */
	srl		SRC_REG, SRC_REG,$1
	and		OUTPUT_REG4, SRC_REG,$0x1f

	extract		PARSE_TEMP1, TRAP_INST, $1    /* Check for value type */
	and		PARSE_TEMP1, PARSE_TEMP1, $0x40 /* (immediate or register) */
	cmp_br_delayed  eq, PARSE_TEMP1, $0, @@regf
	Nop

@@immed:
	/*
	 * 2nd operand is an immediate.
	 */
	cmp_br_delayed	gt, PARSE_TEMP1, $0x0f, @@offsetf  /* If negative, sign extend */
	Nop
	jump		@@offsetf
	or		OUTPUT_REG4, OUTPUT_REG4, $~0x1f	

@@reg:
	/*
	 * Second operand is a register.  Get it like we did the one above.
	 */
	cmp_br_delayed	lt, SRC_REG,  $31, @@getf  
	nop
	jump		@@endf
	add_nt		SRC_REG, SAVED_R15, $0   /* get r31 directly */
@@get:

	invalidate_ib
	rd_special	PARSE_TEMP1, pc         /* Back up one window */
	return		PARSE_TEMP1, $12
	Nop
	sll		PREV_SRC_REG, PREV_SRC_REG, $2	/* s1 = s1 * 4 */
	jump_reg	PREV_SRC_REG, $OpRecov  /* Retrieve value of 2nd op. */
	jump	        @@nextf   /* The instruction in table will be
         		          * executed in the delay slot of this jump. */
@@next:
	invalidate_ib
	call 	       	@@endf			/* Get back to trap window.  */
	Nop

@@end:
	add_nt		OUTPUT_REG4,SRC_REG,$0

	/*
	 *		Get the destination address as the last operand.
	 */
@@offset:
#ifdef 0          /* Not needed for now.  -- daj */
	and		PARSE_TEMP1,TRAP_INST,$0x100	/* Sign extend if negative */
	cmp_br_delayed	eq,PARSE_TEMP1,r0,@@posf
	and		OUTPUT_REG5,TRAP_INST,$0x1ff
	or		OUTPUT_REG5,OUTPUT_REG5,$~0x1ff
	sll		OUTPUT_REG5,OUTPUT_REG5,$2	/* Change to byte displacement */
	jump		parse_end
	add_nt		OUTPUT_REG5,OUTPUT_REG5,r10	/* Add instruction address  */
#else
	jump		parse_end
	nop
#endif

/*
 * Stores have a two part immediate value as the second operand.
 */

parse_store:
	sll		PARSE_TEMP1, TRAP_INST, $3	/* Dest<24:20> move to <27:23> */
	sll		PARSE_TEMP1, PARSE_TEMP1, $2	/* Move to <29:25> */
	extract		PARSE_TEMP1, PARSE_TEMP1, $3	/* Move to <5:1>   */
	rd_insert	OUTPUT_REG4
	wr_insert	$1
	insert		PARSE_TEMP1, r0, PARSE_TEMP1	/* Move to <13:09> */
	wr_insert	OUTPUT_REG4
	srl		OUTPUT_REG4, PARSE_TEMP1, $1	/* Sign-bit <13> to <12> */
	and		OUTPUT_REG4, OUTPUT_REG4, $0x1000 /* Check for negative */
	cmp_br_delayed	eq, OUTPUT_REG4, $0, @@posf    /*    number */
	and 		PARSE_TEMP1, PARSE_TEMP1,$0x1e00  /* Mask out valid bits. */
	add_nt		PARSE_TEMP1, PARSE_TEMP1,$~0x1fff  /* Sign extend  */

@@pos:
	and		OUTPUT_REG4, TRAP_INST, $0x01ff	     /* Put together into */
	or		OUTPUT_REG4, PARSE_TEMP1,  OUTPUT_REG4  /*    14-bit value. */

	/*
	 * Get value being stored
	 */

	extract		SRC_REG, TRAP_INST, $1		/* register number */
	srl		SRC_REG, SRC_REG,$1
	and		SRC_REG, SRC_REG,$0x1f

	cmp_br_delayed	lt, SRC_REG,  $31, @@getf
	nop
	jump		@@endf
	add_nt		SRC_REG, SAVED_R15, $0   /* get r31 directly */

@@get:	rd_special	PARSE_TEMP1, pc         /* Back up one window */
	return		PARSE_TEMP1, $12
	Nop
	sll		PREV_SRC_REG, PREV_SRC_REG, $2	/* s1 = s1 * 4 */
	jump_reg	PREV_SRC_REG, $OpRecov  /* Retrieve value of 2nd op. */
	jump	        @@nextf  /* The instruction in table will be
			      /* executed in the delay slot of this jump. */
@@next:
	invalidate_ib
	call 	       	@@endf			/* Get back to trap window.  */
	Nop

@@end:

	add_nt		OUTPUT_REG2,SRC_REG,$0


	/*
	 * All done.  Restore the registers and go back to the caller.
 	 */		
parse_end:
	add_nt		CUR_PC_REG,SAVED_CUR_PC,$0
	jump_reg	RET_ADDR, r0			/* Go back to caller */
	add_nt		r15, SAVED_R15, $0		/* Restore pre-parse r15 */
.org	MACH_STACK_BOTTOM
mainStack:
/*
 * Leave room for the stacks.
 */
.org MACH_CODE_START
codeStart:
/*
 * Non Master processor jump to this location when spun up by the master
 * processor.  Current it is assumed that the processor is executing in 
 * physical mode.
 */

slaveStart:

/*
 * Initialize the PTEVA.
 */
	LD_CONSTANT(r1, VMMACH_KERN_PT_BASE >> VMMACH_PAGE_SHIFT)
	ST_PT_BASE(r1)
/*
 * Initialize the RPTEVA.
 */
	ST_RPT_BASE(r1)
/*
 * Initialize the 0th segment register.
 */
	ST_GSN(r0, MACH_GSN_0)
/*
 * Initialize the RPTM register.
 */
	LD_CONSTANT(r1, KERN_PT2_BASE)
	ST_RPTM(r1, MACH_RPTM_0)
#ifdef notdef
	/*
 	 * Do not touch the snoop tags on the slave processor while the
	 * master or any other processor is doing virtual translation.
	 * Bad things will happen.
	 */
/*
 * Clear out the cache.
 */
	LD_CONSTANT(r1, 0x03000000)
	LD_CONSTANT(r2, (0x03000000 | VMMACH_CACHE_SIZE))
1:
	st_32		r0, r1, $0
	add_nt		r1, r1, $VMMACH_CACHE_LINE_SIZE
	cmp_br_delayed	lt, r1, r2, 1b
	Nop


/*
 * Clear snoop tags.
 */
	LD_CONSTANT(r1, 0x04000000)
	LD_CONSTANT(r2, (0x04000000 | VMMACH_CACHE_SIZE))
1:
	st_32		r0, r1, $0
	add_nt		r1, r1, $VMMACH_CACHE_LINE_SIZE
	cmp_br_delayed	lt, r1, r2, 1b
	Nop

#endif
/*
 * Clear out the upsw.
 */
	wr_special	upsw, r0, $0

/*
 * Clear out the interrupt mask register so that no interrupts are enabled.
 */
	WRITE_STATUS_REGS(MACH_INTR_MASK_0, r0)

/*
 * Clear the fe status register.
 */
	add_nt		r1, r0, $-1
	WRITE_STATUS_REGS(MACH_FE_STATUS_0, r1)

/*
 * Now jump to virtual mode through the following sequence:
 *
 *	1) Disable instruction buffer just in case it is on.
 *	2) Invalidate the instruction buffer.
 *	3) Make a good kpsw.
 *	4) Jump to slaveMain while setting the kpsw to put is in
 *	   virtual mode in the nop slot of the call.
 */
	wr_kpsw		r0, $0
	invalidate_ib
	add_nt		r1, r0, $(DEFAULT_KPSW)
	LD_PC_RELATIVE(r2,slaveMainAddr)
	jump_reg	r2, $0
	wr_kpsw		r1, $0
	Nop
slaveMainAddr:	.long slaveMain

slaveMain:
/*
 * Initialized the kpsw with the processor number.
 */

	add_nt r3, r0, $1
	st_32  r3, r0, $_machDebugSlave

	GET_PNUM_FROM_BOARD(SAFE_TEMP1)
	rd_kpsw		SAFE_TEMP2
	wr_insert	$3
	insert		SAFE_TEMP2,SAFE_TEMP2,SAFE_TEMP1
	wr_kpsw		SAFE_TEMP2, $0
/*
 * Initialize the cwp, swp and SPILL_SP to their proper values. These values
 * are uptained from the Mach_State of the first process for this processor.
 */
	ld_32		VOL_TEMP2,r0,$firstProcStatePtr
	sll		SAFE_TEMP1,SAFE_TEMP1,$2
	ld_32		r1,VOL_TEMP2,SAFE_TEMP1
	Nop
	add_nt		r1, r1, $MACH_SWITCH_REG_STATE_OFFSET
	ld_32		r2, r1, $MACH_REG_STATE_CWP_OFFSET
	ld_32		r3, r1, $MACH_REG_STATE_SWP_OFFSET
	wr_special	cwp, r0, r2
	wr_special	swp, r3, $0
	ld_32		r4, r1, $MACH_REG_STATE_REGS_OFFSET+32

	add_nt r3, r0, $2
	st_32  r3, r0, $_machDebugSlave
	jump		_mainSlaveStart
	Nop

@


8.7
log
@now uses Fmt_Convert
@
text
@d9 1
a9 1
 * rcs = $Header: /sprite/src/kernel/mach/spur.md/RCS/loMem.s,v 8.6 89/06/19 14:01:10 jhh Exp Locker: jhh $ SPRITE (Berkeley)
d307 1
d3346 34
@


8.6
log
@Cleaning up locked files
@
text
@d9 1
a9 1
 * rcs = $Header: /sprite/src/kernel/mach/spur.md/RCS/loMem.s,v 8.5 89/03/15 17:47:10 mendel Exp $ SPRITE (Berkeley)
d269 1
a269 1
debugSpillStackEndPtr:	.long (MACH_DEBUG_STACK_BOTTOM + MACH_KERN_STACK_SIZE)
d306 1
d520 1
a520 1
	add_nt		r1, r1, $VMMACH_CACHE_BLOCK_SIZE
d531 1
a531 1
	add_nt		r1, r1, $VMMACH_CACHE_BLOCK_SIZE
d1551 1
a1551 1
        add_nt          VOL_TEMP1, VOL_TEMP1, $VMMACH_CACHE_BLOCK_SIZE; 
d3739 1
d3773 1
a3773 1
	add_nt		r1, r1, $VMMACH_CACHE_BLOCK_SIZE
d3785 1
a3785 1
	add_nt		r1, r1, $VMMACH_CACHE_BLOCK_SIZE
d3828 4
d3851 3
@


8.5
log
@Don't enable interrupts when fetching trapping instruction.
@
text
@d9 1
a9 1
 * rcs = $Header: /sprite/src/kernel/mach/spur.md/RCS/loMem.s,v 8.4 89/01/11 09:51:31 mendel Exp $ SPRITE (Berkeley)
d668 1
a684 1
	invalidate_ib
d780 1
d1201 1
d1205 1
d1207 1
d1211 1
d1248 1
d1252 1
d1257 1
d1262 1
d1308 1
d1321 1
d1354 9
d1381 13
d1410 1
d1523 1
d1714 1
d1726 1
d1738 1
d1751 1
d1777 1
d1801 1
d1834 1
d1871 1
d1908 1
d1957 1
d2104 1
d2154 1
d2197 1
d2227 1
d2385 1
d2407 1
d2473 1
d2507 1
d2521 1
a2521 1
	nop
d2603 1
d2655 1
d2658 1
d2678 1
d2696 1
d2714 1
d2746 1
d2788 1
d2879 1
d3123 1
d3168 1
d3215 1
d3241 5
d3278 5
d3312 5
d3346 5
d3393 1
d3424 1
d3503 1
d3512 1
d3593 1
d3634 1
d3643 1
d3710 1
@


8.4
log
@Added fast refresh code.
@
text
@d9 1
a9 1
 * rcs = $Header: /sprite/src/kernel/mach/spur.md/RCS/loMem.s,v 8.3 88/11/30 10:26:28 mendel Exp $ SPRITE (Berkeley)
d1511 8
a2243 2
	wr_kpsw		VOL_TEMP1, $0
	ld_32		VOL_TEMP2, CUR_PC_REG, $0
d2250 1
d2821 2
@


8.3
log
@More multiprocessor mods.
@
text
@d9 1
a9 1
 * rcs = $Header: /sprite/src/kernel/mach/spur.md/RCS/loMem.s,v 8.2 88/11/15 13:41:39 dougj Exp Locker: mendel $ SPRITE (Berkeley)
d162 3
d278 6
a284 7
				.long _proc_RunningProcesses+4
				.long _proc_RunningProcesses+8
				.long _proc_RunningProcesses+12
				.long _proc_RunningProcesses+16
				.long _proc_RunningProcesses+20
				.long _proc_RunningProcesses+24
				.long _proc_RunningProcesses+28
a294 1
_machInterruptAddr:		.long 0
d296 2
d299 7
a485 1

d949 1
a949 1
	jump 	Interrupt
d1012 1
d1014 99
d1134 8
a1141 1

a1722 1

d1727 2
a1728 2
		cmp_trap  ne,r0,VOL_TEMP1,$2

d2026 1
a2026 1
	 * VOL_TEMP1 <= proc_RunningProccesses[pnum]
d2028 1
a2028 1
	LD_CURRENT_PCB_PTR(VOL_TEMP1)
d2037 2
a2038 2
	add_nt		VOL_TEMP1, VOL_TEMP1, VOL_TEMP2
	ld_32		VOL_TEMP2, VOL_TEMP1, $0
d2134 1
d2487 2
a2488 1
	 * Restore the kpsw to that which we trapped with.
d2490 4
d2519 1
a2519 1
	LD_CURRENT_PCB_PTR(VOL_TEMP1)
d2522 2
a2523 2
	add_nt		VOL_TEMP1, VOL_TEMP1, VOL_TEMP2
	ld_32		VOL_TEMP1, VOL_TEMP1, $0
d2525 1
a2525 1
	cmp_br_delayed	ne, VOL_TEMP1, $0, returnTrap_SpecialAction
d2700 8
d3656 6
d3685 1
d3714 1
a3714 1
	LD_PC_RELATIVE(r2,slaveMain)
d3717 2
a3718 1

@


8.2
log
@Fix user traps.  
@
text
@d9 1
a9 1
 * rcs = $Header: /sprite/src/kernel/mach/spur.md/RCS/loMem.s,v 8.1 88/11/14 12:36:54 dougj Exp Locker: dougj $ SPRITE (Berkeley)
d276 7
d1608 6
d1907 1
a1907 1
	 *	(proc_RunningProcesses[0]->kcallTable[sysCallType])()
d1911 1
a1911 1
	 * VOL_TEMP1 <= proc_RunningProccesses[0]
d1913 1
a1913 6
	ld_32		VOL_TEMP1, r0, $runningProcesses
	Nop						
	ld_32		VOL_TEMP1, VOL_TEMP1, $0
	Nop
	ld_32		VOL_TEMP1, VOL_TEMP1, $0
	Nop
d2396 1
a2396 1
	 * proc_RunningProcesses[0]->specialHandling.
d2398 1
a2398 5
	ld_32		VOL_TEMP1, r0, $runningProcesses
	Nop
	ld_32		VOL_TEMP1, VOL_TEMP1, $0
	nop
	ld_32		VOL_TEMP1, VOL_TEMP1, $0
a2876 1
#ifdef notdef
d2880 1
a2880 1
#endif
@


8.1
log
@Handle stores correctly in ParseInstruction
@
text
@d9 1
a9 1
 * rcs = $Header: /sprite/src/kernel/mach/spur.md/RCS/loMem.s,v 1.43 88/10/28 18:01:12 mendel Exp $ SPRITE (Berkeley)
a2196 1
	call		1f                          /* Bump the windows */
d2199 4
a2202 6
						/* Our operands are now
						   in the input registers */
1:	st_40		INPUT_REG3, SPILL_SP, $0    /* First operand */
	st_40		INPUT_REG4, SPILL_SP, $8    /* Second operand */
	add_nt		OUTPUT_REG3, INPUT_REG1,$0  /* opcode */
	add_nt		OUTPUT_REG4, INPUT_REG2,$0  /* destReg */
d2205 3
a2207 1
	add_nt		OUTPUT_REG5, SPILL_SP, $0
d2209 1
a2209 1
	nop
d2211 1
d3258 1
a3258 1
	cmp_br_delayed	ult, SRC_REG,  $31, @@getf  
d3350 1
a3350 1
	cmp_br_delayed	ult, SRC_REG,  $31, @@getf
d3460 5
a3464 2
	add_nt		SRC_REG,OUTPUT_REG2,r0   /* Register number */
	cmp_br_delayed	ult, SRC_REG,  $31, @@getf
d3481 1
@


8.0
log
@Changing version numbers.
@
text
@d9 1
a9 1
 * rcs = $Header: /sprite/src/kernel/mach/spur.md/RCS/loMem.s,v 1.43 88/10/28 18:01:12 mendel Exp Locker: douglis $ SPRITE (Berkeley)
d3208 3
a3210 1
 *      OUTPUT2 -- destination register or condition code
d3350 1
a3350 1
	cmp_br_delayed	ult, SRC_REG,  $31, @@regf
d3455 25
@


1.43
log
@Multiprocessor and ibuffer support.
@
text
@d9 1
a9 1
 * rcs = $Header: /sprite/src/kernel/mach/spur.md/RCS/loMem.s,v 1.42 88/10/20 09:19:31 mendel Exp $ SPRITE (Berkeley)
@


1.42
log
@Added support for multiple processors.
@
text
@d9 1
a9 1
 * rcs = $Header: loMem.s,v 1.41 88/10/13 17:19:14 mendel Exp $ SPRITE (Berkeley)
d117 19
d155 1
d158 4
a161 1

d178 1
a178 1
	Nop
d182 1
a182 1
	Nop
d186 1
a186 1
	Nop
d206 1
a206 1
	Nop
a242 1
runningProcesses: 		.long _proc_RunningProcesses
d244 5
a248 1
 * _machCurStatePtrs is index by processor number.
d250 2
a251 16
_machCurStatePtrs: 		.long 0
				.long 0
				.long 0
				.long 0
				.long 0
				.long 0
				.long 0
				.long 0
				.long 0
				.long 0
				.long 0
				.long 0
				.long 0
				.long 0
				.long 0
				.long 0
d253 1
a253 1
 * _machCurStatePtrs is index by slot ID.
d255 23
a277 16
_machMapSlotToPnum: 		.long 0
				.long 0
				.long 0
				.long 0
				.long 0
				.long 0
				.long 0
				.long 0
				.long 0
				.long 0
				.long 0
				.long 0
				.long 0
				.long 0
				.long 0
				.long 0
d283 1
d287 1
a287 5
numArgsPtr:			.long _machNumArgs
debugStatePtr:			.long _machDebugState
debugSWStackBase:		.long MACH_DEBUG_STACK_BOTTOM
debugSpillStackEnd:		.long (MACH_DEBUG_STACK_BOTTOM + MACH_KERN_STACK_SIZE)
ccStatePtr:			.long _machCCState
d422 26
d554 1
a554 9
#ifdef WITH_IBUFFER
#ifdef WITH_PREFETCH
	add_nt		r1, r0, $(MACH_KPSW_PREFETCH_ENA | MACH_KPSW_IBUFFER_ENA | MACH_KPSW_VIRT_DFETCH_ENA | MACH_KPSW_VIRT_IFETCH_ENA | MACH_KPSW_FAULT_TRAP_ENA | MACH_KPSW_ERROR_TRAP_ENA | MACH_KPSW_ALL_TRAPS_ENA)
#else
add_nt		r1, r0, $(MACH_KPSW_IBUFFER_ENA | MACH_KPSW_VIRT_DFETCH_ENA | MACH_KPSW_VIRT_IFETCH_ENA | MACH_KPSW_FAULT_TRAP_ENA | MACH_KPSW_ERROR_TRAP_ENA | MACH_KPSW_ALL_TRAPS_ENA)
#endif
#else
add_nt		r1, r0, $(MACH_KPSW_VIRT_DFETCH_ENA | MACH_KPSW_VIRT_IFETCH_ENA | MACH_KPSW_FAULT_TRAP_ENA | MACH_KPSW_ERROR_TRAP_ENA | MACH_KPSW_ALL_TRAPS_ENA)
#endif
d600 3
d643 8
d659 12
d672 1
a673 1
	Nop
d755 8
d771 12
d784 1
a903 2
faultIntr_Const2:
	.long	MACH_KPSW_CC_REFRESH
a908 10
	LD_PC_RELATIVE(SAFE_TEMP1, faultIntr_Const2)
	rd_kpsw		VOL_TEMP1
        and             VOL_TEMP1, VOL_TEMP1, SAFE_TEMP1
        cmp_br_delayed  eq, VOL_TEMP1, r0, $faultIntr_NormFault
	nop
	READ_STATUS_REGS(MACH_FE_STATUS_0, SAFE_TEMP1)
	WRITE_STATUS_REGS(MACH_FE_STATUS_0, SAFE_TEMP1)
	return_trap	CUR_PC_REG, $16
	nop

d915 5
d955 10
d966 1
d1079 5
d1116 3
d1122 9
d1154 10
d1165 1
d1179 9
a1187 1
	add_nt		OUTPUT_REG1, r0, $MACH_USER_BAD_SWP
d1409 5
d2455 6
d2462 1
d2466 5
d2472 1
d2485 3
d2519 3
d2640 3
a2642 1

d2686 2
a2687 2
 	st_40		r10, r1, $MACH_REG_STATE_REGS_OFFSET+80
 	st_40		r11, r1, $MACH_REG_STATE_REGS_OFFSET+88
d2794 2
a2795 1
	
d2797 24
a2915 6
machRefresh_Const1:
	.long		MACH_CC_FAULT_ADDR
machRefresh_Const2:
	.long		MACH_KPSW_CC_REFRESH
machRefresh_Const3:
	.long		0x100403e0
d2919 1
a2919 34
	rd_kpsw		SAFE_TEMP1
	LD_PC_RELATIVE(SAFE_TEMP2, machRefresh_Const1)
	LD_PC_RELATIVE(SAFE_TEMP3, machRefresh_Const2)
	wr_kpsw		SAFE_TEMP1, SAFE_TEMP3
	LD_PC_RELATIVE(NON_INTR_TEMP1, machRefresh_Const3)
	st_external	r0, NON_INTR_TEMP1, $MACH_CO_FLUSH
	ld_32_ri	VOL_TEMP1, SAFE_TEMP2, $0
	nop
	jump		ErrorTrap
	nop
	st_external	r0, NON_INTR_TEMP1, $MACH_CO_FLUSH
	ld_32_ro	VOL_TEMP1, SAFE_TEMP2, $0
	nop
	jump		ErrorTrap
	nop
	/*
	 * Restore the special registers that aren't restored by the
	 * trap that we just took.
	 */
	rd_special	VOL_TEMP1, upsw
	nop
	nop
	wr_special	upsw, VOL_TEMP1, $0
	rd_special	VOL_TEMP1, swp
	nop
	nop
	wr_special	swp, VOL_TEMP1, $0
	rd_insert	VOL_TEMP1 
	nop
	nop
	wr_insert	VOL_TEMP1

	wr_kpsw		SAFE_TEMP1, $0

d3174 1
a3174 1
 * Mach_SaveCCAndHalt --
d3176 2
a3177 2
 *	int Mach_TestAndSet(intPtr)
 *	    int *intPtr;
d3179 1
a3179 1
 *	Test-and-set an integer.
a3181 2
 *     	Returns 0 if *intPtr was zero and 1 if *intPtr was non-zero.  Also
 *	in all cases *intPtr is set to a non-zero value.
d3183 2
a3184 2
 * Side effects:
 *	*intPtr set to a non-zero value if not there already.
d3188 11
a3198 4
	.globl _Mach_SaveCCAndHalt
_Mach_SaveCCAndHalt:
	SAVE_CC_STATE_VIRT()
	CALL_DEBUGGER(r0, MACH_BREAKPOINT)
a3199 1

d3461 2
a3462 1

d3468 107
@


1.41
log
@Removed old debugging ifdefs.
@
text
@d9 1
a9 1
 * rcs = $Header: loMem.s,v 1.40 88/10/05 08:39:14 mendel Exp $ SPRITE (Berkeley)
d120 1
a120 1
	.globl _machCurStatePtr
d209 1
a209 1
 * of what _machCurStatePtr points to we can't do it normally by the 
d212 1
a212 1
 * 	ld_32	rt1, r0, $_machCurStatePtr
d221 38
a258 1
_machCurStatePtr: 		.long 0
a525 5
#else
	call		_main
	Nop
#endif

a536 3
winOvFlow_Const1:
	.long 0x8387

d596 2
a597 2
	ld_32		VOL_TEMP1, r0, $_machCurStatePtr
	Nop
a598 1
	rd_special	VOL_TEMP2, swp
d685 3
a687 3
	Nop							/*   check from */
								/*   kernel mode */
	ld_32		VOL_TEMP1, r0, $_machCurStatePtr
d860 1
a860 1
	cmp_br_delayed	eq, SAFE_TEMP1, r0, Interrupt
d862 3
d872 1
a872 1
	cmp_br_delayed	ne, VOL_TEMP1, r0, VMFault
d874 3
a876 1

d988 1
a988 8
	/*
	 * We have a bogus user swp.  Switch over to the kernel's stacks
	 * and take the interrupt.  After taking the interrupt kill the user
	 * process.
	 */
	SWITCH_TO_KERNEL_STACKS()
	wr_kpsw		KPSW_REG, $MACH_KPSW_ALL_TRAPS_ENA
	call		_MachInterrupt
a989 5
	WRITE_STATUS_REGS(MACH_INTR_MASK_0, SAFE_TEMP3)
	add_nt		OUTPUT_REG1, r0, $MACH_USER_BAD_SWP
	call		_MachUserError
	Nop
	/* DOESN'T RETURN */
d1058 16
d1189 2
a1190 2
	ld_32		VOL_TEMP1, r0, $_machCurStatePtr
	Nop
d1207 1
a1207 1
	ld_32		VOL_TEMP1, r0, $_machCurStatePtr
d1295 6
d1639 1
a1639 1
	ld_32		SAFE_TEMP1, r0, $_machCurStatePtr
a1641 1
	Nop
d1841 2
a1842 2
	ld_32           VOL_TEMP1, r0, $_machCurStatePtr
        Nop
d1884 2
a1885 2
	ld_32		VOL_TEMP1, r0, $_machCurStatePtr
	nop
d1932 3
a1934 2
	ld_32           SAFE_TEMP1, r0, $_machCurStatePtr
        Nop
d2045 1
a2045 1
	ld_32		VOL_TEMP1, r0, $_machCurStatePtr
d2283 2
a2284 2
	ld_32           VOL_TEMP1, r0, $_machCurStatePtr
        Nop
d2436 2
a2437 2
	ld_32		SAFE_TEMP1, r0, $_machCurStatePtr
        Nop
d2698 1
a2698 1
	 * Restore the current PC, next PC, insert register, kpsw.
d2701 8
d2867 1
a2867 1
	st_32		VOL_TEMP1, r0, $_machCurStatePtr
@


1.40
log
@*** empty log message ***
@
text
@d9 1
a9 1
 * rcs = $Header: loMem.s,v 1.39 88/09/30 09:19:18 mendel Exp $ SPRITE (Berkeley)
d155 1
a155 1
	invalidate_ib
d159 1
a159 1
	invalidate_ib
d163 1
a163 1
	invalidate_ib
d167 1
a167 1
	invalidate_ib
d171 1
a171 1
	invalidate_ib
d175 1
a175 1
	invalidate_ib
d179 1
a179 1
	invalidate_ib
a182 5
	invalidate_ib

#ifdef BARB
	.org 0x10b0
	jump CmpTrap		/* Hack for BARB */
a183 1
#endif
d185 1
a219 5
#ifdef ovflow_tracing
traceStartAddr:			.long 0x100000
traceEndAddr:			.long 0x400000
traceOvFlowBit:			.long 0x10000000
#endif
a228 1
#ifdef PROF
a229 6
#endif
#ifdef ovflow_tracing
_machNumOvFlow:			.long 0
interruptPC:			.long 0
_machNumUnderFlow:		.long 0
#endif
a330 1
#ifndef BARB
a350 3
#ifdef small_mem
#define	KERN_PT_FIRST_PAGE	60
#else
a351 1
#endif
a378 19
/* IMPORTANT NOTE: This should be a compare against 0 but there is a hack
 * for now to let us refresh the CC wells. */
	cmp_br_delayed	gt, r2, $1, 1b
	Nop

#ifdef small_mem
/*
 * Remap 16 Mbytes of the device 2nd level page tables for now.
 */
	LD_CONSTANT(r1, KERN_PT2_BASE)
	add_nt		r1, r1, $512 
	add_nt		r2, r0, $4
	LD_CONSTANT(r3, MACH_MEM_SLOT_MASK | ((KERN_PT_FIRST_PAGE - 4) << VMMACH_PAGE_FRAME_SHIFT) | VMMACH_RESIDENT_BIT | VMMACH_CACHEABLE_BIT | VMMACH_KRW_URO_PROT | VMMACH_REFERENCED_BIT | VMMACH_MODIFIED_BIT)
	LD_CONSTANT(r4, 1 << VMMACH_PAGE_FRAME_SHIFT)
1:
	st_32		r3, r1, $0
	add_nt		r1, r1, $4
	add_nt		r3, r3, r4
	sub		r2, r2, $1
a380 1
#endif
d382 1
a437 1
#endif
a438 21
#ifdef refresh_CC_wells
refreshWell:
	LD_CONSTANT(r1, MACH_CC_FAULT_ADDR)
	LD_CONSTANT(r2, MACH_KPSW_CC_REFRESH)
	rd_kpsw		r3
	wr_kpsw		r3, r2
	rd_special	r7, pc
	add_nt		r7, r7, $24
	ld_32_ri	r2, r1, $0
	nop
	jump		ErrorTrap
	nop
	rd_special	r7, pc
	add_nt		r7, r7, $24
	ld_32_ro	r2, r1, $0
	nop
	jump		ErrorTrap
	nop
	wr_kpsw		r3, $0
#endif

a457 1
#ifndef BARB
a527 5
#ifdef ovflow_tracing
	add_nt		SAFE_TEMP3, r2, $0
	add_nt		NON_INTR_TEMP1, r3, $0
	LD_PC_RELATIVE(r2, winOvFlow_Const1)
#endif
a535 40
#ifdef ovflow_tracing
	ld_32		r2, r0, $_machNumOvFlow
	nop
	add_nt		r2, r2, $1
	st_32		r2, r0, $_machNumOvFlow
	cmp_br_delayed	lt, r1, r2, 1f
	nop
	wr_special	cwp, r0, $0x0
	st_32		r10, r0, $0x1000
	wr_special	cwp, r0, $0x4
	st_32		r10, r0, $0x1004
	wr_special	cwp, r0, $0x8
	st_32		r10, r0, $0x1008
	wr_special	cwp, r0, $0xc
	st_32		r10, r0, $0x100c
	wr_special	cwp, r0, $0x10
	st_32		r10, r0, $0x1010
	wr_special	cwp, r0, $0x14
	st_32		r10, r0, $0x1014
	wr_special	cwp, r0, $0x18
	st_32		r10, r0, $0x1018
	wr_special	cwp, r0, $0x1c
	st_32		r10, r0, $0x101c
	rd_special	r10, swp
	st_32		r10, r0, $0x1020
	st_32		r1, r0, $0x1024
	st_32		r0, r0, $-1
	nop

1:
	ld_32		r2, r0, $traceStartAddr
	ld_32		r3, r0, $traceOvFlowBit
	nop
	or		r3, r3, r10
	st_32		r3, r2, $0
	st_32		r1, r2, $4
	add_nt		r2, r2, $8
	st_32		r2, r0, $traceStartAddr
#endif

a556 4
#ifdef ovflow_tracing
	add_nt		r2, SAFE_TEMP3, $0
	add_nt		r3, NON_INTR_TEMP1, $0
#endif
a622 3
#ifdef ovflow_tracing
	add_nt		SAFE_TEMP3, r2, $0
#endif
a628 5
#ifdef ovflow_tracing
	ld_32		r2, r0, $_machNumUnderFlow
	nop
	add_nt		r2, r2, $1
	st_32		r2, r0, $_machNumUnderFlow
a629 8
	ld_32		r2, r0, $traceStartAddr
	nop
	st_32		r10, r2, $0
	st_32		r1, r2, $4
	add_nt		r2, r2, $8
	st_32		r2, r0, $traceStartAddr
#endif

a650 3
#ifdef ovflow_tracing
	add_nt		r2, SAFE_TEMP3, $0	/* Restore r2 */
#endif
a828 1
#ifdef BARB
a829 5
	 * Simulate a virtual memory fault.
	 */
	LD_CONSTANT(r18, 0x10000)
#endif
	/*
a838 1
mark:
d904 1
a904 1
#ifdef
a926 1
#ifdef PROF
a930 1
#endif
@


1.39
log
@Patch to catch illegal cache ops on non-cachable pages. Save the current pc
for profiling. Random needed Nops added.
@
text
@d9 1
a9 1
 * rcs = $Header: loMem.s,v 1.38 88/09/16 15:24:41 dougj Exp $ SPRITE (Berkeley)
d155 1
a155 1
	Nop
d159 1
a159 1
	Nop
d163 1
a163 1
	Nop
d167 1
a167 1
	Nop
d171 1
a171 1
	Nop
d175 1
a175 1
	Nop
d179 1
a179 1
	Nop
d183 1
a183 1
	Nop
d225 1
d229 1
d239 1
d241 2
d244 1
d246 1
a246 1

a252 1
interruptPC:			.long 0
d1042 1
d1065 2
d1070 2
a1071 1
	st_32		CUR_PC_REG, r0, $_machInterruptAddr
d2598 5
d2796 1
a2796 1
	 * Restore the current PC, next PC, insert register, kpsw and the upsw.
a2802 1
	wr_special	upsw, r1, $0
d2804 1
d2821 1
d3111 1
d3113 5
a3117 1

d3120 4
a3123 1

@


1.38
log
@Add missing #endif.
@
text
@d9 1
a9 1
 * rcs = $Header: loMem.s,v 1.32 88/09/07 15:08:02 mendel Exp $ SPRITE (Berkeley)
d137 1
d237 1
a237 1

d501 1
d929 2
d979 1
a979 2
	 * The only other type of fault that we can handle is a bus
	 * retry error.
d990 22
d1059 4
d1255 1
d1393 1
d2147 1
@


1.37
log
@Add support for Lisp including ld/st_40 and new parseInstruction
@
text
@d537 1
@


1.36
log
@#ifdef the enabling of ibuffer
@
text
@d9 1
a9 1
 * rcs = $Header: loMem.s,v 1.35 88/09/13 10:33:38 mendel Exp $ SPRITE (Berkeley)
d258 1
a258 1
 * Jump tables to return the operands from an instruction.  Also here
d261 1
a261 33
OpRecov1:
	add_nt		r30,  r0, $0
	add_nt		r30,  r1, $0
	add_nt		r30,  r2, $0
	add_nt		r30,  r3, $0
	add_nt		r30,  r4, $0
	add_nt		r30,  r5, $0
	add_nt		r30,  r6, $0
	add_nt		r30,  r7, $0
	add_nt		r30,  r8, $0
	add_nt		r30,  r9, $0
	add_nt		r30, r10, $0
	add_nt		r30, r11, $0
	add_nt		r30, r12, $0
	add_nt		r30, r13, $0
	add_nt		r30, r14, $0
	add_nt		r30, r15, $0
	add_nt		r30, r16, $0
	add_nt		r30, r17, $0
	add_nt		r30, r18, $0
	add_nt		r30, r19, $0
	add_nt		r30, r20, $0
	add_nt		r30, r21, $0
	add_nt		r30, r22, $0
	add_nt		r30, r23, $0
	add_nt		r30, r24, $0
	add_nt		r30, r25, $0
	add_nt		r30, r26, $0
	add_nt		r30, r27, $0
	add_nt		r30, r28, $0
	add_nt		r30, r29, $0

OpRecov2:
d292 1
d536 1
a536 2
	add_nt		r1, r0, $(MACH_KPSW_IBUFFER_ENA | MACH_KPSW_VIRT_DFETCH_ENA | MACH_KPSW_VIRT_IFETCH_ENA | MACH_KPSW_FAULT_TRAP_ENA | MACH_KPSW_ERROR_TRAP_ENA | MACH_KPSW_ALL_TRAPS_ENA)
#endif
d538 1
a538 1
	add_nt		r1, r0, $(MACH_KPSW_VIRT_DFETCH_ENA | MACH_KPSW_VIRT_IFETCH_ENA | MACH_KPSW_FAULT_TRAP_ENA | MACH_KPSW_ERROR_TRAP_ENA | MACH_KPSW_ALL_TRAPS_ENA)
d637 16
a652 16
	st_32		r10, r1, $0
	st_32		r11, r1, $8
	st_32		r12, r1, $16
	st_32		r13, r1, $24
	st_32		r14, r1, $32
	st_32		r15, r1, $40
	st_32		r16, r1, $48
	st_32		r17, r1, $56
	st_32		r18, r1, $64
	st_32		r19, r1, $72
	st_32		r20, r1, $80
	st_32		r21, r1, $88
	st_32		r22, r1, $96
	st_32		r23, r1, $104
	st_32		r24, r1, $112
	st_32		r25, r1, $120
d751 16
a766 16
	ld_32		r10, r1,   $0
	ld_32		r11, r1,   $8
	ld_32		r12, r1,  $16
	ld_32		r13, r1,  $24
	ld_32		r14, r1,  $32
	ld_32		r15, r1,  $40
	ld_32		r16, r1,  $48
	ld_32		r17, r1,  $56
	ld_32		r18, r1,  $64
	ld_32		r19, r1,  $72
	ld_32		r20, r1,  $80
	ld_32		r21, r1,  $88
	ld_32		r22, r1,  $96
	ld_32		r23, r1, $104
	ld_32		r24, r1, $112
	ld_32		r25, r1, $120
d1098 9
a1106 9
	sub		SPILL_SP, SPILL_SP, $32
	st_32		r1, SPILL_SP, $0
	st_32		r2, SPILL_SP, $4
	st_32		r3, SPILL_SP, $8
	st_32		r5, SPILL_SP, $12
	st_32		r6, SPILL_SP, $16
	st_32		r7, SPILL_SP, $20
	st_32		r8, SPILL_SP, $24
	st_32		r9, SPILL_SP, $28
d1116 8
a1123 8
	ld_32		r1, SPILL_SP, $0
	ld_32		r2, SPILL_SP, $4
	ld_32		r3, SPILL_SP, $8
	ld_32		r5, SPILL_SP, $12
	ld_32		r6, SPILL_SP, $16
	ld_32		r7, SPILL_SP, $20
	ld_32		r8, SPILL_SP, $24
	ld_32		r9, SPILL_SP, $28
d1125 1
a1125 1
	add_nt		SPILL_SP, SPILL_SP, $32
d1175 9
a1183 9
	sub		SPILL_SP, SPILL_SP, $32
	st_32		r1, SPILL_SP, $0
	st_32		r2, SPILL_SP, $4
	st_32		r3, SPILL_SP, $8
	st_32		r5, SPILL_SP, $12
	st_32		r6, SPILL_SP, $16
	st_32		r7, SPILL_SP, $20
	st_32		r8, SPILL_SP, $24
	st_32		r9, SPILL_SP, $28
d1255 9
a1263 9
	ld_32		r1, VOL_TEMP1, $(MACH_TRAP_REGS_OFFSET + 8)
	ld_32		r2, VOL_TEMP1, $(MACH_TRAP_REGS_OFFSET + 16)
	ld_32		r3, VOL_TEMP1, $(MACH_TRAP_REGS_OFFSET + 24)
	ld_32		r4, VOL_TEMP1, $(MACH_TRAP_REGS_OFFSET + 32)
	ld_32		r5, VOL_TEMP1, $(MACH_TRAP_REGS_OFFSET + 40)
	ld_32		r6, VOL_TEMP1, $(MACH_TRAP_REGS_OFFSET + 48)
	ld_32		r7, VOL_TEMP1, $(MACH_TRAP_REGS_OFFSET + 56)
	ld_32		r8, VOL_TEMP1, $(MACH_TRAP_REGS_OFFSET + 64)
	ld_32		r9, VOL_TEMP1, $(MACH_TRAP_REGS_OFFSET + 72)
d1272 2
a1273 1
	Nop
d1284 8
a1291 8
	ld_32		r1, SPILL_SP, $0
	ld_32		r2, SPILL_SP, $4
	ld_32		r3, SPILL_SP, $8
	ld_32		r5, SPILL_SP, $12
	ld_32		r6, SPILL_SP, $16
	ld_32		r7, SPILL_SP, $20
	ld_32		r8, SPILL_SP, $24
	ld_32		r9, SPILL_SP, $28
d1297 1
d1323 8
a1330 8
	ld_32		r1, SPILL_SP, $0
	ld_32		r2, SPILL_SP, $4
	ld_32		r3, SPILL_SP, $8
	ld_32		r5, SPILL_SP, $12
	ld_32		r6, SPILL_SP, $16
	ld_32		r7, SPILL_SP, $20
	ld_32		r8, SPILL_SP, $24
	ld_32		r9, SPILL_SP, $28
d1332 1
a1332 1
	add_nt		SPILL_SP, SPILL_SP, $32
a1350 6
   	 * Clear any pending faults caused by the fetch of the instruction
	 * following the compare trap.
	 */
	add_nt		SAFE_TEMP1,r0,$-1
	WRITE_STATUS_REGS(MACH_FE_STATUS_0, SAFE_TEMP1)
	/*
d2036 4
d2047 1
a2047 1
	ld_32		OUTPUT_REG2, CUR_PC_REG, $0
d2050 1
a2050 1
	 * to be mucking register windows in UserOperandRecov.
d2054 4
a2057 10
	/*
	 * Recover the operands.  We pass the pc to return to in OUTPUT_REG1
	 * and the instruction to recover from in OUTPUT_REG2.  We get back 
	 * the opcode in OUTPUT_REG3, the dest register
	 * in OUTPUT_REG4, the first operand in OUTPUT_REG2, and 
	 * the second operand in OUTPUT_REG5.
	 */
	rd_special	OUTPUT_REG1, pc
	add_nt		OUTPUT_REG1, OUTPUT_REG1, $16
	jump		UserOperandRecov
d2124 1
a2124 2
	 * source operands.  OUTPUT_REG3 and OUTPUT_REG4 have already been
	 * set correctly by the operand recovery routine.
d2126 13
a2138 3
	sub		SPILL_SP, SPILL_SP, $16
	st_40		OUTPUT_REG2, SPILL_SP, $0
	st_40		OUTPUT_REG5, SPILL_SP, $8
d2142 1
a2142 1
	jump_reg	SAFE_TEMP1, $0
d2155 2
a2156 2
	sub		SPILL_SP, SPILL_SP, $8
	st_32		SAFE_TEMP2, SPILL_SP, $0
d2166 2
a2167 2
	st_32		r1, SPILL_SP, $4
	ld_32		r1, SPILL_SP, $0
d2174 2
a2175 2
	ld_32		r1, SPILL_SP, $4
	add_nt		SPILL_SP, SPILL_SP, $8
d2180 2
a2181 2
	ld_32		r1, SPILL_SP, $4
	add_nt		SPILL_SP, SPILL_SP, $8
d2186 2
a2187 2
	ld_32		r1, SPILL_SP, $4
	add_nt		SPILL_SP, SPILL_SP, $8
d2192 2
a2193 2
	ld_32		r1, SPILL_SP, $4
	add_nt		SPILL_SP, SPILL_SP, $8
d2196 2
a2197 2
	ld_32		r1, SPILL_SP, $4
	add_nt		SPILL_SP, SPILL_SP, $8
a2557 10
	st_32		r0, VOL_TEMP1, $MACH_REG_STATE_REGS_OFFSET+0
	st_32		r1, VOL_TEMP1, $MACH_REG_STATE_REGS_OFFSET+8
	st_32		r2, VOL_TEMP1, $MACH_REG_STATE_REGS_OFFSET+16
	st_32		r3, VOL_TEMP1, $MACH_REG_STATE_REGS_OFFSET+24
	st_32		r4, VOL_TEMP1, $MACH_REG_STATE_REGS_OFFSET+32
	st_32		r5, VOL_TEMP1, $MACH_REG_STATE_REGS_OFFSET+40
	st_32		r6, VOL_TEMP1, $MACH_REG_STATE_REGS_OFFSET+48
	st_32		r7, VOL_TEMP1, $MACH_REG_STATE_REGS_OFFSET+56
	st_32		r8, VOL_TEMP1, $MACH_REG_STATE_REGS_OFFSET+64
	st_32		r9, VOL_TEMP1, $MACH_REG_STATE_REGS_OFFSET+72
d2559 11
d2593 22
a2614 22
	st_32		r10, r1, $MACH_REG_STATE_REGS_OFFSET+80
	st_32		r11, r1, $MACH_REG_STATE_REGS_OFFSET+88
	st_32		r12, r1, $MACH_REG_STATE_REGS_OFFSET+96
	st_32		r13, r1, $MACH_REG_STATE_REGS_OFFSET+104
	st_32		r14, r1, $MACH_REG_STATE_REGS_OFFSET+112
	st_32		r15, r1, $MACH_REG_STATE_REGS_OFFSET+120
	st_32		r16, r1, $MACH_REG_STATE_REGS_OFFSET+128
	st_32		r17, r1, $MACH_REG_STATE_REGS_OFFSET+136
	st_32		r18, r1, $MACH_REG_STATE_REGS_OFFSET+144
	st_32		r19, r1, $MACH_REG_STATE_REGS_OFFSET+152
	st_32		r20, r1, $MACH_REG_STATE_REGS_OFFSET+160
	st_32		r21, r1, $MACH_REG_STATE_REGS_OFFSET+168
	st_32		r22, r1, $MACH_REG_STATE_REGS_OFFSET+176
	st_32		r23, r1, $MACH_REG_STATE_REGS_OFFSET+184
	st_32		r24, r1, $MACH_REG_STATE_REGS_OFFSET+192
	st_32		r25, r1, $MACH_REG_STATE_REGS_OFFSET+200
	st_32		r26, r1, $MACH_REG_STATE_REGS_OFFSET+208
	st_32		r27, r1, $MACH_REG_STATE_REGS_OFFSET+216
	st_32		r28, r1, $MACH_REG_STATE_REGS_OFFSET+224
	st_32		r29, r1, $MACH_REG_STATE_REGS_OFFSET+232
	st_32		r30, r1, $MACH_REG_STATE_REGS_OFFSET+240
	st_32		r31, r1, $MACH_REG_STATE_REGS_OFFSET+248
d2647 16
a2662 16
	st_32		r10, r1, $0
	st_32		r11, r1, $8
	st_32		r12, r1, $16
	st_32		r13, r1, $24
	st_32		r14, r1, $32
	st_32		r15, r1, $40
	st_32		r16, r1, $48
	st_32		r17, r1, $56
	st_32		r18, r1, $64
	st_32		r19, r1, $72
	st_32		r20, r1, $80
	st_32		r21, r1, $88
	st_32		r22, r1, $96
	st_32		r23, r1, $104
	st_32		r24, r1, $112
	st_32		r25, r1, $120
d2719 22
a2740 22
	ld_32		r10, r1, $MACH_REG_STATE_REGS_OFFSET+80
	ld_32		r11, r1, $MACH_REG_STATE_REGS_OFFSET+88
	ld_32		r12, r1, $MACH_REG_STATE_REGS_OFFSET+96
	ld_32		r13, r1, $MACH_REG_STATE_REGS_OFFSET+104
	ld_32		r14, r1, $MACH_REG_STATE_REGS_OFFSET+112
	ld_32		r15, r1, $MACH_REG_STATE_REGS_OFFSET+120
	ld_32		r16, r1, $MACH_REG_STATE_REGS_OFFSET+128
	ld_32		r17, r1, $MACH_REG_STATE_REGS_OFFSET+136
	ld_32		r18, r1, $MACH_REG_STATE_REGS_OFFSET+144
	ld_32		r19, r1, $MACH_REG_STATE_REGS_OFFSET+152
	ld_32		r20, r1, $MACH_REG_STATE_REGS_OFFSET+160
	ld_32		r21, r1, $MACH_REG_STATE_REGS_OFFSET+168
	ld_32		r22, r1, $MACH_REG_STATE_REGS_OFFSET+176
	ld_32		r23, r1, $MACH_REG_STATE_REGS_OFFSET+184
	ld_32		r24, r1, $MACH_REG_STATE_REGS_OFFSET+192
	ld_32		r25, r1, $MACH_REG_STATE_REGS_OFFSET+200
	ld_32		r26, r1, $MACH_REG_STATE_REGS_OFFSET+208
	ld_32		r27, r1, $MACH_REG_STATE_REGS_OFFSET+216
	ld_32		r28, r1, $MACH_REG_STATE_REGS_OFFSET+224
	ld_32		r29, r1, $MACH_REG_STATE_REGS_OFFSET+232
	ld_32		r30, r1, $MACH_REG_STATE_REGS_OFFSET+240
	ld_32		r31, r1, $MACH_REG_STATE_REGS_OFFSET+248
d2765 9
a2773 9
	ld_32		r1, VOL_TEMP1, $MACH_REG_STATE_REGS_OFFSET+8
	ld_32		r2, VOL_TEMP1, $MACH_REG_STATE_REGS_OFFSET+16
	ld_32		r3, VOL_TEMP1, $MACH_REG_STATE_REGS_OFFSET+24
	ld_32		r4, VOL_TEMP1, $MACH_REG_STATE_REGS_OFFSET+32
	ld_32		r5, VOL_TEMP1, $MACH_REG_STATE_REGS_OFFSET+40
	ld_32		r6, VOL_TEMP1, $MACH_REG_STATE_REGS_OFFSET+48
	ld_32		r7, VOL_TEMP1, $MACH_REG_STATE_REGS_OFFSET+56
	ld_32		r8, VOL_TEMP1, $MACH_REG_STATE_REGS_OFFSET+64
	ld_32		r9, VOL_TEMP1, $MACH_REG_STATE_REGS_OFFSET+72
a2877 3
	/*
	 * Clear any possible bogus entries from the instruction buffer.
	 */
d3099 1
d3103 1
a3103 2
 *	Relevant instructions: LD_40*, LD_32*, ST_40, ST_32, TEST_AND_SET.
 *	We want to get the address of the operand that accesses memory.
d3105 6
a3110 4
 *	jump to when done is passed in VOL_TEMP1.  Note that since the act of
 *	doing calls to switch windows trashes r10 we have to save r10.  Also
 *	since we use r14 and r15 we have to save and restore them at the end.
 *	We return the data address from the instruction in VOL_TEMP2.
d3112 2
a3113 7
 *	SRC1_REG:	r14 -- src1 register
 *	SRC1_VAL:	r14 -- Value of src1 register.
 *	PREV_SRC1_REG:	r30 -- src1 register in previous window.
 *	SRC2_REG:	r15 -- src2 register or immediate.
 *	SRC2_VAL:	r15 -- Value of src2 register or immediate.
 *	PREV_SRC2_REG:	r31 -- src2 register in previous window.
 *	RET_ADDR:	r18 (VOL_TEMP1) -- Input: Address to return to.
a3114 2
 *	DATA_VAL_REG:	r19 (VOL_TEMP2) -- Output: Data address
 *	OPCODE:		r20 (VOL_TEMP3) -- Opcode.
d3119 2
a3120 4
 *	PARSE_TEMP2:	r25 -- 2nd temporary to use.
 *	SAVED_R10:	r27 -- Place to save r10.
 *	SAVED_R14:	r28 -- Place to save r14.
 *	SAVED_R15:	r29 -- Place to save r15.
d3123 3
a3125 6
#define	SRC1_REG		r14
#define	SRC1_VAL		r14
#define	PREV_SRC1_REG		r30
#define	SRC2_REG		r15
#define	SRC2_VAL		r15
#define	PREV_SRC2_REG		r31
a3126 1
#define	DATA_VAL_REG		r19
a3127 1
#define	OPCODE			r20
d3129 2
a3130 4
#define	PARSE_TEMP2		r25
#define	SAVED_R10		r27
#define	SAVED_R14		r28
#define	SAVED_R15		r29
d3132 1
d3134 8
a3141 13
	add_nt		SAVED_R10, r10, $0	/* Save "return" address */
	add_nt		SAVED_R14, r14, $0	/* Save r14 and r15 because */
	add_nt		SAVED_R15, r15, $0	/*  these will be used to  */
						/*  recover operands. */
	extract		OPCODE, TRAP_INST, $3	/* Opcode <31:25> -> <07:01> */
	srl		OPCODE, OPCODE, $1	/* Opcode <07:01> -> <06:00> */
	sll		SRC1_REG, TRAP_INST, $1	/* s1 <19:15> to <20:16> */
	extract		SRC1_REG, SRC1_REG, $2	/* s1 <20:16> to <04:00> */
	and		SRC1_REG, SRC1_REG, $0x1f
	srl		SRC2_REG, TRAP_INST, $1	/* s2 <13:09> to <12:08> */
	extract		SRC2_REG, SRC2_REG, $1	/* s2 <12:08> to <04:00> */
	and		SRC2_REG, SRC2_REG, $0x1f

d3143 1
a3143 1
	 * Go back one window.
d3145 29
a3173 1
	rd_special	PARSE_TEMP1, pc
d3176 6
a3181 8

	/*
	 * Now we're in the previous window (where the trap occurred)
	 * If s1 < 30 then go through the jump table to recover the value.
	 * Otherwise do it by hand since we trashed r14 and r15 which are r30
	 * and r31 respectively in the previous window.
	 */
	cmp_br_delayed	 lt, PREV_SRC1_REG, $30, parse4
a3182 8
	call		parse1up		/* Back to trap handler window. */
	Nop
parse1up:
	cmp_br_delayed	eq, SRC1_REG,  $30, parse1a
	Nop
	cmp_br_delayed	eq, SRC1_REG,  $31, parse1b
	Nop
	CALL_DEBUGGER(r0, MACH_BAD_SRC_REG)
d3184 2
a3185 4
parse1a:
	add_nt		SRC1_VAL, SAVED_R14, $0
	jump		parse5
	Nop
a3186 8
parse1b: 
	add_nt		SRC1_VAL, SAVED_R15, $0
	jump 		parse5
	Nop
	
parse4:	sll		PREV_SRC1_REG, PREV_SRC1_REG, $2	/* s1 = s1 * 4 */
	jump_reg	PREV_SRC1_REG, $OpRecov1  /* Retrieve value of first op. */
	jump	        parse41		 	/* Value is returned in r30 */
d3188 4
a3191 3
parse41:
	call 	       	parse5			/* Get back to trap window.  */
	Nop
a3192 1
parse5:	
d3194 1
a3194 5
	 * SRC1_VAL now contains src1.  Additional offset will depend on
	 * type of operation.  Load can take either register or immediate
	 * value.  Store takes immediate value only, and from two places.
	 * We have a store if opcode<7> = 2.
	 * Currently back in trap handler register window.
d3196 6
a3201 3
	and		PARSE_TEMP1, OPCODE, $0x20
	cmp_br_delayed  ne, PARSE_TEMP1, $0, parse_store
	Nop
d3204 1
a3204 1
	 * Parsing load or test&set.  Check for register or immediate value.
d3206 15
d3223 1
a3223 1
	cmp_br_delayed  ne, PARSE_TEMP1, $0, parse5a
d3225 1
a3225 1
	cmp_br_delayed	always, r0, r0, parse5b
d3228 1
a3228 1
parse5a:
d3232 1
a3232 1
	and		SRC2_VAL, TRAP_INST, $0x1fff	/* Extract immediate val. */
d3238 17
a3254 2
	add_nt		SRC2_VAL, SRC2_VAL, $~0x1fff	/* Sign extend SRC2_VAL */
	cmp_br_delayed	always, r0, r0, parse_end
d3256 7
d3264 19
a3282 1
parse5b:
d3284 1
a3284 1
	 * Go back one window.
d3286 1
a3286 2
	rd_special	PARSE_TEMP2, pc
	return 		PARSE_TEMP2, $12
d3288 2
d3291 1
d3293 1
a3293 4
	 * Now we're in the previous window (where the trap occurred)
	 * If s2 < 30 then go through the jump table to recover the value.
	 * Otherwise do it by hand since we trashed r14 and r15 which are
	 * r30 and r31 respectively in the previous window.
d3295 8
a3302 1
	cmp_br_delayed	 lt, PREV_SRC2_REG, $30, parse6
d3304 6
a3309 1
	call		pars2up
a3310 6
pars2up:
	cmp_br_delayed	 eq, SRC2_REG,  $30, parse2a
	Nop
	cmp_br_delayed	 eq, SRC2_REG,  $31, parse2b
	Nop
	CALL_DEBUGGER(r0, MACH_BAD_SRC_REG)
d3312 2
a3313 4
parse2a:
	add_nt		SRC2_VAL, SAVED_R14, $0
	jump		parse_end
	Nop
d3315 10
a3324 2
parse2b:
	add_nt		SRC2_VAL, SAVED_R15, $0
d3326 5
a3330 1
	Nop
a3331 10
parse6:	sll		PREV_SRC2_REG, PREV_SRC2_REG, $2  /* Multiply src2 reg */
							  /*   by 4 to represent */
							  /*   offset in jump  */
							  /*   table. */
	jump_reg	PREV_SRC2_REG, $OpRecov2  /* Recover 2nd operand register */
	jump 		parse7			 /*   and put value in r31 */
parse7:	
	call		parse_end
	Nop

d3333 1
a3333 3
 * Handle store here by getting immediate part and putting in SRC2_VAL.  Then
 * join up with the load/store logic and calculate address.  For stores,
 * we are in the trap handler register window all along.
d3340 1
d3343 4
a3346 3
	srl		PARSE_TEMP2, PARSE_TEMP1, $1	/* Sign-bit <13> to <12> */
	and		PARSE_TEMP2, PARSE_TEMP2, $0x1000 /* Check for negative */
	cmp_br_delayed	eq, PARSE_TEMP2, $0, parse_pos    /*    number */
a3348 4
							  /*    PARSE_TEMP2. */
parse_pos:
	and		PARSE_TEMP2, TRAP_INST, $0x01ff	     /* Put together into */
	or		SRC2_VAL, PARSE_TEMP1,  PARSE_TEMP2  /*    14-bit value. */
d3350 7
a3356 4
/*
 *  In the trap window.  SRC1_VAL contains first part of address.
 *  SRC2_VAL contains second part.  Now add them and mask.
 */
d3358 2
a3359 3
	add_nt		DATA_VAL_REG, SRC1_VAL, SRC2_VAL	
	add_nt		r10, SAVED_R10, $0		/* Restore pre-parse r10 */
	add_nt		r14, SAVED_R14, $0		/* Restore pre-parse r14 */
a3360 13
	jump_reg	RET_ADDR, r0			/* Go back to caller */
	Nop

/*
 * Do operand recovery for a user trap.  For now this is a dummy routine.
 */
UserOperandRecov:
	add_nt		OUTPUT_REG3, r0, $0x12
	add_nt		OUTPUT_REG4, r0, $17
	add_nt		OUTPUT_REG2, r0, $0x321
	add_nt		OUTPUT_REG5, r0, $0x654
	jump_reg	OUTPUT_REG1, $0
	nop
@


1.35
log
@Aligned save regs array on Mach_RegState to be on 64bit boundry to allow
st_64's to it.
@
text
@d9 1
a9 1
 * rcs = $Header: loMem.s,v 1.34 88/09/12 09:40:25 mendel Exp $ SPRITE (Berkeley)
d563 2
d566 6
d2906 4
@


1.34
log
@Clear fe_status reg on compare trap.
@
text
@d9 1
a9 1
 * rcs = $Header: loMem.s,v 1.33 88/09/09 16:02:13 nelson Exp $ SPRITE (Berkeley)
d1726 1
a1726 1
	ld_32		SAFE_TEMP2, SAFE_TEMP1, $(MACH_TRAP_REGS_OFFSET + 8 * 16)
d1733 1
a1733 1
	cmp_br_delayed	le, SAFE_TEMP2, VOL_TEMP1, sysCallTrap_FetchArgs
d1786 1
a1786 1
	ld_32		VOL_TEMP1, SAFE_TEMP1, $(MACH_TRAP_REGS_OFFSET + 8 * MACH_SPILL_SP)
d1906 1
a1906 1
	st_32		RETURN_VAL_REG, SAFE_TEMP1, $(MACH_TRAP_REGS_OFFSET + 8 * MACH_RETURN_VAL_REG)
d1972 1
a1972 1
	st_32		SPILL_SP, VOL_TEMP1, $(MACH_TRAP_REGS_OFFSET + 8 * 4)
d2579 10
a2588 10
	st_32		r0, VOL_TEMP1, $0
	st_32		r1, VOL_TEMP1, $8
	st_32		r2, VOL_TEMP1, $16
	st_32		r3, VOL_TEMP1, $24
	st_32		r4, VOL_TEMP1, $32
	st_32		r5, VOL_TEMP1, $40
	st_32		r6, VOL_TEMP1, $48
	st_32		r7, VOL_TEMP1, $56
	st_32		r8, VOL_TEMP1, $64
	st_32		r9, VOL_TEMP1, $72
d2613 22
a2634 22
	st_32		r10, r1, $80
	st_32		r11, r1, $88
	st_32		r12, r1, $96
	st_32		r13, r1, $104
	st_32		r14, r1, $112
	st_32		r15, r1, $120
	st_32		r16, r1, $128
	st_32		r17, r1, $136
	st_32		r18, r1, $144
	st_32		r19, r1, $152
	st_32		r20, r1, $160
	st_32		r21, r1, $168
	st_32		r22, r1, $176
	st_32		r23, r1, $184
	st_32		r24, r1, $192
	st_32		r25, r1, $200
	st_32		r26, r1, $208
	st_32		r27, r1, $216
	st_32		r28, r1, $224
	st_32		r29, r1, $232
	st_32		r30, r1, $240
	st_32		r31, r1, $248
d2739 22
a2760 22
	ld_32		r10, r1, $80
	ld_32		r11, r1, $88
	ld_32		r12, r1, $96
	ld_32		r13, r1, $104
	ld_32		r14, r1, $112
	ld_32		r15, r1, $120
	ld_32		r16, r1, $128
	ld_32		r17, r1, $136
	ld_32		r18, r1, $144
	ld_32		r19, r1, $152
	ld_32		r20, r1, $160
	ld_32		r21, r1, $168
	ld_32		r22, r1, $176
	ld_32		r23, r1, $184
	ld_32		r24, r1, $192
	ld_32		r25, r1, $200
	ld_32		r26, r1, $208
	ld_32		r27, r1, $216
	ld_32		r28, r1, $224
	ld_32		r29, r1, $232
	ld_32		r30, r1, $240
	ld_32		r31, r1, $248
d2785 9
a2793 9
	ld_32		r1, VOL_TEMP1, $8
	ld_32		r2, VOL_TEMP1, $16
	ld_32		r3, VOL_TEMP1, $24
	ld_32		r4, VOL_TEMP1, $32
	ld_32		r5, VOL_TEMP1, $40
	ld_32		r6, VOL_TEMP1, $48
	ld_32		r7, VOL_TEMP1, $56
	ld_32		r8, VOL_TEMP1, $64
	ld_32		r9, VOL_TEMP1, $72
@


1.33
log
@User level trap handlers added but not tested.
@
text
@d9 1
a9 1
 * rcs = $Header: loMem.s,v 1.32 88/09/07 15:08:02 mendel Exp $ SPRITE (Berkeley)
d1372 6
@


1.32
log
@Modifed to disable interrupts around st_exteral's.
@
text
@d9 1
a9 1
 * rcs = $Header: loMem.s,v 1.31 88/09/02 11:51:18 nelson Exp $ SPRITE (Berkeley)
d2042 4
d2066 4
a2078 3
	and		VOL_TEMP1, KPSW_REG, $~MACH_KPSW_INTR_TRAP_ENA
	or		VOL_TEMP1, VOL_TEMP1, $MACH_KPSW_ALL_TRAPS_ENA
	wr_kpsw		VOL_TEMP1, $0
@


1.31
log
@In progress addition of LISP support.
@
text
@d9 1
a9 1
 * rcs = $Header: loMem.s,v 1.30 88/08/27 14:25:36 nelson Exp $ SPRITE (Berkeley)
d1105 2
a1106 1
	 * take some action.
d1109 3
a1112 1
	WRITE_STATUS_REGS(MACH_INTR_MASK_0, SAFE_TEMP3)
d1155 2
d2977 3
d2985 1
a2985 2
	rd_kpsw		VOL_TEMP1
	or		VOL_TEMP1, VOL_TEMP1, $MACH_KPSW_INTR_TRAP_ENA
@


1.30
log
@Changed around the way signals are handled so that the state is aved
on the user's stack when a signal handler is called.
@
text
@d9 1
a9 1
 * rcs = $Header: loMem.s,v 1.29 88/08/26 11:51:49 nelson Exp $ SPRITE (Berkeley)
d136 1
d233 1
d324 1
d326 37
d1380 9
d1433 12
d1453 4
a1456 1
	jump		cmpTrap_BadSWPTrap
d1458 14
a1471 1
	jump		cmpTrap_TestFaultTrap
d1493 10
d1504 10
a1513 4
cmpTrap_BadSWPTrap:
	add_nt		OUTPUT_REG1, r0, $MACH_USER_BAD_SWP
	jump		UserErrorTrap
	Nop
d1515 10
a1524 5
cmpTrap_TestFaultTrap:
	add_nt		CUR_PC_REG, CUR_PC_REG, $8
	add_nt		NEXT_PC_REG, r0, $0
	jump		FaultIntr
	Nop
d1526 12
d1556 8
a1575 1
	rd_insert	VOL_TEMP2
a1577 1
	wr_insert	VOL_TEMP2
d2024 261
d3317 11
@


1.29
log
@Eliminated old debugging stuff which was overwriting code.  Also fixed
a bug in the fault handler.
@
text
@d9 1
a9 1
 * rcs = $Header: loMem.s,v 1.28 88/08/23 10:18:41 mendel Exp $ SPRITE (Berkeley)
d1134 1
a1134 1
	cmp_br_delayed	eq, VOL_TEMP1, $0, vmFault_PC
d1146 2
d1149 15
d1194 1
a1194 1
1:	jump		ReturnTrap
d1212 1
a1212 1
	jump		ReturnTrap
d1258 13
d1293 18
a1614 1
	add_nt		RETURN_VAL_REG, r0, $MACH_NORM_RETURN
d1800 4
d1838 4
a1841 1
	 * Enable traps.
d1843 4
a1846 27
	or		VOL_TEMP1, KPSW_REG, $MACH_KPSW_ALL_TRAPS_ENA
	wr_kpsw		VOL_TEMP1, $0
	/*
	 * Go back to the previous window.  Note that the previous window
	 * contains the saved values of the current PC, the next PC and
	 * the kpsw.
	 */
	rd_special	VOL_TEMP1, pc
	return		VOL_TEMP1, $12
	Nop
	/*
	 * The saved KPSW tells us where to continue when we return from the
	 * trap.  Extract out this info and disable traps.  Note that we don't
	 * just use the KPSW directly because the user could have screwed 
	 * it up.  The only part that we are interested in is whether to 
	 * return to the current PC or the next PC.
	 */
	LD_PC_RELATIVE(SAFE_TEMP1, sigReturnTrap_Const1)
	and		VOL_TEMP1, KPSW_REG, SAFE_TEMP1
	rd_kpsw		VOL_TEMP2
	and		VOL_TEMP2, VOL_TEMP2, $~MACH_KPSW_ALL_TRAPS_ENA
	or		KPSW_REG, VOL_TEMP1, VOL_TEMP2
	wr_kpsw		KPSW_REG, $0
	/*
	 * Switch over to the kernel stacks and save the user state.
	 */
	SAVE_USER_STATE()
a1853 1
	rd_insert	VOL_TEMP1
a1855 1
	wr_insert	VOL_TEMP1
a2096 1
	rd_insert	VOL_TEMP1
a2098 1
	wr_insert	VOL_TEMP1
d2112 2
a2113 1
 *	Need to start the process off calling a signal handler.
d2116 20
a2138 5
	 * Grab the current state pointer in OUTPUT_REG5 so that we can use
	 * it after we shift the window.
	 */
	ld_32		OUTPUT_REG5, r0, $_machCurStatePtr
	/*
d2143 3
a2145 4
	ld_32		OUTPUT_REG1, OUTPUT_REG5, $MACH_SIG_NUM_OFFSET
	ld_32		OUTPUT_REG2, OUTPUT_REG5, $MACH_SIG_CODE_OFFSET
	add_nt		OUTPUT_REG3, SPILL_SP, $0
	Nop
a2146 28
	 * Enable traps so that we can safely advance the window.
	 */
	or		VOL_TEMP1, KPSW_REG, $MACH_KPSW_ALL_TRAPS_ENA
	wr_kpsw		VOL_TEMP1, $0
	/*
	 * Advance to the window where the signal handler will execute.
	 */
	call		1f
	Nop
1:
	/*
	 * Put the pc to execute in VOL_TEMP1.  Note that INPUT_REG5 contains
	 * the pointer to the machine struct that was in OUTPUT_REG5 before
	 * we shifted the window.
	 */
	ld_32		VOL_TEMP1, INPUT_REG5, $MACH_NEW_CUR_PC_OFFSET
	/*
	 * See if we have enough window memory.
	 */
	ld_32		VOL_TEMP2, INPUT_REG5, $MACH_MAX_SWP_OFFSET
	rd_special	VOL_TEMP3, swp
	sub		VOL_TEMP2, VOL_TEMP2, $(2 * MACH_SAVED_REG_SET_SIZE)
	cmp_br_delayed	ule, VOL_TEMP3, VOL_TEMP2, 1f
	nop
	call		_MachGetWinMem
	nop
1:
	/*
d2150 1
d2152 1
a2152 2
	rd_kpsw		VOL_TEMP2
	or		VOL_TEMP2, VOL_TEMP2, $MACH_KPSW_CUR_MODE
d2154 1
a2154 1
	wr_kpsw		VOL_TEMP2, $0
@


1.28
log
@Various bug fixes in window overflow/underflow and signal routines.
@
text
@d9 1
a9 1
 * rcs = $Header: loMem.s,v 1.27 88/08/21 14:50:06 mendel Exp $ SPRITE (Berkeley)
d466 1
d485 1
a511 2
	SAVE_CC_STATE()

d1157 1
a1157 1
	 * MachVMDataFault(faultType, PC, kpsw).
d1209 18
d1233 14
@


1.27
log
@Fixed bug in call signal handlers.
@
text
@d9 1
a9 1
 * rcs = $Header: loMem.s,v 1.26 88/08/21 14:37:26 nelson Exp $ SPRITE (Berkeley)
d553 8
a560 1
	VERIFY_SWP(winOvFlow_SaveWindow)	/* Verify that the SWP is OK. */
d661 1
a661 1
	cmp_br_delayed	le, VOL_TEMP2, VOL_TEMP1, winOvFlow_Return
d698 10
d772 1
a772 1
	cmp_br_delayed	gt, VOL_TEMP2, VOL_TEMP1, winUnFlow_Return
d1811 2
a1813 5
	VERIFY_SWP(getWinMemTrap_GoodSWP)
	USER_SWP_ERROR()
	/* DOESN'T RETURN */

getWinMemTrap_GoodSWP:
a1821 1
	rd_insert	VOL_TEMP1
a1823 1
	wr_insert	VOL_TEMP1
d1825 4
a1828 2
	 * Restore the current and next PCs and then do a
	 * normal return from trap.
d1830 10
a1839 2
	add_nt		CUR_PC_REG, NON_INTR_TEMP1, $0
	add_nt		NEXT_PC_REG, NON_INTR_TEMP2, $0
d1902 21
d1924 1
d2084 17
d2102 1
a2102 1
	 * Assume that the user's signal handler will to a "return r10,r0,8".
a2104 1
	ld_32		VOL_TEMP1, INPUT_REG5, $MACH_NEW_CUR_PC_OFFSET
d2106 1
a2106 1
	or		VOL_TEMP2, VOL_TEMP2, $MACH_KPSW_CUR_MODE|MACH_KPSW_ALL_TRAPS_ENA
@


1.26
log
@*** empty log message ***
@
text
@d9 1
a9 1
 * rcs = $Header: loMem.s,v 1.25 88/08/18 18:42:16 nelson Exp $ SPRITE (Berkeley)
d2041 1
d2043 1
a2043 1
	add_nt		RETURN_ADDR_REG, r0, $SigReturnAddr
@


1.25
log
@Got simple user processes working.
@
text
@d9 1
a9 1
 * rcs = $Header: loMem.s,v 1.24 88/08/17 12:00:11 nelson Exp $ SPRITE (Berkeley)
d1560 1
a1560 1
	 * the user stack pointer - numArgs * 4 to point to the base
d1564 3
a1566 3
	Nop
	sll		VOL_TEMP3, SAFE_TEMP3, $3
	add_nt		VOL_TEMP1, VOL_TEMP1, VOL_TEMP3
d1568 6
d1586 1
d1600 1
a1600 1
	st_32		VOL_TEMP2, SPILL_SP, $-56
d1604 1
a1604 1
	st_32		VOL_TEMP2, SPILL_SP, $-48
d1608 1
a1608 1
	st_32		VOL_TEMP2, SPILL_SP, $-40
d1612 1
a1612 1
	st_32		VOL_TEMP2, SPILL_SP, $-32
d1616 1
a1616 1
	st_32		VOL_TEMP2, SPILL_SP, $-24
d1620 1
a1620 1
	st_32		VOL_TEMP2, SPILL_SP, $-16
d1622 1
a1622 1
	ld_32		VOL_TEMP2, VOL_TEMP1, $-8	/* 1 args */
d1624 1
a1624 1
	st_32		VOL_TEMP2, SPILL_SP, $-8
a1627 4
	/*
	 * Set the kernel's spill stack.
	 */
	add_nt		SPILL_SP, VOL_TEMP3, $0
@


1.24
log
@Added check for interrupt on ld, st, and test and set instructions and
fixed a couple of bugs.
@
text
@d9 1
a9 1
 * rcs = $Header: loMem.s,v 1.23 88/08/10 13:27:10 nelson Exp $ SPRITE (Berkeley)
d256 1
a256 1
 * Jump table to return the operand from an instruction.  Also here
d259 33
a291 1
OpRecov:
a321 1

d1641 2
d1669 1
a1669 1
	add_nt		RETURN_ADDR_REG, RETURN_ADDR_REG, $16
d1868 2
d2709 2
a2710 2
	jump_reg	PREV_SRC1_REG, $OpRecov  /* Retrieve value of first op. */
	jump	        parse41		 	/* Value is returned in r31 */
a2712 1
	add_nt		r30, r31, $0		/* Move to src1's register. */
d2791 1
a2791 1
	jump_reg	PREV_SRC2_REG, $OpRecov  /* Recover 2nd operand register */
@


1.23
log
@Saves and restores globals on interrupt.
@
text
@d9 1
a9 1
 * rcs = $Header: loMem.s,v 1.22 88/08/09 18:38:01 nelson Exp $ SPRITE (Berkeley)
d244 1
d946 2
d949 22
d1153 2
a1154 1
	 * faulted at in VOL_TEMP2.
d1158 4
d1166 1
d1168 2
a2020 5
 *	NOTE: We are called with all traps disabled.  This is important
 *	      because since we are going back to previous windows we can't
 *	      afford to take interrupts because otherwise we would
 *	      trash some windows.
 *
d2176 9
d2195 1
d2240 4
@


1.22
log
@Middle of spur port.
@
text
@d9 1
a9 1
 * rcs = $Header: loMem.s,v 1.21 88/08/01 15:05:58 mendel Exp $ SPRITE (Berkeley)
d1002 16
d1022 14
d2498 4
d2504 3
@


1.21
log
@Patched bug in Mach_TestAndSet.
@
text
@d9 1
a9 1
 * rcs = $Header: loMem.s,v 1.20 88/07/31 22:37:15 mendel Exp $ SPRITE (Berkeley)
d129 2
a130 1
	.globl _MachVMFault 
d615 2
a616 2
	Nop							/*  check from */
								/*  kernel mode */
d950 3
a952 2
	 * Save the insert register in a safe temporary, disable all but
	 * non-maskable interrupts and then enable all traps.
a957 1
	wr_kpsw		KPSW_REG, $MACH_KPSW_ALL_TRAPS_ENA
d974 1
d986 1
d1002 1
d1031 1
a1031 1
	cmp_br_delayed	eq, VOL_TEMP1, $0, vmFault_GetDataAddr
d1044 1
a1044 1
vmFault_GetDataAddr:
d1050 26
d1077 1
d1090 1
a1090 1
	cmp_br_delayed	ge, VOL_TEMP1, VOL_TEMP2, vmFault_NoData
d1092 3
d1108 2
a1109 1
	 * We now have the data address in VOL_TEMP2
d1111 4
a1114 16
	add_nt		OUTPUT_REG3, r0, $1	/* 3rd arg is TRUE to indicate */
						/*   that there is a data addr */
	add_nt		OUTPUT_REG4, VOL_TEMP2, $0	/* 4th arg is the data */
							/*    addr. */
	cmp_br_delayed	always, r0, r0, vmFault_CallHandler
	Nop
vmFault_NoData:
	add_nt		OUTPUT_REG3, r0, $0		/* 3rd arg is FALSE */
							/*   (no data addr) */
vmFault_CallHandler:
	add_nt		OUTPUT_REG1, SAFE_TEMP1, $0	/* 1st arg is fault type. */
	add_nt		OUTPUT_REG2, CUR_PC_REG, $0	/* 2nd arg is the  */
							/*   faulting PC. */
	add_nt		OUTPUT_REG5, KPSW_REG, $0	/* 5th arg to  */
							/*   MachVMFault is the */
							/*   kpsw */
d1116 1
a1116 1
	call		_MachVMFault
d1560 2
a1561 2
	 * instruction.  This forces to advance the window by a call
	 * and then do a jump_reg.  Unfortunately this means that we can't
d1655 2
a1656 1
	 * it up.
d1658 2
a1659 2
	LD_PC_RELATIVE(VOL_TEMP1, sigReturnTrap_Const1)
	and		VOL_TEMP1, KPSW_REG, VOL_TEMP1
d1670 2
a1671 1
	 * Reenable traps.
a1674 7
	/*
	 * The old hold mask was stored on the spill stack.  Pass it
	 * as an arg to the signal return routine and restore the spill
	 * stack pointer.
	 */
	ld_32		OUTPUT_REG1, SPILL_SP, $0
	add_nt		SPILL_SP, SPILL_SP, $8
a1917 8
	/* 
	 * Make room on the spill stack for the signal context stuff 
	 * (it contains 8 bytes, 4 for the hold mask and 4 for filler) and
	 * save the old hold mask on the spill stack.
	 */
	ld_32		VOL_TEMP1, OUTPUT_REG5, $MACH_OLD_HOLD_MASK_OFFSET
	sub		SPILL_SP, SPILL_SP, $8
	st_32		VOL_TEMP1, SPILL_SP, $0
@


1.20
log
@Made the code at label Interrupt preserve the Imask register. Make
Mach_{Enable,Disable}Intr updates of Imask atomic.            ^^^Made
@
text
@d9 1
a9 1
 * rcs = $Header: loMem.s,v 1.19 88/07/29 11:25:06 nelson Exp $ SPRITE (Berkeley)
d2458 3
a2460 1
	test_and_set	RETURN_VAL_REG, INPUT_REG1, $0
@


1.19
log
@SPUR port in progress.
@
text
@d9 1
a9 1
 * rcs = $Header: loMem.s,v 1.18 88/07/23 12:49:58 nelson Exp $ SPRITE (Berkeley)
a883 1
	st_32		r0, r0, $-1
d937 2
a938 1
	 * as an arg to the interrupt routine.
d941 2
a942 2
	READ_STATUS_REGS(MACH_INTR_MASK_0, SAFE_TEMP1)
	and		OUTPUT_REG1, OUTPUT_REG1, SAFE_TEMP1
d975 1
a975 3
	ld_32		SAFE_TEMP1, r0, $_machIntrMask
	nop
	WRITE_STATUS_REGS(MACH_INTR_MASK_0, SAFE_TEMP1)
d993 1
a993 3
	ld_32		SAFE_TEMP1, r0, $_machIntrMask
	nop
	WRITE_STATUS_REGS(MACH_INTR_MASK_0, SAFE_TEMP1)
d1005 1
a1005 3
	ld_32		SAFE_TEMP1, r0, $_machIntrMask
	nop
	WRITE_STATUS_REGS(MACH_INTR_MASK_0, SAFE_TEMP1)
d2368 2
a2369 1
	ld_32		SAFE_TEMP1, r0, $_machNonmaskableIntrMask
d2371 1
d2398 3
d2404 1
d2427 3
d2433 1
@


1.18
log
@Successfully use non-maskable timer to refresh wells.
@
text
@d9 1
a9 1
 * rcs = $Header: loMem.s,v 1.17 88/07/20 18:29:10 nelson Exp $ SPRITE (Berkeley)
d143 1
a143 1
	jump PowerUp		# Reset - Jump to powerup sequencer.
d147 1
a147 1
	jump ErrorTrap		# Error
d151 1
a151 1
	jump WinOvFlow		# Window overflow
d155 1
a155 1
	jump WinUnFlow		# Window underflow
d159 1
a159 1
	jump FaultIntr		# Fault or interrupt
d163 1
a163 1
	jump FPUExcept		# FPU Exception
d167 1
a167 1
	jump Illegal		# Illegal op, kernel mode access violation
d171 1
a171 1
	jump Fixnum		# Fixnum, fixnum_or_char, generation
d175 1
a175 1
	jump Overflow		# Integer overflow
d179 1
a179 1
	jump CmpTrap		# Compare trap instruction
d184 1
a184 1
	jump CmpTrap		# Hack for BARB
d241 2
a242 1
ccStatePtr:			.long 0xff03b000
d520 1
a520 1
	VERIFY_SWP(winOvFlow_SaveWindow)	# Verify that the SWP is OK.
d527 1
a527 1
	add_nt		SAFE_TEMP2, r1, $0	# Save r1
d534 1
a534 1
	wr_special	cwp, VOL_TEMP1, $4	# Move forward one window.
d537 1
d598 1
a598 1
	wr_special	cwp, r1, $-4		# Move back one window.
d601 1
a601 1
	add_nt		r1, SAFE_TEMP2, $0	# Restore r1
d613 3
a615 3
	cmp_br_delayed	eq, SAFE_TEMP1, r0, winOvFlow_Return	# No need to
	Nop							#  check from
								#  kernel mode
d661 1
a661 1
	add_nt		SAFE_TEMP2, r1, $0	# Save r1
d666 1
d668 1
a668 1
	wr_special	cwp, VOL_TEMP1,  $-8	# move back two windows
d703 1
a703 1
	wr_special	cwp,  r1, $8	# move back ahead two windows
d705 1
a705 1
	add_nt		r1, SAFE_TEMP2, $0	# Restore r1
d707 1
a707 1
	add_nt		r2, SAFE_TEMP3, $0	# Restore r2
d714 3
a716 3
	cmp_br_delayed	eq, SAFE_TEMP1, $0, winUnFlow_Return	# No need to
	Nop							#   check from
								#   kernel mode
d729 3
a731 3
	rd_special	VOL_TEMP1, pc	# Return from traps and then
	return_trap	VOL_TEMP1, $12	#   take the compare trap to
	Nop				#   get back in in kernel mode.
d830 1
a830 1
PowerUp: 			# Jump to power up sequencer
d858 2
d880 1
a880 1
	 * Read the fault/error status register.
d883 3
d902 4
a905 3
	extract		SAFE_TEMP1, SAFE_TEMP1, $2
	and		SAFE_TEMP1, SAFE_TEMP1, $0xf
	cmp_br_delayed	ne, SAFE_TEMP1, r0, VMFault
d907 1
d909 12
d941 2
d1023 1
a1023 1
 *	in SAFE_TEMP1 before we were called.
d1028 1
d1059 1
a1059 1
	extract		VOL_TEMP1, SAFE_TEMP2, $3  	# Opcode <31:25> -> 
d1061 1
a1061 1
	srl		VOL_TEMP1, VOL_TEMP1, $1	# Opcode <07:01> ->
d1063 1
a1063 1
	and		VOL_TEMP1, VOL_TEMP1, $0xf0	# Get upper 4 bits.
d1082 4
a1085 4
	add_nt		OUTPUT_REG3, r0, $1	# 3rd arg is TRUE to indicate
						#   that there is a data addr
	add_nt		OUTPUT_REG4, VOL_TEMP2, $0	# 4th arg is the data
							#    addr.
d1089 2
a1090 2
	add_nt		OUTPUT_REG3, r0, $0		# 3rd arg is FALSE
							#   (no data addr)
d1092 6
a1097 6
	add_nt		OUTPUT_REG1, SAFE_TEMP1, $0	# 1st arg is fault type.
	add_nt		OUTPUT_REG2, CUR_PC_REG, $0	# 2nd arg is the 
							#   faulting PC.
	add_nt		OUTPUT_REG5, KPSW_REG, $0	# 5th arg to 
							#   MachVMFault is the
							#   kpsw
a1102 4
	/* 
	 * Clear fault bits.
	 */
	st_external	SAFE_TEMP1, r0, $MACH_FE_STATUS_2|MACH_CO_WR_REG	
d1156 2
a1157 2
	sll		VOL_TEMP1, SAFE_TEMP1, $3	# Multiple by 8 to
							#   get offset
d1221 13
d1480 1
a1480 1
	ld_32		VOL_TEMP2, VOL_TEMP1, $-56	# 7 args
d1484 1
a1484 1
	ld_32		VOL_TEMP2, VOL_TEMP1, $-48	# 6 args
d1488 1
a1488 1
	ld_32		VOL_TEMP2, VOL_TEMP1, $-40	# 5 args
d1492 1
a1492 1
	ld_32		VOL_TEMP2, VOL_TEMP1, $-32	# 4 args
d1496 1
a1496 1
	ld_32		VOL_TEMP2, VOL_TEMP1, $-24	# 3 args
d1500 1
a1500 1
	ld_32		VOL_TEMP2, VOL_TEMP1, $-16	# 2 args
d1504 1
a1504 1
	ld_32		VOL_TEMP2, VOL_TEMP1, $-8	# 1 args
d2000 1
d2044 1
d2052 3
a2054 3
	srl		r3, r3, $1	# Read the swp and then shift it so
	srl		r3, r3, $1	#    it aligns with the cwp.  That is
	srl		r3, r3, $1	#    swp<9:7> -> swp<4:2>
d2063 1
a2063 1
	wr_special	cwp, r3, $0	# Set the cwp to the window to save.
d2065 1
a2065 1
					# Increment the swp by one window.
d2087 2
a2088 2
	wr_special	cwp, r2, $0x4	# Move back to the current window.
	wr_special	swp, r1, $0	# Update the swp.
d2219 17
d2237 1
d2268 1
a2268 1
 * MachContextSwitch(fromProcPtr, toProcPtr) --
d2276 2
a2277 2
	.globl	_MachContextSwitch
_MachContextSwitch:
d2531 8
a2538 8
	add_nt		SAVED_R10, r10, $0	# Save "return" address
	add_nt		SAVED_R14, r14, $0	# Save r14 and r15 because
	add_nt		SAVED_R15, r15, $0	#  these will be used to 
						#  recover operands.
	extract		OPCODE, TRAP_INST, $3	# Opcode <31:25> -> <07:01>
	srl		OPCODE, OPCODE, $1	# Opcode <07:01> -> <06:00>
	sll		SRC1_REG, TRAP_INST, $1	# s1 <19:15> to <20:16>
	extract		SRC1_REG, SRC1_REG, $2	# s1 <20:16> to <04:00>
d2540 2
a2541 2
	srl		SRC2_REG, TRAP_INST, $1	# s2 <13:09> to <12:08>
	extract		SRC2_REG, SRC2_REG, $1	# s2 <12:08> to <04:00>
d2559 1
a2559 1
	call		parse1up		# Back to trap handler window.
d2578 3
a2580 3
parse4:	sll		PREV_SRC1_REG, PREV_SRC1_REG, $2	# s1 = s1 * 4
	jump_reg	PREV_SRC1_REG, $OpRecov  # Retrieve value of first op.
	jump	        parse41		 	# Value is returned in r31
d2583 2
a2584 2
	add_nt		r30, r31, $0		# Move to src1's register.
	call 	       	parse5			# Get back to trap window. 
d2613 3
a2615 3
	and		SRC2_VAL, TRAP_INST, $0x1fff	# Extract immediate val.
	add_nt		PARSE_TEMP1, TRAP_INST, $0	# Check for a 
	srl		PARSE_TEMP1, PARSE_TEMP1, $1	#   negative number
d2619 1
a2619 1
	add_nt		SRC2_VAL, SRC2_VAL, $~0x1fff	# Sign extend SRC2_VAL
d2658 6
a2663 6
parse6:	sll		PREV_SRC2_REG, PREV_SRC2_REG, $2  # Multiply src2 reg
							  #   by 4 to represent
							  #   offset in jump 
							  #   table.
	jump_reg	PREV_SRC2_REG, $OpRecov  # Recover 2nd operand register
	jump 		parse7			 #   and put value in r31
d2675 3
a2677 3
	sll		PARSE_TEMP1, TRAP_INST, $3	# Dest<24:20> move to <27:23>
	sll		PARSE_TEMP1, PARSE_TEMP1, $2	# Move to <29:25>
	extract		PARSE_TEMP1, PARSE_TEMP1, $3	# Move to <5:1>  
d2679 7
a2685 7
	insert		PARSE_TEMP1, r0, PARSE_TEMP1	# Move to <13:09>
	srl		PARSE_TEMP2, PARSE_TEMP1, $1	# Sign-bit <13> to <12>
	and		PARSE_TEMP2, PARSE_TEMP2, $0x1000 # Check for negative
	cmp_br_delayed	eq, PARSE_TEMP2, $0, parse_pos    #    number
	and 		PARSE_TEMP1, PARSE_TEMP1,$0x1e00  # Mask out valid bits.
	add_nt		PARSE_TEMP1, PARSE_TEMP1,$~0x1fff  # Sign extend 
							  #    PARSE_TEMP2.
d2687 2
a2688 2
	and		PARSE_TEMP2, TRAP_INST, $0x01ff	     # Put together into
	or		SRC2_VAL, PARSE_TEMP1,  PARSE_TEMP2  #    14-bit value.
d2696 4
a2699 4
	add_nt		r10, SAVED_R10, $0		# Restore pre-parse r10
	add_nt		r14, SAVED_R14, $0		# Restore pre-parse r14
	add_nt		r15, SAVED_R15, $0		# Restore pre-parse r15
	jump_reg	RET_ADDR, r0			# Go back to caller
@


1.17
log
@Initial spur boot
@
text
@d9 1
a9 1
 * rcs = $Header: loMem.s,v 1.16 88/07/19 17:08:46 nelson Exp $ SPRITE (Berkeley)
d133 2
d222 3
d231 2
d234 3
d319 2
a320 2
#define	MEM_SLOT_MASK		0xff000000
#define KERN_FIRST_PHYS_PAGE	2
d322 4
d327 1
a327 1
#define	KERN_PT_BASE	(MEM_SLOT_MASK | (KERN_PT_FIRST_PAGE * VMMACH_PAGE_SIZE))
d344 1
a344 1
	LD_CONSTANT(r3, MEM_SLOT_MASK | (KERN_PT_FIRST_PAGE << VMMACH_PAGE_FRAME_SHIFT) | VMMACH_RESIDENT_BIT | VMMACH_CACHEABLE_BIT | VMMACH_KRW_URO_PROT | VMMACH_REFERENCED_BIT | VMMACH_MODIFIED_BIT)
d357 1
d364 1
a364 1
	LD_CONSTANT(r3, MEM_SLOT_MASK | ((KERN_PT_FIRST_PAGE - 4) << VMMACH_PAGE_FRAME_SHIFT) | VMMACH_RESIDENT_BIT | VMMACH_CACHEABLE_BIT | VMMACH_KRW_URO_PROT | VMMACH_REFERENCED_BIT | VMMACH_MODIFIED_BIT)
d373 1
d381 1
a381 1
	LD_CONSTANT(r3, MEM_SLOT_MASK | (KERN_FIRST_PHYS_PAGE << VMMACH_PAGE_FRAME_SHIFT) | VMMACH_RESIDENT_BIT | VMMACH_CACHEABLE_BIT | VMMACH_KRW_URO_PROT | VMMACH_REFERENCED_BIT | VMMACH_MODIFIED_BIT)
d443 6
a450 1

d459 10
d511 3
d527 5
d538 57
a594 16
	st_40		r10, r1, $0
	st_40		r11, r1, $8
	st_40		r12, r1, $16
	st_40		r13, r1, $24
	st_40		r14, r1, $32
	st_40		r15, r1, $40
	st_40		r16, r1, $48
	st_40		r17, r1, $56
	st_40		r18, r1, $64
	st_40		r19, r1, $72
	st_40		r20, r1, $80
	st_40		r21, r1, $88
	st_40		r22, r1, $96
	st_40		r23, r1, $104
	st_40		r24, r1, $112
	st_40		r25, r1, $120
d600 5
d660 3
d667 31
a697 16
	ld_40		r10, r1,   $0
	ld_40		r11, r1,   $8
	ld_40		r12, r1,  $16
	ld_40		r13, r1,  $24
	ld_40		r14, r1,  $32
	ld_40		r15, r1,  $40
	ld_40		r16, r1,  $48
	ld_40		r17, r1,  $56
	ld_40		r18, r1,  $64
	ld_40		r19, r1,  $72
	ld_40		r20, r1,  $80
	ld_40		r21, r1,  $88
	ld_40		r22, r1,  $96
	ld_40		r23, r1, $104
	ld_40		r24, r1, $112
	ld_40		r25, r1, $120
d703 3
d916 1
a916 1
	 * as a arg to the interrupt routine.
a923 1

d925 2
a926 1
	 * Save the insert register in a safe temporary.
d929 4
a932 1

a933 6
	 * Disable interrupts but enable all other traps.
	 */
	and		VOL_TEMP2, KPSW_REG, $(~MACH_KPSW_INTR_TRAP_ENA)
	or		VOL_TEMP2, VOL_TEMP2, $MACH_KPSW_ALL_TRAPS_ENA
	wr_kpsw		VOL_TEMP2, $0
	/*
a938 1

a942 1

d951 3
a953 2
	or		VOL_TEMP1, KPSW_REG, $MACH_KPSW_ALL_TRAPS_ENA
	wr_kpsw		VOL_TEMP1, $0
d965 3
a967 2
	 * Restore the insert register and then do a normal return
	 * from trap in case the user process needs to take some action.
d970 4
d982 1
a982 1
	 * Restore insert register and kpsw and return.
d985 4
d991 1
a991 2
	return_trap	NEXT_PC_REG, $0
	Nop
d1145 4
a1166 2
	jump		cmpTrap_RefreshTrap
	Nop
d1301 38
d1533 1
a1533 1
	st_40		RETURN_VAL_REG, SAFE_TEMP1, $(MACH_TRAP_REGS_OFFSET + 8 * MACH_RETURN_VAL_REG)
d1741 1
a1741 2
	or		VOL_TEMP1, KPSW_REG, $MACH_KPSW_CUR_MODE
	wr_kpsw		VOL_TEMP1, $0
d1744 2
d1765 1
a1765 1
	return_trap	NEXT_PC_REG, $0
d1768 1
a1768 1
	return_trap	CUR_PC_REG, $0
d1935 1
d1937 1
d1945 10
a1954 10
	st_40		r0, VOL_TEMP1, $0
	st_40		r1, VOL_TEMP1, $8
	st_40		r2, VOL_TEMP1, $16
	st_40		r3, VOL_TEMP1, $24
	st_40		r4, VOL_TEMP1, $32
	st_40		r5, VOL_TEMP1, $40
	st_40		r6, VOL_TEMP1, $48
	st_40		r7, VOL_TEMP1, $56
	st_40		r8, VOL_TEMP1, $64
	st_40		r9, VOL_TEMP1, $72
d1978 22
a1999 22
	st_40		r10, r1, $80
	st_40		r11, r1, $88
	st_40		r12, r1, $96
	st_40		r13, r1, $104
	st_40		r14, r1, $112
	st_40		r15, r1, $120
	st_40		r16, r1, $128
	st_40		r17, r1, $136
	st_40		r18, r1, $144
	st_40		r19, r1, $152
	st_40		r20, r1, $160
	st_40		r21, r1, $168
	st_40		r22, r1, $176
	st_40		r23, r1, $184
	st_40		r24, r1, $192
	st_40		r25, r1, $200
	st_40		r26, r1, $208
	st_40		r27, r1, $216
	st_40		r28, r1, $224
	st_40		r29, r1, $232
	st_40		r30, r1, $240
	st_40		r31, r1, $248
d2031 16
a2046 16
	st_40		r10, r1, $0
	st_40		r11, r1, $8
	st_40		r12, r1, $16
	st_40		r13, r1, $24
	st_40		r14, r1, $32
	st_40		r15, r1, $40
	st_40		r16, r1, $48
	st_40		r17, r1, $56
	st_40		r18, r1, $64
	st_40		r19, r1, $72
	st_40		r20, r1, $80
	st_40		r21, r1, $88
	st_40		r22, r1, $96
	st_40		r23, r1, $104
	st_40		r24, r1, $112
	st_40		r25, r1, $120
d2093 22
a2114 22
	ld_40		r10, r1, $80
	ld_40		r11, r1, $88
	ld_40		r12, r1, $96
	ld_40		r13, r1, $104
	ld_40		r14, r1, $112
	ld_40		r15, r1, $120
	ld_40		r16, r1, $128
	ld_40		r17, r1, $136
	ld_40		r18, r1, $144
	ld_40		r19, r1, $152
	ld_40		r20, r1, $160
	ld_40		r21, r1, $168
	ld_40		r22, r1, $176
	ld_40		r23, r1, $184
	ld_40		r24, r1, $192
	ld_40		r25, r1, $200
	ld_40		r26, r1, $208
	ld_40		r27, r1, $216
	ld_40		r28, r1, $224
	ld_40		r29, r1, $232
	ld_40		r30, r1, $240
	ld_40		r31, r1, $248
d2135 9
a2143 9
	ld_40		r1, VOL_TEMP1, $8
	ld_40		r2, VOL_TEMP1, $16
	ld_40		r3, VOL_TEMP1, $24
	ld_40		r4, VOL_TEMP1, $32
	ld_40		r5, VOL_TEMP1, $40
	ld_40		r6, VOL_TEMP1, $48
	ld_40		r7, VOL_TEMP1, $56
	ld_40		r8, VOL_TEMP1, $64
	ld_40		r9, VOL_TEMP1, $72
d2163 2
d2172 2
d2178 5
d2279 53
d2336 1
a2336 1
 *	Disable interrupts.
d2348 3
a2350 3
	rd_kpsw		VOL_TEMP1
	and		VOL_TEMP1, VOL_TEMP1, $(~MACH_KPSW_INTR_TRAP_ENA)
	wr_kpsw		VOL_TEMP1, $0
d2361 1
a2361 1
 *	Enable interrupts.
d2373 3
a2375 3
	rd_kpsw		VOL_TEMP1
	or		VOL_TEMP1, VOL_TEMP1, $MACH_KPSW_INTR_TRAP_ENA
	wr_kpsw		VOL_TEMP1, $0
d2403 25
@


1.16
log
@*** empty log message ***
@
text
@d9 1
a9 1
 * rcs = $Header: loMem.s,v 1.15 88/07/16 15:39:01 nelson Exp $ SPRITE (Berkeley)
d135 2
d187 8
d231 1
d310 2
a311 1
#define	KERN_PT_FIRST_PAGE	1024
d314 1
a314 1
#define	KERN_PT2_BASE	(KERN_PT_BASE + VMMACH_SEG_PT_SIZE / 4 * VMMACH_KERN_PT_QUAD)
a316 14
 * Zero out all of the physical memory where the kernel page tables are
 * going to be at.
 */
	LD_CONSTANT(r1, KERN_PT_BASE)
	add_nt		r2, r2, $0
	LD_CONSTANT(r3, VMMACH_NUM_PT_PAGES * VMMACH_PAGE_SIZE)

1:	add_nt		r4, r1, r2
	st_32		r0, r4, $0
	add_nt		r2, r2, $4
	cmp_br_delayed	lt, r2, r3, 1b
	Nop

/*
d338 18
d365 1
a365 1
	LD_CONSTANT(r3, MEM_SLOT_MASK | VMMACH_RESIDENT_BIT | VMMACH_CACHEABLE_BIT | VMMACH_KRW_URO_PROT | VMMACH_REFERENCED_BIT | VMMACH_MODIFIED_BIT)
d397 1
a397 1
	LD_CONSTANT(r2, VMMACH_CACHE_SIZE)
d408 1
a408 1
	LD_CONSTANT(r2, VMMACH_CACHE_SIZE)
d416 14
d445 2
d459 2
a460 1
	call		_main
d469 1
d747 2
d750 11
d771 1
a771 1
	READ_STATUS_REGS(MACH_FE_STATUS_0, VOL_TEMP1)
d781 1
a781 1
	cmp_br_delayed	eq, VOL_TEMP1, r0, Interrupt
d788 1
a788 1
	extract		SAFE_TEMP1, VOL_TEMP1, $2
d2000 28
d2111 1
a2111 1
	return		RETURN_ADDR_REG, $0
@


1.15
log
@Added the UART mapping and the refresh and single step traps and made the
debugger be entered with all traps enabled but interrupts off.
@
text
@d9 1
a9 1
 * rcs = $Header: loMem.s,v 1.14 88/07/15 12:25:44 nelson Exp $ SPRITE (Berkeley)
a126 1
	.globl _MachCallDebugger
d1856 2
a1857 2
	st_32		r1, VOL_TEMP1, $MACH_TRAP_SWP_OFFSET
	st_32		r2, VOL_TEMP1, $MACH_TRAP_CWP_OFFSET
@


1.14
log
@*** empty log message ***
@
text
@d9 1
a9 1
 * rcs = $Header: loMem.s,v 1.11 88/07/05 15:09:37 nelson Exp $ SPRITE (Berkeley)
d306 16
a321 1
 * In this code registers have the following meaning:
d422 2
a423 1
 *	4) Jump to the main function.
d944 1
a944 1
	 * or cur PC.
d987 2
d1007 1
a1007 5

cmpTrap_TestFaultTrap:
	add_nt		CUR_PC_REG, CUR_PC_REG, $8
	add_nt		NEXT_PC_REG, r0, $0
	jump		FaultIntr
d1035 11
a1067 1

d1104 32
d1137 3
d2111 2
a2112 1
	return	RETURN_ADDR_REG, $8
@


1.13
log
@Simulate window overflow and underflow, saving and restoring state and
faults and interrupts.
@
text
@a321 2
	cmp_br_delayed	eq, r2, $0, 2f
	Nop
d326 1
a326 1
	cmp_br_delayed	always, r0, r0, 1b
a327 1
2:
a337 2
	cmp_br_delayed	eq, r2, $0, 2f
	Nop
d342 1
a342 1
	cmp_br_delayed	always, r0, r0, 1b
a343 1
2:
@


1.12
log
@Changed to handle the new signal stuff.
@
text
@d179 6
d209 1
a209 6
 * The other way to do it is
 *
 *	LD_CONSTANT(rt1, _machCurStatePtr)
 *	ld_32	rt1, rt1, $0
 *
 * which is a several instruction sequence.
d279 1
d295 2
a296 3
 *	KERN_PT_VIRT_BASE	The virtual address of the kernel's page tables.
 *	KERN_PT_PHYS_BASE	The physical address of the kernel's page tables
 *	KERN_PT2_VIRT_BASE	The virtual address of the 2nd level kernel
a297 2
 *	KERN_PT2_PHYS_BASE	The physical address of the 2nd level kernel
 *				page tables.
d299 1
d302 2
a303 4
#define	KERN_PT_VIRT_BASE	(KERN_PT_FIRST_PAGE * VMMACH_PAGE_SIZE)
#define	KERN_PT_PHYS_BASE	(0xff000000 + KERN_PT_VIRT_BASE)
#define	KERN_PT2_VIRT_BASE	(KERN_PT_VIRT_BASE + VMMACH_SEG_PT_SIZE / 4 * VMMACH_KERN_PT_QUAD)
#define	KERN_PT2_PHYS_BASE	(0xff000000 + KERN_PT2_VIRT_BASE)
d308 1
a308 1
 *	r1:	The base address of the page tables.
d316 1
a316 1
	LD_CONSTANT(r1, KERN_PT2_PHYS_BASE)
d318 1
a318 1
	LD_CONSTANT(r3, (KERN_PT_FIRST_PAGE << VMMACH_PAGE_FRAME_SHIFT) | VMMACH_RESIDENT_BIT | VMMACH_CACHEABLE_BIT | VMMACH_KRW_URO_PROT)
d336 3
a338 3
	LD_CONSTANT(r1, KERN_NUM_PAGES)
	add_nt		r2, r0, $KERN_PT_FIRST_PAGE
	LD_CONSTANT(r3, VMMACH_RESIDENT_BIT | VMMACH_CACHEABLE_BIT | VMMACH_KRW_URO_PROT)
d367 1
a367 1
	LD_CONSTANT(r1, KERN_PT2_PHYS_BASE)
d372 1
a372 1
	LD_CONSTANT(r1, 0x3000000)
d381 12
d395 1
a395 1
	wr_special	cwp, r0, $1
d400 1
d402 6
d422 4
d702 2
d710 1
a710 1
	LD_CONSTANT(SAFE_TEMP1, MACH_KPSW_USE_CUR_PC)
d716 1
d718 5
d811 2
a812 1
	jump		returnTrap_NormReturn
d867 2
a868 2
	FETCH_CUR_INSTRUCTION(VOL_TEMP1)
	extract		VOL_TEMP1, VOL_TEMP1, $3  	# Opcode <31:25> -> 
d878 2
a879 2
	 * address to return to in VOL_TEMP1 and the PC of the faulting 
	 * instruction is already in CUR_PC_REG.
d881 1
d929 2
d937 2
a938 2
	LD_CONSTANT(SAFE_TEMP1, MACH_KPSW_USE_NEXT_PC)
	or		KPSW_REG, KPSW_REG, SAFE_TEMP1
d943 2
a944 2
	FETCH_CUR_INSTRUCTION(r17)
	and		SAFE_TEMP1, r17, $0x1ff 
d972 2
a973 2
	add_nt		VOL_TEMP2, VOL_TEMP1, $16
	jump_reg	VOL_TEMP2, $0
d975 2
a982 2
	jump		BreakpointTrap
	Nop
d993 2
d996 6
d1151 1
d1171 2
a1172 2
	sll		VOL_TEMP3, SAFE_TEMP3, $2
	add_nt		VOL_TEMP1, VOL_TEMP1, VOL_TEMP2
d1197 1
a1197 1
	ld_32		VOL_TEMP2, VOL_TEMP1, $-28	# 7 args
d1199 1
a1199 1
	st_32		VOL_TEMP2, SPILL_SP, $-28
d1201 1
a1201 1
	ld_32		VOL_TEMP2, VOL_TEMP1, $-24	# 6 args
d1203 1
a1203 1
	st_32		VOL_TEMP2, SPILL_SP, $-24
d1205 1
a1205 1
	ld_32		VOL_TEMP2, VOL_TEMP1, $-20	# 5 args
d1207 1
a1207 1
	st_32		VOL_TEMP2, SPILL_SP, $-20
d1209 1
a1209 1
	ld_32		VOL_TEMP2, VOL_TEMP1, $-16	# 4 args
d1211 1
a1211 1
	st_32		VOL_TEMP2, SPILL_SP, $-16
d1213 1
a1213 1
	ld_32		VOL_TEMP2, VOL_TEMP1, $-12	# 3 args
d1215 1
a1215 1
	st_32		VOL_TEMP2, SPILL_SP, $-12
d1217 1
a1217 1
	ld_32		VOL_TEMP2, VOL_TEMP1, $-8	# 2 args
d1219 1
a1219 1
	st_32		VOL_TEMP2, SPILL_SP, $-8
d1221 1
a1221 1
	ld_32		VOL_TEMP2, VOL_TEMP1, $-4	# 1 args
d1223 1
a1223 1
	st_32		VOL_TEMP2, SPILL_SP, $-4
d1335 2
d1357 1
a1357 1
	LD_CONSTANT(VOL_TEMP1, (MACH_KPSW_USE_CUR_PC | MACH_KPSW_USE_NEXT_PC))
d1442 3
d1501 1
a1501 1
	LD_CONSTANT(VOL_TEMP2, MACH_KPSW_USE_CUR_PC)
a1756 1
	and		r1, r1, $0x380
d1763 2
a1764 1
	srl		r3, r1, $1	# Read the swp and then shift it so
a1812 1

d2078 3
a2080 3
 *	RET_ADDR:	r18 (VOL_TEMP1)  -- Address to return to when done.
 *	DATA_VAL_REG:	r19 (VOL_TEMP2) -- Data address from instruction.
 *	TRAP_INST:	r19 (VOL_TEMP2) -- Trapping instruction.
a2108 1
	FETCH_CUR_INSTRUCTION(TRAP_INST)
@


1.11
log
@*** empty log message ***
@
text
@d9 1
a9 1
 * rcs = $Header: loMem.s,v 1.10 88/06/30 15:31:42 nelson Exp $ SPRITE (Berkeley)
d276 2
a277 1
Start:
d1300 3
a1302 1
	 * Go back to the previous window.
d1308 4
a1311 3
	 * Disable traps.  Note that the kpsw that we use now is the one
	 * that we saved in the previous window when we called the signal
	 * handler.  It will have all traps disabled.
d1313 5
d1330 3
a1332 3
	 * The old hold mask was stored in NON_INTR_TEMP1.  Also the first and
	 * second PCs were saved in CUR_PC_REG and NEXT_PC_REG.  Call
	 * the signal return handler with the old hold mask as an argument.
d1334 2
a1335 1
	add_nt		OUTPUT_REG1, NON_INTR_TEMP1, $0
d1570 2
a1571 4
	/* 
	 * Save the old hold mask in the current window.  The PCs
	 * are already saved in CUR_PC_REG and NEXT_PC_REG.  Note that the
	 * current state pointer is put in OUTPUT_REG5 so that we can use
d1575 8
a1582 3
	Nop
	ld_32		NON_INTR_TEMP1, OUTPUT_REG5, $MACH_OLD_HOLD_MASK_OFFSET
	Nop
d1584 3
a1586 1
	 * Load in the PC and the arguments to the signal handler.
d1590 1
a1590 1
	ld_32		OUTPUT_REG3, OUTPUT_REG5, $MACH_OLD_HOLD_MASK_OFFSET
d2239 1
@


1.10
log
@*** empty log message ***
@
text
@d9 1
a9 1
 * rcs = $Header: loMem.s,v 1.7 88/06/09 10:18:08 nelson Exp $ SPRITE (Berkeley)
d704 1
a704 1
	cmp_br_delayed	ne, SAFE_TEMP1, 0, VMFault
d1410 1
a1410 1
	cmp_br_delayed	eq, VOL_TEMP1, 0, returnTrap_Return
@


1.9
log
@*** empty log message ***
@
text
@d117 19
d219 2
a220 2
debugSWStackBase:		.long MACH_DEBUG_STACK_BASE
debugSpillStackEnd:		.long (MACH_DEBUG_STACK_BASE + MACH_KERN_STACK_SIZE)
d289 9
d300 5
a304 2
#define	KERN_PT_BASE		(KERN_PT_FIRST_PAGE * VMMACH_PAGE_SIZE)
#define	KERN_PT2_BASE		(KERN_PT_BASE + VMMACH_SEG_PT_SIZE / 4 * VM_KERN_PT_QUAD)
d317 1
a317 1
	LD_CONSTANT(r1, KERN_PT2_BASE)
d329 1
a329 1
	jump		1b
d337 1
a337 1
	LD_CONSTANT(r1, KERN_PT_BASE)
d348 1
a348 1
	jump		1b
d368 1
a368 1
	LD_CONSTANT(r1, KERN_PT2_BASE)
d382 9
a390 1
 * Now to jump to virtual mode through the following sequence:
d395 1
a395 1
 *	4) Jump to virtual mode.
d400 1
a400 2
	rd_special	r2, pc
	jump_reg	r2, $12
a401 13

/*
 * Now we are executing in virtual mode (hopefully).  Initialize the cwp, 
 * swp and SPILL_SP to their proper values and then jump to the main
 * function.
 */
	wr_special	cwp, r0, $1
	LD_CONSTANT(r1, MACH_STACK_BOTTOM)
	wr_special	swp, r1, $0
	LD_CONSTANT(SPILL_SP, MACH_CODE_START)

	call		_main
	Nop
d883 1
a883 1
	st_external	SAFE_TEMP1, r0, $MACH_FE_STATUS_2|MACH_WR_REG	
d1030 1
a1030 1
	add_nt		OUTPUT_REG1, r0, $MACH_BREAKPOINT_ERROR
d1079 1
a1079 1
	add_nt		OUTPUT_REG1, r0, $MACH_USER_BAD_SYS_CALL
d1186 1
d1188 2
d1207 1
a1207 1
	ld_32		VOL_TEMP2, r0, $machKcallTableOffset
d1420 1
a1420 1
	ld_32		VOL_TEMP2, r0, $machSpecialHandlingOffset
d1444 1
a1444 1
	LD_CONSTANT(VOL_TEMP2, MACH_USE_CUR_PC)
d1885 1
a1885 1
	ld_32		NON_INTR_TEMP1, r0, $statePtrOffset
@


1.8
log
@*** empty log message ***
@
text
@d125 1
a125 1
	jump Error		# Error
a246 2
	Error					# last two cases are errors
	Error
d256 2
d259 122
d443 1
a443 1
	sub_nt		VOL_TEMP1, VOL_TEMP1, $(2 * MACH_SAVED_REG_SET_SIZE)
d642 1
a642 1
Error:	
d661 2
a662 1
	or		KPSW_REG, KPSW_REG, $MACH_KPSW_USE_CUR_PC
a700 1
	 */
d716 1
a716 1
	and		VOL_TEMP2, KPSW_REG, $((~MACH_KPSW_INTR_TRAP_ENA)&0x3fff)
d718 1
a718 1
	wr_kpsw		VOL_TEMP2
d740 1
a740 1
	write_kpsw	VOL_TEMP1
d766 1
a766 1
	wr_kpsw		KPSW_REG
d804 1
a804 1
	wr_kpsw		VOL_TEMP1
d817 2
a818 1
	cmp_br_delayed	ge, VOL_TEMP1, $0x30, vmFault_NoData
d838 1
a838 1
	cmp_br_delayed	always, vmFault_CallHandler
d878 2
a879 1
	or		KPSW_REG, KPSW_REG, $MACH_KPSW_USE_NEXT_PC
d970 1
a970 1
	wr_kpsw		VOL_TEMP1
d1004 1
a1004 1
	wr_kpsw		VOL_TEMP1
d1034 1
a1034 1
	wr_kpsw		VOL_TEMP1
d1098 2
a1099 2
	 * the user stack pointer.  Then move the kernel's stack pointer 
	 * back by numArgs * 4 to point to the first arg on the spill stack.
d1103 2
a1104 2
	sll		VOL_TEMP2, SAFE_TEMP3, $2
	sub_nt		SPILL_SP, SPILL_SP, VOL_TEMP2
d1116 2
a1117 2
	 *	VOL_TEMP2:	Stack increment
	 *	VOL_TEMP3:	Temporary
d1119 2
a1120 3
	add_nt		VOL_TEMP2, r0, r0
	add_nt		VOL_TEMP3, r0, $12
	sub_nt		SAFE_TEMP3, VOL_TEMP3, SAFE_TEMP3
d1123 3
a1125 3
	rd_special	VOL_TEMP3, pc
	add_nt		VOL_TEMP3, SAFE_TEMP3, VOL_TEMP3
	jump_reg	VOL_TEMP3, $16
d1128 2
a1129 2
_MachFetchArgStart
	ld_32		VOL_TEMP3, VOL_TEMP1, VOL_TEMP2	# 7 args
d1131 1
a1131 3
	st_32		VOL_TEMP3, SPILL_SP, VOL_TEMP2
	add_nt		VOL_TEMP2, VOL_TEMP2, $4
	ld_32		VOL_TEMP3, VOL_TEMP1, VOL_TEMP2	# 6 args
d1133 1
a1133 3
	st_32		VOL_TEMP3, SPILL_SP, VOL_TEMP2
	add_nt		VOL_TEMP2, VOL_TEMP2, $4
	ld_32		VOL_TEMP3, VOL_TEMP1, VOL_TEMP2	# 5 args
d1135 1
a1135 3
	st_32		VOL_TEMP3, SPILL_SP, VOL_TEMP2
	add_nt		VOL_TEMP2, VOL_TEMP2, $4
	ld_32		VOL_TEMP3, VOL_TEMP1, VOL_TEMP2	# 4 args
d1137 1
a1137 3
	st_32		VOL_TEMP3, SPILL_SP, VOL_TEMP2
	add_nt		VOL_TEMP2, VOL_TEMP2, $4
	ld_32		VOL_TEMP3, VOL_TEMP1, VOL_TEMP2	# 3 args
d1139 1
a1139 3
	st_32		VOL_TEMP3, SPILL_SP, VOL_TEMP2
	add_nt		VOL_TEMP2, VOL_TEMP2, $4
	ld_32		VOL_TEMP3, VOL_TEMP1, VOL_TEMP2	# 2 args
d1141 1
a1141 3
	st_32		VOL_TEMP3, SPILL_SP, VOL_TEMP2
	add_nt		VOL_TEMP2, VOL_TEMP2, $4
	ld_32		VOL_TEMP3, VOL_TEMP1, VOL_TEMP2	# 1 args
d1143 14
a1156 2
	st_32		VOL_TEMP3, SPILL_SP, VOL_TEMP2
	add_nt		VOL_TEMP2, VOL_TEMP2, $4
d1158 1
a1158 1
_MachFetchArgEnd
d1160 3
d1200 1
a1200 1
1f:
d1238 1
a1238 1
	wr_kpsw		VOL_TEMP1
d1269 1
a1269 1
	wr_kpsw		VOL_TEMP1
d1281 1
a1281 1
	wr_kpsw		KPSW_REG
d1291 1
a1291 1
	wr_kpsw		VOL_TEMP1
d1299 1
a1299 1
	call		_MachSigReturn()
d1328 1
a1328 1
	wr_kpsw		VOL_TEMP1
d1364 1
a1364 1
	wr_kpsw		KPSW_REG
d1408 1
a1408 1
	wr_kpsw		VOL_TEMP1
d1416 3
a1418 2
	and		VOL_TEMP1, KPSW_REG, $MACH_USE_CUR_PC
	cmp_br_delayed	eq, VOL_TEMP1, $MACH_USE_CUR_PC, 1f
d1447 1
a1447 1
	wr_kpsw		VOL_TEMP1
d1478 1
a1478 1
	wr_kpsw		VOL_TEMP1
d1509 1
a1509 1
	wr_kpsw		VOL_TEMP1
d1530 1
a1530 1
	wr_kpsw		KPSW_REG
d1553 1
a1553 1
	wr_kpsw		VOL_TEMP1
d1568 1
a1568 1
	wr_kpsw		VOL_TEMP2
d1626 2
a1627 2
	and		VOL_TEMP3, VOL_TEMP3, $((~MACH_KPSW_INTR_TRAP_ENA)&0x3fff)
	wr_kpsw		VOL_TEMP3
d1629 1
a1629 1
	return_reg	VOL_TEMP3, $12
d1719 1
a1719 1
	wr_kpsw		r5
d1743 4
a1746 4
	ld_32		r2, r1, $MACH_REG_STATE_CWP
	ld_32		r3, r1, $MACH_REG_STATE_SWP
	wr_special	cwp, r2
	wr_special	swp, r3
d1825 1
a1825 1
	and		KPSW_REG, KPSW_REG, $((~MACH_KPSW_ALL_TRAPS_ENA)&0x3fff)
d1918 2
a1919 2
	and		VOL_TEMP1, VOL_TEMP1, $((~MACH_KPSW_INTR_TRAP_ENA)&0x3fff)
	wr_kpsw		VOL_TEMP1
d1944 1
a1944 1
	wr_kpsw		VOL_TEMP1
d2056 1
a2056 1
	CallDebugger(MACH_BAD_SRC_REG)
d2096 1
a2096 1
	cmp_br_delayed	always, parse5b
d2109 2
a2110 2
	add_nt		SRC2_VAL, SRC2_VAL, $0x2000	# Sign extend SRC2_VAL
	cmp_br_delayed	always, parse_end
d2136 1
a2136 1
	CallDebugger(MACH_BAD_SRC_REG)
d2174 1
a2174 1
	add_nt		PARSE_TEMP1, PARSE_TEMP1,$0x2000  # Sign extend 
@


1.7
log
@*** empty log message ***
@
text
@d9 1
a9 1
 * rcs = $Header: loMem.s,v 1.6 88/06/07 21:05:12 nelson Exp $ SPRITE (Berkeley)
d67 1
a67 1
 * When user processes trap into the kernel the kernel will switch over
d195 2
a196 3
_machMaxSysCall			.long 0
numArgsPtr			.long _machNumArgs
debugStatePtr			.long _machDebugState
d198 5
d274 1
a274 1
	USER_ERROR(MACH_USER_BAD_SWP)
d359 1
a359 1
	USER_ERROR(MACH_USER_BAD_SWP)
d434 1
a434 1
	USER_ERROR(MACH_USER_FPU_EXCEPT)
d454 1
a454 1
	USER_ERROR(MACH_USER_ILLEGAL)
d474 1
a474 1
	USER_ERROR(MACH_USER_FIXNUM)
d494 1
a494 1
	USER_ERROR(MACH_USER_OVERFLOW)
d535 6
d575 2
a576 1
	 * Read the interrupt status register.
d578 1
d581 4
d592 1
a592 2
	 * Disable interrupts but enable all other traps.  Save the kpsw
	 * in a safe temporary.
d594 1
a594 2
	read_kpsw	SAFE_TEMP2
	and		VOL_TEMP2, SAFE_TEMP2, $((~MACH_KPSW_INTR_TRAP_ENA)&0x3fff)
d600 1
a600 1
	and		VOL_TEMP2, SAFE_TEMP2, $MACH_KPSW_PREV_MODE
d617 1
a617 2
	read_kpsw	VOL_TEMP1
	or		VOL_TEMP1, VOL_TEMP1, $MACH_KPSW_INTR_TRAP_ENA
d630 1
a630 1
	 * Restore the kpsw and insert register and then do a normal return
a633 1
	wr_kpsw		SAFE_TEMP2
d641 1
a641 1
	 * Restore insert register and kpsw.
d644 1
a644 1
	wr_kpsw		SAFE_TEMP2
a659 1
	read_kpsw	SAFE_TEMP2			# Save KPSW
d663 1
a663 1
	and		VOL_TEMP1, SAFE_TEMP2, $MACH_KPSW_PREV_MODE
d681 1
a681 1
	or		VOL_TEMP1, SAFE_TEMP2, $MACH_KPSW_ALL_TRAPS_ENA
d702 1
a702 1
	rd_insert	SAFE_TEMP3
d707 1
a707 1
	wr_insert	SAFE_TEMP3
d724 1
a724 1
	add_nt		OUTPUT_REG5, SAFE_TEMP2, $0	# 5th arg to 
d731 1
a731 1
vmFault_ReturnFromTrap:
d733 1
a733 1
	 * Clear fault bit and restore the kpsw.
a735 1
	wr_kpsw		SAFE_TEMP2
d751 7
d761 1
a761 1
	and             SAFE_TEMP1, r17, $0x1ff 
d765 1
a765 2
	rd_kpsw		SAFE_TEMP2
	and		VOL_TEMP1, SAFE_TEMP2, $MACH_KPSW_PREV_MODE
d771 1
a771 1
	VERIFY_SWP(cmpTrap_CheckType)
a793 2
	jump		UserErrorTrap
	Nop
d798 1
a798 1
	jump		cmpTrap_CallDebugger
d800 10
a809 2
cmpTrap_CallDebugger:
	CALL_DEBUGGER(r0, MACH_DEBUGGER_CALL)
d811 25
d842 1
a842 2
	rd_kpsw		VOL_TEMP1
	and		VOL_TEMP2, VOL_TEMP1, $MACH_KPSW_PREV_MODE
d845 1
a845 1
	or		VOL_TEMP1, VOL_TEMP1, $MACH_KPSW_ALL_TRAPS_ENA
a851 2
	and		VOL_TEMP1,VOL_TEMP1,$((~MACH_KPSW_ALL_TRAPS_ENA)&0x3fff)
	wr_kpsw		VOL_TEMP1
d858 1
d862 37
d909 1
a909 2
	rd_kpsw		VOL_TEMP1
	or		VOL_TEMP1, VOL_TEMP1, $MACH_KPSW_ALL_TRAPS_ENA
d933 2
a934 4
	rd_kpsw		VOL_TEMP1
	and		VOL_TEMP1,VOL_TEMP1,$((~MACH_KPSW_ALL_TRAPS_ENA)&0x3fff)
	wr_kpsw		VOL_TEMP1
	jump		returnTrap_NormReturn
d974 2
a975 3
	 * the user stack pointer.  Then move the user stack pointer and 
	 * kernel's stack pointer back by numArgs * 4 to point to the first
	 * arg on the spill stack.
d1062 6
a1067 1
	 * Call the routine.
d1070 1
a1070 1
	ld_32		VOL_TEMP2, VOL_TEMP2, VOL_TEMP3
d1077 1
a1077 1
	jump_reg	VOL_TEMP1, $0
d1079 2
d1090 2
a1091 4
	rd_kpsw		VOL_TEMP1
	and		VOL_TEMP1,VOL_TEMP1,$((~MACH_KPSW_ALL_TRAPS_ENA)&0x3fff)
	wr_kpsw		VOL_TEMP1
	jump		returnTrap_NormReturn
d1101 1
a1101 1
 *	respectively and the error type was stored in NON_INTR_TEMP1.
d1106 2
a1107 3
	add_nt		OUTPUT_REG1, NON_INTR_TEMP1, $0
	add_nt		CUR_PC_REG, NON_INTR_TEMP2, $0
	add_nt		NEXT_PC_REG, NON_INTR_TEMP3, $0
d1111 1
a1111 2
	rd_kpsw		SAFE_TEMP1
	or		VOL_TEMP1, SAFE_TEMP1, $MACH_KPSW_ALL_TRAPS_ENA
d1121 1
a1121 1
	 * Restore the kpsw and do a normal return trap.
a1122 1
	wr_kpsw		SAFE_TEMP1
d1142 2
a1143 3
	rd_kpsw		SAFE_TEMP1
	or		SAFE_TEMP2, SAFE_TEMP1, $MACH_KPSW_ALL_TRAPS_ENA
	wr_kpsw		SAFE_TEMP2
d1145 1
a1145 1
	 * Get back to the previous window.
d1151 3
a1153 1
	 * Disable traps.
d1155 1
a1155 1
	wr_kpsw		SAFE_TEMP1
d1157 1
a1157 2
	 * We are now in the previous window.  Switch over to the kernel
	 * stacks and save the user state.
d1164 2
a1165 1
	wr_kpsw		SAFE_TEMP2
d1176 1
a1176 4
	/*
	 * Restore the kpsw.
	 */
	wr_kpsw		SAFE_TEMP1
d1201 1
a1201 2
	rd_kpsw		SAFE_TEMP2
	or		VOL_TEMP1, SAFE_TEMP2, $MACH_KPSW_ALL_TRAPS_ENA
d1211 1
a1211 1
	 * Restore the kpsw plus the current and next PCs and then do a
a1213 1
	wr_kpsw		SAFE_TEMP2
d1216 2
a1217 1
	jump		returnTrap_NormReturn
d1228 3
a1230 2
 *	RETURN_VAL_REG.  If it is not one of MACH_NORM_RETURN or 
 *	MACH_FAILED_COPY then it is a kernel error value.
d1236 5
d1247 2
d1255 1
a1255 2
	rd_kpsw		VOL_TEMP1
	and		VOL_TEMP1, VOL_TEMP1, $MACH_KPSW_PREV_MODE
a1265 1
	Nop
d1278 4
a1281 2
	rd_kpsw		VOL_TEMP1
	or		VOL_TEMP1, VOL_TEMP1, $MACH_KPSW_CUR_MODE
d1286 11
d1319 1
a1319 2
	rd_kpsw		VOL_TEMP1
	or		VOL_TEMP1, VOL_TEMP1, $MACH_KPSW_ALL_TRAPS_ENA
d1333 6
a1338 1
	return		RETURN_ADDR_REG, $0
d1342 29
d1381 1
a1381 2
	rd_kpsw		SAFE_TEMP1
	or		VOL_TEMP1, SAFE_TEMP1, $MACH_KPSW_ALL_TRAPS_ENA
a1386 1
	wr_kpsw		SAFE_TEMP1
d1393 2
a1394 1
	jump		returnTrap_NormReturn
d1403 1
d1425 1
a1425 2
	rd_kpsw		VOL_TEMP1
	or		VOL_TEMP1, VOL_TEMP1, $MACH_KPSW_ALL_TRAPS_ENA
d1439 1
a1439 1
	or		VOL_TEMP2, VOL_TEMP2, $MACH_KPSW_CUR_MODE
d1465 1
a1465 2
	rd_kpsw		VOL_TEMP3
	st_32		VOL_TEMP3, VOL_TEMP1, $MACH_REG_STATE_KPSW_OFFSET
d1540 1
d1542 1
d1555 1
a1555 1
	and		r3, r3, $0x1c0
d1587 2
a1588 5
	rd_special	VOL_TEMP3, swp
	st_32		VOL_TEMP3, VOL_TEMP1, $MACH_TRAP_SWP_OFFSET
	rd_special	VOL_TEMP3, cwp
	sub_nt		VOL_TEMP3, VOL_TEMP3, $4
	st_32		VOL_TEMP3, VOL_TEMP1, $MACH_TRAP_CWP_OFFSET
d1610 3
a1612 1
	 * Restore the current PC, next PC, insert register, kpsw and the upsw.
d1614 6
a1619 8
	ld_32		r1, VOL_TEMP1, $MACH_REG_STATE_KPSW_OFFSET
	ld_32		r2, VOL_TEMP1, $MACH_REG_STATE_UPSW_OFFSET
	ld_32		r3, VOL_TEMP1, $MACH_REG_STATE_INSERT_OFFSET
	ld_32		CUR_PC_REG, VOL_TEMP1, $MACH_REG_STATE_CUR_PC_OFFSET
	ld_32		NEXT_PC_REG, VOL_TEMP1, $MACH_REG_STATE_NEXT_PC_OFFSET
	wr_kpsw		r1
	wr_special	upsw, r2, $0
	wr_insert	r3
d1621 3
a1623 1
	 * Restore the previous window from the state struct.
a1624 4
	add_nt		r1, VOL_TEMP1, $0
	rd_special	r2, cwp
	wr_special	cwp, r2, $-4	# Go back one window.
	Nop
d1627 20
a1646 20
        ld_40		r12, r1, $96
        ld_40		r13, r1, $104
        ld_40		r14, r1, $112
        ld_40		r15, r1, $120
        ld_40		r16, r1, $128
        ld_40		r17, r1, $136
        ld_40		r18, r1, $144
        ld_40		r19, r1, $152
        ld_40		r20, r1, $160
        ld_40		r21, r1, $168
        ld_40		r22, r1, $176
        ld_40		r23, r1, $184
        ld_40		r24, r1, $192
        ld_40		r25, r1, $200
        ld_40		r26, r1, $208
        ld_40		r27, r1, $216
        ld_40		r28, r1, $224
        ld_40		r29, r1, $232
        ld_40		r30, r1, $240
        ld_40		r31, r1, $248
d1648 1
a1648 1
	 * Switch back to the current window.
d1650 1
a1650 1
	wr_special	cwp, r2, $0
d1652 2
d1655 10
d1685 1
a1685 1
 * MachRunUserProc(regStatePtr)
d1694 1
a1694 1
	 * Disable all traps.
d1696 3
a1698 3
	rd_kpsw		VOL_TEMP1
	and		VOL_TEMP1, VOL_TEMP1, $((~MACH_KPSW_ALL_TRAPS_ENA)&0x3fff)
	wr_kpsw		VOL_TEMP1
d1700 1
a1700 2
	 * Change the cwp so that it points to the next window after the
	 * one that we are about to restore to.
d1702 2
a1703 2
	add_nt		r1, INPUT_REG1, $0
	ld_32		r2, r1, $MACH_REG_STATE_CWP_OFFSET
a1704 19
	wr_special	cwp, r2, $4
	Nop
	/*
	 * Now we are in the window after the one that we are supposed to
	 * restore to.  Now restore the windows.
	 */
	add_nt		VOL_TEMP1, r1, $0
	rd_special	VOL_TEMP2, pc
	add_nt		VOL_TEMP2, VOL_TEMP2, $16
	jump		RestoreState, $0
	Nop
	/*
	 * Set the previous mode bit in the kpsw to indicate that we came
	 * from user mode and then do a normal return from trap.
	 */
	rd_kpsw		VOL_TEMP1
	or		VOL_TEMP1, VOL_TEMP1, $MACH_KPSW_PREV_MODE
	wr_kpsw		VOL_TEMP1
	jump		returnTrap_NormReturn
d1744 1
a1744 1
	jump		SaveState, $0
d1763 1
a1763 1
	jump		RestoreState, $0
d1768 1
a1768 1
	return		r10, $0
d1772 74
d1862 12
a1873 12
 *	RET_ADDR:	r17 (VOL_TEMP1)  -- Address to return to when done.
 *	DATA_VAL_REG:	r18 (VOL_TEMP2) -- Data address from instruction.
 *	TRAP_INST:	r18 (VOL_TEMP2) -- Trapping instruction.
 *	OPCODE:		r19 (VOL_TEMP3) -- Opcode.
 *	CALLER_TEMP1	r20 (SAFE_TEMP1) -- Temporary reserved for caller.
 *	CALLER_TEMP2	r21 (SAFE_TEMP2) -- Temporary reserved for caller.
 *	CALLER_TEMP3	r22 (SAFE_TEMP3) -- Temporary reserved for caller.
 *	PARSE_TEMP1:	r23 -- One temporary to use.
 *	PARSE_TEMP2:	r24 -- 2nd temporary to use.
 *	SAVED_R10:	r25 -- Place to save r10.
 *	SAVED_R14:	r27 -- Place to save r14.
 *	SAVED_R15:	r28 -- Place to save r15.
d1882 9
a1890 8
#define	RET_ADDR		VOL_TEMP1
#define	TRAP_INST		VOL_TEMP2
#define	OPCODE			VOL_TEMP3
#define	PARSE_TEMP1		rt7
#define	PARSE_TEMP2		rt8
#define	SAVED_R10		rt9
#define	SAVED_R14		r27
#define	SAVED_R15		r28
d1955 1
d1958 2
a1959 2
	and		PARSE_TEMP1, OPCODE, $0x20	 # Have store if bits 
	cmp_br_delayed  ne, PARSE_TEMP1, $0, parse_store #     <7:4> = 2
d1963 1
a1963 1
	 * Parsing load or test&set.  Check for register or immediate value
d1965 2
a1966 3
	extract		PARSE_TEMP1, TRAP_INST, $1	# <15:8> to <7:0>
	and		PARSE_TEMP1, PARSE_TEMP1, $0x40	# Check for immediate 
							#     2nd oprd
d2058 1
a2058 6
	add_nt		SRC1_VAL, SRC1_VAL, SRC2_VAL	
	and		PARSE_TEMP1, OPCODE, $0x02	# Check for 40-bit
	sll		PARSE_TEMP1, PARSE_TEMP1, $1	# If 0x02, then 40-bit
	add_nt		PARSE_TEMP1, PARSE_TEMP1, $0x3ff8   # Gen up mask to 
	and		DATA_VAL_REG, SRC1_VAL, PARSE_TEMP1 #  to make 8-bit
							    #  aligned if 40-bit
d2065 4
@


1.6
log
@*** empty log message ***
@
text
@d9 1
a9 1
 * rcs = $Header: loMem.s,v 1.5 88/06/03 10:57:04 nelson Exp $ SPRITE (Berkeley)
d19 12
a30 9
 * When user processes trap into the kernel the kernel uses the user saved
 * window stack rather than its own.  This is done for simplicity: we only
 * have to worry about one stack.  However, since the SWP can be written
 * in user mode the kernel has to be careful before using the user's
 * SWP.  Thus before the kernel does anything with a user process the first
 * thing that it does is verify that the SWP is valid.  It can do this
 * by looking at the bounds on the SWP that are present in each processes
 * machine state info.  An SWP is valid if it satisfies the following
 * constraints:
d32 1
a32 2
 *	    swp >= min_swp_offset - MACH_SAVED_WINDOW_SIZE and
 *	    swp + MACH_OVERFLOW_EXTRA <= max_swp_offset
d34 1
a34 6
 * The MACH_OVERFLOW_EXTRA worth of data at the top is there in case we need 
 * to save windows when we are executing in the kernel on behalf of a user
 * process.  It also ensures that we have room to save the current window
 * if we take a window overflow trap from user mode.  The
 * MACH_SAVED_WINDOW_SIZE at the bottom is in case an interrupt comes between
 * the time that we do an underflow and we try to get more window memory.
d36 7
a42 5
 * If a user's SWP is found to be bogus then the kernel switches over to
 * the kernel's saved window stack and the user process is killed.  If
 * the SWP is bogus when an interrupt occurs, then the user process is not
 * killed until after the interrupt is handled.  All memory between 
 * min_swp_offset and max_swp_offset is wired down.
d44 1
a44 9
 * More memory is allocated for a user process's saved window stack after
 * it takes a underflow or overflow fault right before it returns to user mode.
 * Since while a process is in the kernel user windows can be saved on the
 * saved window stack without allocating more memory, memory is allocated
 * not when there is only MACH_OVERFLOW_EXTRA available on the stack but
 * when there is less than MACH_OVERFLOW_EXTRA + MACH_OVERFLOW_SLOP where
 * MACH_OVERFLOW_SLOP is equal to the maximum amount of user windows (8) that
 * can be saved on a user's saved window stack while it is executing in
 * the kernel.
d46 19
d91 10
d191 1
a191 1
_proc_RunningProcesses: 	.long 0
d195 2
d269 1
a269 1
	VERIFY_SWP(winOvFlow_SaveWindow, 0)	# Verify that the SWP is OK.
d305 4
a308 1
	 * See if we have to allocate more memory.
d317 1
a317 1
	add_nt		VOL_TEMP2, VOL_TEMP2, $(MACH_OVERFLOW_EXTRA + MACH_OVERFLOW_SLOP)
d354 1
a354 1
	VERIFY_SWP(winUnFlow_RestoreWindow, MACH_SAVED_WINDOW_SIZE)
d385 3
a387 1
	 * See if need more memory.
d396 2
a397 1
	cmp_br_delayed	ge, VOL_TEMP2, VOL_TEMP1, winUnFlow_Return
d517 1
a517 1
	SWITCH_TO_KERNEL_SPILL_STACK()
a529 1
	SWITCH_TO_KERNEL_SPILL_STACK()
d533 1
a533 2
	READ_STATUS_REG(MACH_FE_STATUS_0, VOL_TEMP1)

d551 1
d567 2
a568 1
	READ_STATUS_REG(MACH_INTR_STATUS_0,OUTPUT_REG1)
d593 1
a593 1
	VERIFY_SWP(interrupt_GoodSWP, 0)
d596 3
a598 3
	 * We have a bogus user swp.  Switch over to the kernel's saved
	 * window stack and take the interrupt.  After taking the interrupt
	 * kill the user process.
d600 1
a600 6
	ld_32		VOL_TEMP1, r0, $_machCurStatePtr
	Nop
	ld_32		VOL_TEMP2, VOL_TEMP1, $MACH_KERN_STACK_START_OFFSET
	wr_special	swp, VOL_TEMP2, $0
	wr_special	cwp, r0, $1
	Nop
d612 3
a614 2
interrupt_KernMode:
	call 		_MachInterrupt
d617 2
a618 1
	 * Clear the interrupt status register.
d620 4
a623 1
	CLR_INTR_STATUS(0xffffffff)
d625 3
d629 1
a629 1
	 * Restore user stack pointer, insert register and kpsw.
a630 1
	RESTORE_USER_SPILL_SP()
a648 3
	add_nt		OUTPUT_REG5, SAFE_TEMP2, $0	# 5th arg to 
							#   MachVMFault is the
							#   kpsw
d650 1
a650 1
	 * Enable all traps.
d652 3
a654 2
	or		VOL_TEMP2, VOL_TEMP2, $MACH_KPSW_ALL_TRAPS_ENA
	wr_kpsw		VOL_TEMP2
d656 1
a656 1
	 * Check kernel or user mode.
d658 2
a659 7
	and		VOL_TEMP2, SAFE_TEMP2, $MACH_KPSW_PREV_MODE
	cmp_br_delayed	eq, VOL_TEMP2, $0, vmFault_GetDataAddr
	Nop
	VERIFY_SWP(vmFault_GetDataAddr, 0)
	add_nt		OUTPUT_REG1, r0, $MACH_USER_BAD_SWP
	call		_MachUserError
	Nop
d662 4
d667 11
d684 1
a684 5
	/*
	 * All instructions besides loads, stores and test-and-set instructions
	 * have opcodes greater than 0x20.
	 */
	cmp_br_delayed	gt, VOL_TEMP1, $0x20, vmFault_NoData
d691 1
d696 1
d713 3
d735 1
a735 1
 *	and vectoring to the right spot to handle trap.
d740 3
a742 5
	SWITCH_TO_KERNEL_SPILL_STACK()
	rd_kpsw		VOL_TEMP1
	or		VOL_TEMP1, VOL_TEMP1, $MACH_KPSW_ALL_TRAPS_ENA
	wr_kpsw		VOL_TEMP1

d744 8
a751 2
	and             VOL_TEMP1, r17, $0x1ff        # Get trap number

d753 1
a753 3
	 * Verify the SWP for all but user error traps.  On user error traps
	 * we can't user VERIFY_SWP because the reason that we are trapping
	 * may be because the SWP is bogus.
d755 2
a756 6
	cmp_br_delayed	eq, VOL_TEMP1, $MACH_USER_ERROR_TRAP, 1f
	Nop
	VERIFY_SWP(1f, 0)
	add_nt		OUTPUT_REG1, r0, $MACH_BAD_USER_SWP
	call		_MachUserError
	Nop
d758 3
a760 2
1:
	cmp_br_delayed	gt, VOL_TEMP1, $MACH_MAX_TRAP_TYPE, cmpTrap_BadTrapType
d762 2
d765 6
a770 1
	sll		VOL_TEMP1, VOL_TEMP1, $3	# Multiple by 8 to
d792 2
a793 2
	 * in kernel mode call the debugger.  Otherwise call
	 * the user error routine.
d799 2
d824 33
d858 153
a1025 4
	cmp_br_delayed	eq, OUTPUT_REG1, $MACH_USER_BAD_SWP, 1f
	Nop
	VERIFY_SWP(2f, 0)
1:
d1027 1
a1027 2
	 * Switch over to the kernel's saved window stack since our SWP is
	 * bogus.
d1029 6
a1034 8
	ld_32		VOL_TEMP1, r0, $_machCurStatePtr
	Nop
	ld_32		VOL_TEMP2, VOL_TEMP1, $MACH_KERN_STACK_START
	wr_special	swp, VOL_TEMP2, $0
	wr_special	cwp, r0, $1
	Nop
	add_nt		OUTPUT_REG1, r0, $MACH_USER_BAD_SWP
2:
d1040 1
a1040 1
	 * Disable all traps and do a normal return trap.
d1042 1
a1042 3
	rd_kpsw		VOL_TEMP1
	and		VOL_TEMP1,VOL_TEMP1,$((~MACH_KPSW_ALL_TRAPS_ENA)&0x3fff)
	wr_kpsw		VOL_TEMP1
d1052 3
a1054 1
 *	the saved info when we called the signal handler.
d1062 3
a1064 3
	rd_kpsw		VOL_TEMP1
	or		VOL_TEMP1, VOL_TEMP1, $MACH_KPSW_ALL_TRAPS_ENA
	wr_kpsw		VOL_TEMP1
d1072 1
a1072 5
	 * We are now in the previous window.  The user stack pointer was saved
	 * in NON_INTR_TEMP1 and the old hold mask in NON_INTR_TEMP2.  Also
	 * the first and second PCs were saved in CUR_PC_REG and NEXT_PC_REG.
	 * Restore the stack pointer and then call the signal return handler
	 * with the old hold mask as an argument.
d1074 17
a1090 1
	add_nt		OUTPUT_REG1, NON_INTR_TEMP2, $0
a1095 6
	 * Store the new user stack pointer value into the mach struct.
	 */
	ld_32		VOL_TEMP1, r0, $_machCurStatePtr
	Nop
	st_32		NON_INTR_TEMP1, VOL_TEMP1, $MACH_TRAP_USP_OFFSET
	/*
d1098 1
a1098 3
	rd_kpsw		VOL_TEMP1
	and		VOL_TEMP1, VOL_TEMP1, $((~MACH_KPSW_ALL_TRAPS_ENA)&0x3fff)
	wr_kpsw		VOL_TEMP1
d1108 3
a1110 1
 *	Get more memory for the window stack.
d1115 2
a1116 4
	VERIFY_SWP(1f, 0)
	add_nt		OUTPUT_REG1, r0, $MACH_USER_BAD_SWP
	call		_MachUserError
	Nop
d1118 2
a1119 1
1:
d1127 1
a1127 1
	 * Call _MachGetWinMem(swp)
a1128 1
	rd_special	OUTPUT_REG1, swp
d1134 1
a1134 1
	 * Restore the kpsw plush the current and next PCs and then do a
d1140 1
a1140 1
	jump		ReturnTrap
d1170 2
a1171 2
	rd_kpsw		SAFE_TEMP2
	and		VOL_TEMP1, SAFE_TEMP2, $MACH_KPSW_PREV_MODE
d1176 2
d1179 2
a1180 2
	ld_32		VOL_TEMP1, r0, $proc_RunningProcesses
	ld_32		VOL_TEMP2, r0, $machSpecialHandlingOffset
d1183 2
d1192 1
a1192 1
	 * Restore the spill sp and put us back into user mode.
d1194 4
a1197 6
	ld_32		VOL_TEMP1, r0, $_machCurStatePtr
	Nop
	ld_32		SPILL_SP, VOL_TEMP1, $MACH_TRAP_USP_OFFSET
	Nop
	or		SAFE_TEMP2, SAFE_TEMP2, $MACH_KPSW_CUR_MODE
	wr_kpsw		SAFE_TEMP2
d1259 1
d1261 2
a1262 7
	 * The user action routine will return TRUE (1) if a signal is
	 * pending and FALSE (0) otherwise.
	 *
	 *	MACH_CALL_SIG_HANDLER	Set up to call a signal handler
	 *				when the process continues.
	 *	MACH_SIG_PENDING	A signal needs to be taken.
	 *	MACH_DO_NOTHING		No action is pending.
d1264 1
a1264 1
	cmp_br_delayed	eq, RETURN_VAL_REG, $MACH_CALL_SIG_HANDLER, returnTrap_CallSigHandler
a1265 3
	cmp_br_delayed	eq, RETURN_VAL_REG, $MACH_SIG_PENDING, returnTrap_SigPending
	Nop
	wr_kpsw		SAFE_TEMP1
d1275 1
d1277 1
a1277 1
	 * Save the current stack pointer in the current window.  The PCs
d1284 1
a1284 2
	ld_32		NON_INTR_TEMP1, OUTPUT_REG5, $MACH_TRAP_USP_OFFSET
	ld_32		NON_INTR_TEMP2, OUTPUT_REG5, $MACH_OLD_HOLD_MASK_OFFSET
d1287 1
a1287 2
	 * Load in the PC, stack pointer and the arguments to the signal
	 * handler.
a1308 2
	ld_32		SPILL_SP, INPUT_REG5, $MACH_TRAP_USP_OFFSET
	Nop
a1315 57
 * returnTrap_SigPending --
 *
 *	We need to process a user signal.
 */
returnTrap_SigPending:
	/*
	 * Before we call the user error handler save enough state so that
	 * the user can debug his process.  Call the routine to save state.
	 * Note that we don't want to shift the window so we simulate a call
	 * by passing the return address in SAFE_REG2, where to save things
	 * in SAFE_REG1 and then doing a jump.
	 */
	ld_32		SAFE_REG1, r0, $_machCurStatePtr
	Nop
	add_nt		SAFE_REG1, SAFE_REG1, $MACH_TRAP_REG_STATE_OFFSET
	rd_special	SAFE_REG2, pc
	add_nt		SAFE_REG2, SAFE_REG2, $16
	jump		SaveState, $0
	Nop

	/*
	 * Enable all traps.
	 */
	read_kpsw	VOL_TEMP1
	or		VOL_TEMP2, VOL_TEMP2, $MACH_KPSW_ALL_TRAPS_ENA
	wr_kpsw		VOL_TEMP2

	rd_insert	VOL_TEMP2
	call		_MachHandleSig
	Nop
	wr_insert	VOL_TEMP2

	/*
	 * Restore kpsw.
	 */
	wr_kpsw		VOL_TEMP1

	/*
	 * Call the routine to restore state.  The return address is passed
	 * in SAFE_REG2 and where to restore the state from is in SAFE_REG1.
	 */
	ld_32		SAFE_REG1, r0, $_machCurStatePtr
	Nop
	add_nt		SAFE_REG1, SAFE_REG1, $MACH_TRAP_REG_STATE_OFFSET
	rd_special	SAFE_REG2, pc
	add_nt		SAFE_REG2, SAFE_REG2, $16
	jump		RestoreState, $0
	Nop

	/*
	 * Now we have processed our signal.  Go through the normal return
	 * from trap sequence.
	 */
	jump		ReturnTrap
	Nop

/*
d1322 2
a1323 2
 *	window stack.  SAFE_TEMP1 contains where to save the state to and 
 *	SAFE_TEMP2 contains the return address.  
d1327 1
a1327 1
 *	      afford to take traps or interrupts because otherwise we would
d1337 9
a1345 8
	rd_kpsw		VOL_TEMP1
	st_32		VOL_TEMP1, SAFE_TEMP1, $MACH_REG_STATE_KPSW_OFFSET
	rd_special	VOL_TEMP1, upsw
	st_32		VOL_TEMP1, SAFE_TEMP1, $MACH_REG_STATE_UPSW_OFFSET
	st_32		CUR_PC_REG, SAFE_TEMP1, $MACH_REG_STATE_CUR_PC_OFFSET
	st_32		NEXT_PC_REG, SAFE_TEMP1, $MACH_REG_STATE_NEXT_PC_OFFSET
	rd_insert	VOL_TEMP1
	st_32		VOL_TEMP1, SAFE_TEMP1, $MACH_REG_STATE_INSERT_OFFSET
d1349 11
a1359 9
	st_40		r1, SAFE_TEMP1, $8
	st_40		r2, SAFE_TEMP1, $16
	st_40		r3, SAFE_TEMP1, $24
	st_40		r4, SAFE_TEMP1, $32
	st_40		r5, SAFE_TEMP1, $40
	st_40		r6, SAFE_TEMP1, $48
	st_40		r7, SAFE_TEMP1, $56
	st_40		r8, SAFE_TEMP1, $64
	st_40		r9, SAFE_TEMP1, $72
a1360 10
	 * Set r3 to the swp aligned with the cwp so that we can use it for
	 * comparisons.
	 */
	rd_special	r3, swp		# Read the swp and then shift it so
	srl		r3, r3, $1	#    it aligns with the cwp.  That is
	srl		r3, r3, $1	#    swp<9:7> -> swp<4:2>
	srl		r3, r3, $1
	srl 		r3, r3, $1
	srl		r3, r3, $1
	/*
d1363 2
a1364 1
	add_nt		r1, SAFE_TEMP1, $0
d1366 3
a1368 3
	 * See if the current value of the cwp is just one past the swp.
	 * If so then the swp points to what we want to save in the state
	 * struct.  Otherwise we have to go back one window.
d1370 6
a1375 4
	rd_special	r2, cwp
	sub_nt		r2, r2, $4
	and		r2, r2, 0x1c0
	cmp_br_delayed	ne, r2, r3, saveState_1
a1376 32
saveState_SWP:
	/*
	 * The SWP points to the window that we want to save.  We restore
	 * the window that the SWP points to, decrement the SWP and then
	 * do the normal saving of windows.
	 */
	wr_special	cwp, r2, $0	# Go back one window
	rd_special	r5, swp
	ld_40		r10, r5, $0
	ld_40		r11, r5, $8
	ld_40		r12, r5, $16
	ld_40		r13, r5, $24
	ld_40		r14, r5, $32
	ld_40		r15, r5, $40
	ld_40		r16, r5, $48
	ld_40		r17, r5, $56
	ld_40		r18, r5, $64
	ld_40		r19, r5, $72
	ld_40		r20, r5, $80
	ld_40		r21, r5, $88
	ld_40		r22, r5, $96
	ld_40		r23, r5, $104
	ld_40		r24, r5, $112
	ld_40		r25, r5, $120
	/*
	 * Go back to the current window and make the swp point to the previous
	 * window since we just restored one.
	 */
	wr_special	cwp, r2, $4
	wr_special	swp, r5, $-MACH_SAVED_WINDOW_SIZE
	sub_nt		r3, r3, $4
	and		r3, r3, 0x1c0
a1377 1
saveState_1:
d1379 2
a1380 1
	 * Have to go back to previous active window to get register values.
a1381 2
	wr_special	cwp, r2, $0	# Go back one window.
	Nop
d1404 1
d1406 2
a1407 2
	 * Now push all of the windows before the current one
	 * onto the saved window stack.  Note that swp points to last window
d1409 2
a1410 2
	 * r3 contains the current value of the swp shifted over to align with
	 * the cwp and r2 contains the cwp - 1.
d1413 11
d1458 5
a1462 4
	rd_special	VOL_TEMP1, swp
	st_32		VOL_TEMP1, SAFE_TEMP1, $MACH_TRAP_SWP_OFFSET
	rd_special	VOL_TEMP1, cwp
	st_32		VOL_TEMP1, SAFE_TEMP1, $MACH_TRAP_CWP_OFFSET
d1464 1
a1464 1
	 * Return to our caller.
d1466 2
a1467 1
	jump_reg	SAFE_TEMP2, $0
d1477 2
a1478 2
 *	window stack.  SAFE_TEMP1 contains where to restore the state from
 *	and SAFE_TEMP2 contains the return address.
d1486 8
a1493 8
	ld_32		VOL_TEMP1, SAFE_TEMP1, $MACH_REG_STATE_KPSW_OFFSET
	ld_32		VOL_TEMP2, SAFE_TEMP1, $MACH_REG_STATE_UPSW_OFFSET
	ld_32		VOL_TEMP3, SAFE_TEMP1, $MACH_REG_STATE_INSERT_OFFSET
	ld_32		CUR_PC_REG, SAFE_TEMP1, $MACH_REG_STATE_CUR_PC_OFFSET
	ld_32		NEXT_PC_REG, SAFE_TEMP1, $MACH_REG_STATE_NEXT_PC_OFFSET
	wr_kpsw		VOL_TEMP1
	wr_special	upsw, VOL_TEMP2, $0
	wr_insert	VOL_TEMP3
d1497 1
d1501 22
a1522 22
	ld_40		r10, SAFE_TEMP1, $80
	ld_40		r11, SAFE_TEMP1, $88
        ld_40		r12, SAFE_TEMP1, $96
        ld_40		r13, SAFE_TEMP1, $104
        ld_40		r14, SAFE_TEMP1, $112
        ld_40		r15, SAFE_TEMP1, $120
        ld_40		r16, SAFE_TEMP1, $128
        ld_40		r17, SAFE_TEMP1, $136
        ld_40		r18, SAFE_TEMP1, $144
        ld_40		r19, SAFE_TEMP1, $152
        ld_40		r20, SAFE_TEMP1, $160
        ld_40		r21, SAFE_TEMP1, $168
        ld_40		r22, SAFE_TEMP1, $176
        ld_40		r23, SAFE_TEMP1, $184
        ld_40		r24, SAFE_TEMP1, $192
        ld_40		r25, SAFE_TEMP1, $200
        ld_40		r26, SAFE_TEMP1, $208
        ld_40		r27, SAFE_TEMP1, $216
        ld_40		r28, SAFE_TEMP1, $224
        ld_40		r29, SAFE_TEMP1, $232
        ld_40		r30, SAFE_TEMP1, $240
        ld_40		r31, SAFE_TEMP1, $248
d1531 9
a1539 9
	ld_40		r1, SAFE_TEMP1, $8
	ld_40		r2, SAFE_TEMP1, $16
	ld_40		r3, SAFE_TEMP1, $24
	ld_40		r4, SAFE_TEMP1, $32
	ld_40		r5, SAFE_TEMP1, $40
	ld_40		r6, SAFE_TEMP1, $48
	ld_40		r7, SAFE_TEMP1, $56
	ld_40		r8, SAFE_TEMP1, $64
	ld_40		r9, SAFE_TEMP1, $72
d1543 1
a1543 1
	jump_reg	SAFE_TEMP2, $0
d1551 1
a1551 3
 *	Start the user process executing.  This involves restoring the
 * 	state of the world from regStatePtr and then doing a normal
 *	return from trap.
d1568 1
a1568 1
	ld_32		r2, r1, $MACH_TRAP_CWP_OFFSET
d1576 3
a1578 3
	add_nt		SAFE_TEMP1, r1, $0
	rd_special	SAFE_REG2, pc
	add_nt		SAFE_REG2, SAFE_REG2, $16
d1588 1
a1588 1
	jump		ReturnTrap
d1606 1
a1606 1
	add_nt		OUTPUT_REG1, INPUT_REG1, $0
d1616 2
a1617 2
	add_nt		SAFE_TEMP1, INPUT_REG1, NON_INTR_TEMP1
	ld_32		SAFE_TEMP1, SAFE_TEMP1, $0
d1625 3
a1627 3
	add_nt		SAFE_REG1, SAFE_REG1, $MACH_SWITCH_REG_STATE_OFFSET
	rd_special	SAFE_REG2, pc
	add_nt		SAFE_REG2, SAFE_REG2, $16
d1633 2
a1634 2
	add_nt		SAFE_TEMP1, INPUT_REG2, NON_INTR_TEMP1
	ld_32		SAFE_TEMP1, SAFE_TEMP1, $0
d1639 1
a1639 1
	st_32		SAFE_TEMP1, r0, $_machCurStatePtr
d1644 3
a1646 3
	add_nt		SAFE_REG1, SAFE_REG1, $MACH_SWITCH_REG_STATE_OFFSET
	rd_special	SAFE_REG2, pc
	add_nt		SAFE_REG2, SAFE_REG2, $16
@


1.5
log
@*** empty log message ***
@
text
@d9 1
a9 1
 * rcs = $Header: loMem.s,v 1.4 88/05/25 23:11:07 nelson Exp $ SPRITE (Berkeley)
d29 2
a30 2
 *	    swp - MACH_UNDERFLOW_EXTRA >= min_swp_offset and
 *	    swp + page_size <= max_swp_offset
d32 6
a37 7
 * The MACH_UNDERFLOW_EXTRA bytes of extra space is required on the bottom in 
 * order to handle the case when we are trying to allocate more memory after a
 * window underflow and we need space to save a window in case of a
 * window overflow fault.  The page_size worth of data at the top is
 * there in case we need to save windows when we are executing in the kernel
 * on behalf of a user process.  Having a whole page guarantees us that we
 * can make 32 calls before we run out of saved window space.
d45 10
d155 2
a156 1
 * of what _machCurStatePtr points to we can't do it by the instruction
d161 2
a162 1
 * However we can do
d164 3
a166 1
 *	ld_32	rt1, r0, $_curStatePtr
d169 1
a169 4
 * We could also do this by doing
 *
 *	LD_CONSTANT(rt1,_machCurStatePtr)
 *	ld_32	rt1, rt1, $0
d171 5
a175 4
runningProcesses: 	.long _proc_RunningProcesses
curStatePtr: 		.long _machCurStatePtr
statePtrOffset:		.long _machStatePtrOffset
vmFault_GotDataAddrPtr	.long VMFault_GotDataAddr
d247 3
a249 1
	VERIFY_SWP(0)				# Verify that the SWP is OK.
d254 1
d258 21
a278 19
	rd_special	GLOB_TMP1, swp
	st_40           r10, GLOB_TMP1, $0
	st_40           r11, GLOB_TMP1, $8
        st_40           r12, GLOB_TMP1, $16
        st_40           r13, GLOB_TMP1, $24
        st_40           r14, GLOB_TMP1, $32
        st_40           r15, GLOB_TMP1, $40
        st_40           r16, GLOB_TMP1, $48
        st_40           r17, GLOB_TMP1, $56
        st_40           r18, GLOB_TMP1, $64
        st_40           r19, GLOB_TMP1, $72
        st_40           r20, GLOB_TMP1, $80
        st_40           r21, GLOB_TMP1, $88
        st_40           r22, GLOB_TMP1, $96
        st_40           r23, GLOB_TMP1, $104
        st_40           r24, GLOB_TMP1, $112
        st_40           r25, GLOB_TMP1, $120
	rd_special	GLOB_TMP1, cwp
	wr_special	cwp, GLOB_TMP1, $-4		# Move back one window.
a279 2
	rd_special	GLOB_TMP1, swp
	wr_special	swp, GLOB_TMP1, $128		# swp = swp + 128
d281 8
a288 7
    /*
     * SAFE_TEMP1 == MACH_KPSW_CUR_MODE if we are in user mode and 0 otherwise.
     * If we are in kernel mode then we can just return.  However, if we are in
     * user mode then we have to make sure that we have at least one page
     * of overflow stack available.
     */
	cmp_br_delayed	eq, SAFE_TEMP1, $0, winOvFlow_Return
a289 4
	ld_32		VOL_TEMP1, r0, $curStatePtr
	Nop
	ld_32		VOL_TEMP1, VOL_TEMP1, $0
	Nop
d292 2
a293 2
	add_nt		VOL_TEMP2, VOL_TEMP2, $MACH_PAGE_SIZE
	cmp_br_delayed	le, VOL_TEMP1, VOL_TEMP2, winOvFlow_Return
d296 1
a296 1
	 * Need to allocate more memory.
d300 3
a302 3
	rd_special	VOL_TEMP1, pc	# Return from traps and then
	return_trap	VOL_TEMP1, $12	#   take the compare trap to
	Nop				#   get into kernel mode.
d329 3
a331 2
	VERIFY_SWP(128)				# Make sure at least one 
						#   windows worth on stack.
d333 4
a336 3
        rd_special	GLOB_TMP1, swp
        rd_special      VOL_TEMP1, cwp
	wr_special      cwp, VOL_TEMP1,  $-8	# move back two windows
d338 19
a356 27
        wr_special      swp, GLOB_TMP1, $-128
        ld_40           r10, GLOB_TMP1,   $0
        ld_40           r11, GLOB_TMP1,   $8
        ld_40           r12, GLOB_TMP1,  $16
        ld_40           r13, GLOB_TMP1,  $24
        ld_40           r14, GLOB_TMP1,  $32
        ld_40           r15, GLOB_TMP1,  $40
        ld_40           r16, GLOB_TMP1,  $48
        ld_40           r17, GLOB_TMP1,  $56
        ld_40           r18, GLOB_TMP1,  $64
        ld_40           r19, GLOB_TMP1,  $72
        ld_40           r20, GLOB_TMP1,  $80
        ld_40           r21, GLOB_TMP1,  $88
        ld_40           r22, GLOB_TMP1,  $96
        ld_40           r23, GLOB_TMP1, $104
        ld_40           r24, GLOB_TMP1, $112
        ld_40           r25, GLOB_TMP1, $120
        rd_special      GLOB_TMP1, cwp
        wr_special      cwp,  GLOB_TMP1, $8	# move back ahead two windows
        Nop

    /*
     * SAFE_TEMP1 == MACH_KPSW_CUR_MODE if we are in user mode and 0 otherwise.
     * If we are in kernel mode then we can just return.  However, if we are in
     * user mode then we have to see if we need more wired down.
     */
	cmp_br_delayed	eq, SAFE_TEMP1, $0, winUnFlow_Return
d358 8
a365 3
	ld_32		VOL_TEMP1, r0, $curStatePtr
	Nop
	ld_32		VOL_TEMP1, VOL_TEMP1, $0
d369 1
a369 2
	add_nt		VOL_TEMP1, VOL_TEMP1, $MACH_UNDERFLOW_EXTRA
	cmp_br_delayed	gt, VOL_TEMP2, VOL_TEMP1, winUnFlow_Return
d399 1
a399 1
	and		VOL_TEMP1, VOL_TEMP1, $MACH_KPSW_CUR_MODE
d403 1
d419 1
a419 1
	and		VOL_TEMP1, VOL_TEMP1, $MACH_KPSW_CUR_MODE
d423 1
d439 1
a439 1
	and		VOL_TEMP1, VOL_TEMP1, $MACH_KPSW_CUR_MODE
d443 1
d459 1
a459 1
	and		VOL_TEMP1, VOL_TEMP1, $MACH_KPSW_CUR_MODE
d463 1
d489 2
a490 1
	CallDebugger(MACH_ERROR)
d502 1
d506 1
a506 10
	ld_external	VOL_TEMP1, r0, $MACH_FE_STATUS_0|MACH_RD_REG
	ld_external	VOL_TEMP2, r0, $MACH_FE_STATUS_1|MACH_RD_REG
	wr_insert	$1
	insert		VOL_TEMP1, VOL_TEMP1, VOL_TEMP2
	ld_external	VOL_TEMP2, r0, $MACH_FE_STATUS_2|MACH_RD_REG
	wr_insert	$2
	insert		VOL_TEMP1, VOL_TEMP1, VOL_TEMP2
	ld_external	VOL_TEMP2, r0, $MACH_FE_STATUS_3|MACH_RD_REG
	wr_insert	$3
	insert		VOL_TEMP1, VOL_TEMP1, VOL_TEMP2
d523 1
a523 1
	 * We can't handle any of the rest of the faults.
a524 6
	rd_kpsw		VOL_TEMP1
	and		VOL_TEMP1, VOL_TEMP1, $MACH_KPSW_PREV_MODE
	cmp_br_delayed	eq, VOL_TEMP1, $0, faultIntr_KernError
	Nop
	USER_ERROR(MACH_BAD_FAULT)
faultIntr_KernError:
d538 5
a545 14
	/*
	 * Get the interrupt status register as the first parameter to
	 * the interrupt handling routine.
	 */
	ld_external	OUTPUT_REG1, r0, $MACH_INTR_STATUS_0|MACH_RD_REG
	ld_external	VOL_TEMP1, r0, $MACH_INTR_STATUS_1|MACH_RD_REG
	wr_insert	$1
	insert		OUTPUT_REG1, OUTPUT_REG1, VOL_TEMP1
	ld_external	VOL_TEMP1, r0, $MACH_INTR_STATUS_2|MACH_RD_REG
	wr_insert	$2
	insert		OUTPUT_REG1, OUTPUT_REG1, VOL_TEMP1
	ld_external	VOL_TEMP1, r0, $MACH_INTR_STATUS_3|MACH_RD_REG
	wr_insert	$3
	insert		OUTPUT_REG1, OUTPUT_REG1, VOL_TEMP1
d552 2
a553 2
	and		VOL_TEMP2, SAFE_TEMP2, $((~MACH_INTR_TRAP_ENA)&0x3fff)
	or		VOL_TEMP2, VOL_TEMP2, $MACH_ALL_TRAPS_ENA
d555 3
d561 1
d563 1
a563 10
	 * We took the interrupt from user mode.  Verify that the swp
	 * is OK which means:
	 *
	 *	swp >= min_swp_offset and
	 *	swp + page_size - MACH_UNDERFLOW_EXTRA <= max_swp_offset
	 *
	 * This is MACH_UNDERFLOW_EXTRA bytes different then the standard 
	 * check (VERIFY_SWP) because we may interrupt a process after it 
	 * has taken a window overflow or underflow fault but before it has
	 * had a chance to allocate more memory for the window stack.
d565 2
a566 11
	ld_32		VOL_TEMP1, r0, $curStatePtr
	rd_special	VOL_TEMP2, swp
	ld_32		VOL_TEMP3, VOL_TEMP1, $MACH_MIN_SWP_OFFSET
	Nop
	cmp_br_delayed	gt, VOL_TEMP3, VOL_TEMP2, interrupt_BadSWP
	Nop
	ld_32		VOL_TEMP3, VOL_TEMP1, $MACH_MAX_SWP_OFFSET
	add_nt		VOL_TEMP2, VOL_TEMP2, $(MACH_PAGE_SIZE - MACH_UNDERFLOW_EXTRA)
	cmp_br_delayed	ge, VOL_TEMP3, VOL_TEMP2, interrupt_GoodSWP
	Nop
interrupt_BadSWP:
d569 2
a570 2
	 * window and spill stacks and take the interrupt.  After taking
	 * the interrupt kill the user process.
d572 6
a577 1
	SWITCH_TO_KERNEL_STACKS()
d583 1
a583 1
	add_nt		r11, r0, $MACH_USER_BAD_SWP
d586 1
a588 11
	/*
	 * We have a good user swp.  Switch to the kernel's spill stack, call
	 * the interrupt handler and then go back to the user's stack.
	 */
	add_nt		VOL_TEMP2, SPILL_SP, $0
	ld_32		SPILL_SP, VOL_TEMP1, $MACH_KERN_STACK_END
	call		_MachInterrupt
	Nop
	add_nt		SPILL_SP, VOL_TEMP2, $0
	cmp_br_delayed	always, interrupt_Return
	Nop
a589 4
	/*
	 * We took the interrupt in kernel mode so all that we have to
	 * do is call the interrupt handler.
	 */
a591 1
interrupt_Return:
d593 1
a593 1
	 * Restore saved KPSW and insert register and return from trap.
d595 6
d618 1
a618 5
	/*
	 * Enable all traps.  Save the kpsw in a safe temporary before 
	 * modifying it so that we can restore it later.
	 */
	read_kpsw	SAFE_TEMP2
d622 4
a625 1
	or		VOL_TEMP2, VOL_TEMP2, $MACH_ALL_TRAPS_ENA
d627 3
d633 6
a638 1
	VERIFY_SWP(0)
d649 1
a649 1
	 * 
d657 2
a658 2
	ld_32		VOL_TEMP1, r0, $vmFault_GotDataAddrPtr
	Nop
a660 1
vmFault_GotDataAddr:
d662 1
a662 1
	 * We now have the data address in VOL_TEMP1
d666 1
a666 1
	add_nt		OUTPUT_REG4, VOL_TEMP1, $0	# 4th arg is the data
d677 1
a677 5
	and		VOL_TEMP2, SAFE_TEMP1, $MACH_KPSW_PREV_MODE
	cmp_br_delayed	eq, VOL_TEMP2, $0, vmFault_KernMode
	Nop
	add_nt		SAFE_TEMP3, SPILL_SP, $0
	SWITCH_TO_KERNEL_SPILL_STACK()
d680 1
a680 9
	add_nt		SPILL_SP, SAFE_TEMP3, $0
	jump		vmFault_ReturnFromTrap
	Nop
vmFault_KernMode:
	/*
	 * Kernel process so just call the routine.
	 */
	call		_MachVMFault
	Nop
d701 5
d707 15
a721 1
        and             VOL_TEMP1, r17, $0x1ff        # Get trap number
d724 1
d732 1
a732 1
        Nop
d737 7
d754 9
a762 1
	USER_ERROR(MACH_BAD_TRAP_TYPE)
a789 6
	rd_kpsw		SAFE_TEMP1
	or		VOL_TEMP1, SAFE_TEMP1, $MACH_KPSW_ALL_TRAPS_ENA
	wr_kpsw		VOL_TEMP1
	VERIFY_SWP(0)
	add_nt		SAFE_TEMP2, SPILL_SP, $0
	SWITCH_TO_KERNEL_SPILL_STACK()
d793 1
a793 1
	jump		_MachUserError
d795 2
d798 2
a799 1
	 * Restore kpsw and the user stack pointer.
d801 18
a818 2
	wr_kpsw		SAFE_TEMP1
	add_nt		SPILL_SP, SAFE_TEMP2, $0
a832 1
	VERIFY_SWP(0)
d847 4
a850 5
	 * in rt1 and the old hold mask in rt2.  Also the first and second
	 * PCs were saved in CUR_PC_REG and NEXT_PC_REG.  Restore the 
	 * stack pointer and then call the signal return handler with the old
	 * hold mask as an argument.  The signal return handler will check for
	 * other signals pending and return one of the normal ReturnTrap codes.
d852 3
a854 5
	add_nt		SPILL_SP, rt1, $0
	add_nt		OUTPUT_REG1, rt2, $0
	add_nt		SAFE_TEMP1, SPILL_SP, $0
	SWITCH_TO_KERNEL_SPILL_STACK()
	jump		_MachSigReturn()
d856 1
d858 1
a858 1
	 * Restore the spill stack and kpsw.
d860 6
a865 1
	add_nt		SPILL_SP, SAFE_TEMP1, $0
d867 1
a867 1
	and		VOL_TEMP1, VOL_TEMP1, $(~MACH_KPSW_ALL_TRAPS_ENA)
d872 1
d876 40
d918 5
a922 4
 *	Return from a trap handler.  We are called with all traps disabled.
 *	Assume that the type of return to do has been stored in RETURN_VAL_REG.
 *	If it is not one of MACH_NORM_RETURN, MACH_FAILED_COPY or
 *	MACH_CALL_SIG_HANDLER then it is a kernel error value.
d934 9
a942 1
	cmp_br_delayed	eq, RETURN_VAL_REG, $MACH_CALL_SIG_HANDLER, returnTrap_CallSigHandler
d944 6
a949 1
	cmp_br_delayed	eq, RETURN_VAL_REG, $MACH_SIG_PENDING, returnTrap_SigPending
d951 35
a985 1
	CALL_DEBUGGER(RETURN_VAL_REG, 0)
d988 2
a989 2
	 * A copy to/from user space failed.  Enable all traps and then g
	 * go back to the previous window and return an error to the caller.
d992 1
a992 1
	or		VOL_TEMP1, VOL_TEMP1, MACH_ALL_TRAPS_ENA
d1001 2
a1002 1
	add_nt		RETURN_VAL_REG, r0, $0
d1004 2
a1005 1
	insert		RETURN_VAL_REG, r0, $2
d1008 8
a1015 1
returnTrap_CallSigHandler:
d1017 2
a1018 2
	 * Need to call a users signal handler.  First turn on all
	 * traps.
d1020 2
a1021 2
	rd_kpsw		VOL_TEMP1
	or		VOL_TEMP1, VOL_TEMP1, MACH_ALL_TRAPS_ENA
d1023 12
a1034 3
	/* 
	 * Next save the current stack pointer in the current window.  The PCs
	 * are already saved in CUR_PC_REG and NEXT_PC_REG.
d1036 1
a1036 1
	ld_32		r31, r0, $curStatePtr
d1038 1
a1038 1
	ld_32		r31, r31, $0
d1040 15
a1054 5
	ld_32		rt2, r31, $MACH_OLD_HOLD_MASK_OFFSET
	add_nt		rt1, SPILL_SP, $0
	/*
	 * Go to the next window which is where the signal handler will
	 * execute in.
d1056 1
a1056 1
	call		1f
d1058 3
a1060 1
1f:
d1065 4
a1068 6
	ld_32		VOL_TEMP1, r15, $MACH_NEW_CUR_PC_OFFSET
	ld_32		SPILL_SP, r15, $MACH_NEW_USER_SP_OFFSET
	add_nt		RETURN_ADDR_REG, r0, $SigReturnAddr
	ld_32		INPUT_REG1, r15, $MACH_SIG_NUM_OFFSET
	ld_32		INPUT_REG2, r15, $MACH_SIG_CODE_OFFSET
	ld_32		INPUT_REG3, r15, $MACH_OLD_HOLD_MASK_OFFSET
d1070 1
a1070 1
	 * Call the signal handler and switch to user mode.
d1072 3
a1074 6
	rd_kpsw		GLOB_TMP1
	or		GLOB_TMP1, GLOB_TMP1, $MACH_ALL_TRAPS_ENA|MACH_KPSW_CUR_MODE
	jump_reg	VOL_TEMP1, $0
	wr_kpsw		GLOB_TMP1

returnTrap_NormReturn:
d1076 1
a1076 2
	 * Do a return from trap.  If the 2nd PC in NEXT_PC_REG is zero then 
	 * we don't do the jump to the 2nd PC because there is none.
d1078 1
a1078 1
	cmp_br_delayed	eq, NEXT_PC_REG, $0, returnTrap_No2ndPC
d1080 6
a1085 4
	jump_reg	CUR_PC_REG, $0
	return_trap	NEXT_PC_REG, $0
returnTrap_No2ndPC:
	return_trap	CUR_PC_REG, $0
d1087 5
d1093 5
d1100 5
a1104 9
	 * We need to process a user signal.  Before we call the user error
	 * handler save enough state so that the user can debug his process.
	 * This can make calling signal handlers expensive but we take
	 * the simple approach for now.
	 *
	 * Call the routine to save state.  Note that we don't want to
	 * shift the window so we simulate a call by passing the return address
	 * in SAFE_REG2, where to save things in SAFE_REG1 and then doing a
	 * jump.
d1106 1
a1106 1
	ld_32		SAFE_REG1, r0, $curStatePtr
a1107 2
	ld_32		SAFE_REG1, SAFE_REG1, $0
	Nop
d1114 8
a1121 2
	ld_32		SPILL_SP, SAFE_REG1, $MACH_KERN_STACK_END
	Nop
d1124 1
d1127 5
a1133 2
	 * The act or restoring the state will restoring the SPILL_SP
	 * register.
d1135 1
a1135 1
	ld_32		SAFE_REG1, r0, $curStatePtr
a1136 2
	ld_32		SAFE_REG1, SAFE_REG1, $0
	Nop
d1158 1
a1158 1
 *	SAFE_TEMP2 contains the return address.
d1160 5
d1169 2
a1170 1
	 * Save kpsw, upsw and the current and next PCs of the fault.
d1178 2
d1193 2
a1194 1
	 * Now save the previous window in the state struct.
d1196 9
d1206 9
a1214 2
	rd_special	GLOB_TMP1, cwp
	wr_special	cwp, GLOB_TMP1 $-4	# Go back one window.
d1216 1
a1216 22
	st_40           r10, r1, $80
	st_40           r11, r1, $88
        st_40           r12, r1, $96
        st_40           r13, r1, $104
        st_40           r14, r1, $112
        st_40           r15, r1, $120
        st_40           r16, r1, $128
        st_40           r17, r1, $136
        st_40           r18, r1, $144
        st_40           r19, r1, $152
        st_40           r20, r1, $160
        st_40           r21, r1, $168
        st_40           r22, r1, $176
        st_40           r23, r1, $184
        st_40           r24, r1, $192
        st_40           r25, r1, $200
        st_40           r26, r1, $208
        st_40           r27, r1, $216
        st_40           r28, r1, $224
        st_40           r29, r1, $232
        st_40           r30, r1, $240
        st_40           r31, r1, $248
d1218 60
d1279 4
a1282 1
	 * onto the saved window stack.
d1284 5
a1288 9
	rd_special	r1, cwp
	rd_special	r2, swp		# Read the swp and then shift it so
	srl		r3, r2, $1	#    it aligns with the cwp.  That is
	srl		r3, r3, $1	#    swp<9:7> -> swp<4:2>
	srl		r3, r3, $1
	srl 		r3, r3, $1
	srl		r3, r3, $1
	wr_special	cwp, r3, $0	# Set the cwp to the first window to
					#    save.
d1290 1
a1290 2
SaveState_SaveRegs:
	cmp_br_delayed	eq, r3, r1, SaveState_Done
d1292 19
a1310 21
	st_40           r10, r2, $0
	st_40           r11, r2, $8
        st_40           r12, r2, $16
        st_40           r13, r2, $24
        st_40           r14, r2, $32
        st_40           r15, r2, $40
        st_40           r16, r2, $48
        st_40           r17, r2, $56
        st_40           r18, r2, $64
        st_40           r19, r2, $72
        st_40           r20, r2, $80
        st_40           r21, r2, $88
        st_40           r22, r2, $96
        st_40           r23, r2, $104
        st_40           r24, r2, $112
        st_40           r25, r2, $120
	add_nt		r2, r2, $128	# Increment the swp by one window.
	add_nt		r3, r3, $0x4	# Increment the cwp by one window
	and		r3, r3, $0x1c0	#    and mask out good bits in case 
					#    it wrapped.
	wr_special	cwp, r3, $0
a1311 1
	jump		SaveState_SaveRegs
d1313 3
a1315 3
SaveState_Done:
	wr_special	cwp, r1, $0x4	# Move back to the current window.
	Nop
d1343 1
a1343 1
	 * Restore the current PC, next PC and the upsw.
d1345 5
a1349 4
	ld_32		VOL_TEMP1, SAFE_TEMP1, $MACH_TRAP_KPSW_OFFSET
	ld_32		VOL_TEMP2, SAFE_TEMP1, $MACH_TRAP_UPSW_OFFSET
	ld_32		CUR_PC_REG, SAFE_TEMP1, $MACH_TRAP_CUR_PC_OFFSET
	ld_32		NEXT_PC_REG, SAFE_TEMP1, $MACH_TRAP_NEXT_PC_OFFSET
d1351 2
a1352 1
	wr_special	upsw, VOL_TEMP2
d1356 2
a1357 2
	rd_special	GLOB_TMP1, cwp
	wr_special	cwp, GLOB_TMP1, $-4	# Go back one window.
d1359 22
a1380 22
	ld_40           r10, r1, $80
	ld_40           r11, r1, $88
        ld_40           r12, r1, $96
        ld_40           r13, r1, $104
        ld_40           r14, r1, $112
        ld_40           r15, r1, $120
        ld_40           r16, r1, $128
        ld_40           r17, r1, $136
        ld_40           r18, r1, $144
        ld_40           r19, r1, $152
        ld_40           r20, r1, $160
        ld_40           r21, r1, $168
        ld_40           r22, r1, $176
        ld_40           r23, r1, $184
        ld_40           r24, r1, $192
        ld_40           r25, r1, $200
        ld_40           r26, r1, $208
        ld_40           r27, r1, $216
        ld_40           r28, r1, $224
        ld_40           r29, r1, $232
        ld_40           r30, r1, $240
        ld_40           r31, r1, $248
d1384 1
a1384 1
	wr_special	cwp, GLOB_TMP1, $0
d1405 111
d1521 1
a1521 1
 *	jump to when done is passed in rt1.  Note that since the act of
d1524 1
d1533 1
d1730 3
a1732 3
	add_nt		PARSE_TEMP1, PARSE_TEMP1, $0x3ff8 # Gen up mask to make
	and		SRC1_VAL, SRC1_VAL, PARSE_TEMP1   #   to make 8-bit
							  #   aligned if 40-bit
@


1.4
log
@*** empty log message ***
@
text
@d9 1
a9 1
 * rcs = $Header: loMem.s,v 1.3 88/05/25 23:02:41 nelson Exp $ SPRITE (Berkeley)
d64 2
a65 2
 * FIRST_PC_REG and SECOND_PC_REG which tell us where to continue when we
 * truly return to the user process.  Thus FIRST_PC_REG and SECOND_PC_REG 
d68 1
a68 1
 * Therefore I need to save FIRST_PC_REG and SECOND_PC_REG in a place where 
d92 1
a92 1
	jump PowerUp$w		# Reset - Jump to powerup sequencer.
d96 1
a96 1
	jump Error$w		# Error
d100 1
a100 1
	jump WinOvFlow$w	# Window overflow
d104 1
a104 1
	jump WinUnFlow$w	# Window underflow
d108 1
a108 1
	jump FaultIntr$w	# Fault or interrupt
d112 1
a112 1
	jump FPUExcept$w	# FPU Exception
d116 1
a116 1
	jump Illegal$w		# Illegal op, kernel mode access violation
d120 1
a120 1
	jump Fixnum$w		# Fixnum, fixnum_or_char, generation
d124 1
a124 1
	jump Overflow$w		# Integer overflow
d128 1
a128 1
	jump CmpTrap$w		# Compare trap instruction
d243 1
d245 1
a245 1
	st_40           r26, GLOB_TMP1, $0
d263 1
d287 2
a288 2
	add_nt		NON_INTR_TEMP1, FIRST_PC_REG, $0
	add_nt		NON_INTR_TEMP2, SECOND_PC_REG, $0
d296 3
a298 3
	add_nt		GLOB_TMP1, SECOND_PC_REG, r0
	return_trap	FIRST_PC_REG, $0
	jump_reg	GLOB_TMP1, $0
d324 1
d365 2
a366 2
	add_nt		NON_INTR_TEMP1, FIRST_PC_REG, $0
	add_nt		NON_INTR_TEMP2, SECOND_PC_REG, $0
d374 3
a376 3
	add_nt		GLOB_TMP1, SECOND_PC_REG, r0
	return_trap	FIRST_PC_REG, $0
	jump_reg	GLOB_TMP1, $0
d395 1
a395 1
	CALL_DEBUGGER(MACH_KERN_FPU_EXCEPT)
d414 1
a414 1
	CALL_DEBUGGER(MACH_KERN_ILLEGAL)
d433 1
a433 1
	CALL_DEBUGGER(MACH_KERN_FIXNUM)
d452 1
a452 1
	CALL_DEBUGGER(MACH_KERN_OVERFLOW)
d525 1
a525 1
	CALL_DEBUGGER(MACH_BAD_FAULT)
d596 1
a596 1
	call		_MachInterrupt$w
d602 1
a602 1
	call		_MachUserError$w
d610 1
d612 1
a612 2
	add_nt		VOL_TEMP1, SPILL_SP, $0
	call		_MachInterrupt$w
d614 1
d616 1
a616 1
	add_nt		SPILL_SP, VOL_TEMP1, $0
d622 1
a622 1
	call 		_MachInterrupt$w
d630 3
a632 3
	add_nt		GLOB_TMP1, SECOND_PC_REG, $0
	return_trap	FIRST_PC_REG, $0
	jump_reg	GLOB_TMP1, $0
a633 1

d675 1
a675 1
	 * instruction is already in FIRST_PC_REG.
d679 1
a679 1
	jump		ParseInstruction$w
d696 1
a696 1
	add_nt		OUTPUT_REG2, FIRST_PC_REG, $0	# 2nd arg is the 
d701 3
a703 2
	SAVE_STATE_AND_SWITCH_STACK()
	call		_MachVMFault$w
d705 2
a706 2
	RESTORE_USER_STATE()
	jump		vmFault_ReturnFromTrap$w
d712 1
a712 1
	call		_MachVMFault$w
d720 1
a720 1
	jump		ReturnTrap$w
d744 1
a744 1
	jump		SysCallTrap$w	
d746 1
a746 1
	jump		UserErrorTrap$w
d748 1
a748 1
	jump		SigReturnTrapa$w
d763 1
a763 1
	CALL_DEBUGGER(MACH_BAD_TRAP_TYPE)
d781 2
a782 2
 *	Handle a user error trap.  Before we were called the old FIRST_PC_REG 
 *	and SECOND_PC_REG were saved in NON_INTR_TEMP2 and NON_INTR_TEMP3 
d788 3
d792 2
a793 1
	SAVE_STATE_AND_SWITCH_STACK()
d795 3
a797 3
	add_nt		FIRST_PC_REG, NON_INTR_TEMP2, $0
	add_nt		SECOND_PC_REG, NON_INTR_TEMP3, $0
	jump		_MachUserError$w
d799 6
a804 2
	RESTORE_STATE()
	jump		ReturnTrap$w
d834 1
a834 1
	 * PCs were saved in FIRST_PC_REG and SECOND_PC_REG.  Restore the 
d841 2
a842 1
	SAVE_STATE_AND_SWITCH_STACK()
d845 8
a852 2
	RESTORE_STATE()
	jump		ReturnTrap$w
d860 4
a863 4
 *	Return from a trap handler.  Assume that the type of return to
 *	do has been stored in RETURN_VAL_REG.  If it is not one of
 *	MACH_NORM_RETURN, MACH_FAILED_COPY or MACH_CALL_SIG_HANDLER
 *	then it is a kernel error value.
d877 3
a879 1
	CALL_DEBUGGER_REG(RETURN_VAL_REG)
d882 2
a883 2
	 * A copy to/from user space failed.  Go back to the previous window
	 * and then return an error to the caller.
d885 3
d902 2
a903 3
	 * Need to call a users signal handler.  First save the current
	 * stack pointer in the current window.  The PCs are already saved
	 * in FIRST_PC_REG and SECOND_PC_REG.
d905 7
d929 1
a929 1
	ld_32		VOL_TEMP1, r15, $MACH_NEW_FIRST_PC_OFFSET
d945 1
a945 1
	 * Do a return from trap.  If the 2nd PC in SECOND_PC_REG is zero then 
d948 4
a951 4
	cmp_br_delayed	eq, SECOND_PC_REG, $0, returnTrap_No2ndPC
	add_nt		GLOB_TMP1, SECOND_PC_REG, $0
	return_trap	FIRST_PC_REG, $0
	jump_reg	GLOB_TMP1, $0
d953 1
a953 1
	return_trap	FIRST_PC_REG, $0
d956 50
d1007 193
d1273 1
a1273 1
	call		parse1up$w		# Back to trap handler window.
d1294 1
a1294 1
	jump	        parse41$w		 # Value is returned in r31
d1298 1
a1298 1
	call 	       	parse5$w		# Get back to trap window. 
d1353 1
a1353 1
	call		pars2up$w
d1377 1
a1377 1
	jump 		parse7$w		 #   and put value in r31
d1379 1
a1379 1
	call		parse_end$w
@


1.3
log
@*** empty log message ***
@
text
@d9 1
a9 1
 * rcs = $Header: loMem.s,v 1.2 88/05/24 22:54:41 nelson Exp $ SPRITE (Berkeley)
a16 22
 * REGISTER CONVENTIONS
 *
 * The routines in this file use the following conventions for using
 * registers (see reg.h for symbolic names):
 *
 *	1) r1-r8:	Globals used by the Lisp system and are left untouched.
 *	2) r9:		Global that we can use as a temporary.
 *	3) r10:		Where the PC to return to when a trap occurs is stored
 *	4) r11-r15:	Off limits because these are the previous windows
 *			output registers and it might be in the middle
 *			of using them.  If one of these registers is used
 *			then it must be saved and restored.
 *	5) r16:		Where the 2nd PC is stored when a trap occurs.
 *	6) r17-r25:	Temporaries.  r17-r19 can be changed by the macros
 *			in machAsmDefs.h and r23-r25 are off limits to the
 *			interrupt handler for reasons described under
 *			"SWITCHING TO KERNEL MODE" below.
 *	7) r26:		Callers return PC.
 *	8) r27-r31:	Output registers.  Generally unused in here except
 *			by the instruction parsing routines and to pass args
 *			to C routines.
 *
a87 7
 * Temporary global registers.  Note that the only one that we can use is r9
 * because r1 through r8 are redquired by the Lisp system.  If these need to
 * be used then they have to be saved first.
 */
#define	GLOB_TMP1	r9

/*
a270 1

@


1.2
log
@*** empty log message ***
@
text
@d1 10
a10 10
|* loMem.s --
|*
|*	The first thing that is loaded into the kernel.  Handles traps,
|*	faults, errors and interrupts.
|*
|* Copyright (C) 1985 Regents of the University of California
|* All rights reserved.
|*
|* rcs = $Header: loMem.s,v 1.1 88/05/23 22:48:42 nelson Exp $ SPRITE (Berkeley)
|*
d12 1
d20 1
a20 1
 * registers:
d25 4
a28 6
 *	4) r11-r15:	Used as special temporaries to save things when
 *			taking traps to switch to kernel mode for user
 *			errors and for allocating pages for window overflow
 *			and underflow.  These cannot be touched by the 
 *			interrupt routines.  See the window overflow handler
 *			for details.
d30 6
a35 3
 *	6) r17-r25:	Temporaries.  r22-r25 can be changed by the macros
 *			in machAsmDefs.h.
 *	7) r26-r31:	Output registers.  Generally unused in here except
d51 1
a51 1
 *	    swp - 128 >= min_swp_offset and
d54 2
a55 2
 * The 128 bytes of extra space is required on the bottom in order
 * to handle the case when we are trying to allocate more memory after a
d60 1
a60 1
 * can make 32 calls before we run out saved window space.
d82 12
a93 19
 * are user mode.  The only way to get to kernel mode is to do a return from
 * trap and then immediately do a compare trap to get back in.  Unfortunately
 * the cmp-tra
	 * Need to allocate more memory.  This has to be done in a really
	 * gross way.  I want to switch to kernel mode in order to allocate
	 * memory but I can't switch to kernel mode because I am in user
	 * mode.  Thus the only way to get to kernel mode is to do a return
	 * from trap and then make the instruction that I return to do a
	 * cmp_trap to get back into the kernel.   Of course the cmp_trap
	 * will trash r10 and r16 in the current window so I need to save
	 * these registers at other locations in the current window so they
	 * don't get trashed.   Now the act of returning from the trap 
	 * means that interrupts are enabled which means that an interrupt
	 * can come in.  Therefore I need to save r10 and r16 in a place
	 * where they won't get trashed if an interrupt comes in.  The
	 * place to put them is in r14 and r15 which are registers that
	 * aren't used for anything in here except for parsing 
	 * instructions which won't happen.
	 */
d97 1
a97 2
 * Temporary local registers.  Note that the macros in machAsmDefs.h are allowed
 * to use registers rt6 through rt9.
d111 1
a111 1
 * because r1 through r8 are required by the Lisp system.  If these need to
a204 6
 * Address of a Nop to execute.  Here for same reason as SigReturnAddr.
 */
ExecNop:
	Nop

/*
d251 2
d256 3
a258 4
 *	validated
 * first.  If it is invalid then the trapping process is killed.  Also if
 * in user mode more memory is wired down if the trapping process doesn't
 * have at least one page worth of window overflow stack wired down.
d261 3
a263 3
	rd_kpsw		rt1
	and		rt1, rt1, $MACH_KPSW_CUR_MODE
	cmp_br_delayed	eq, rt1, r0, winOvFlow_SaveWindow
d265 1
a265 1
	VERIFY_SWP(0)
d267 5
a271 2
	rd_special	rt2, cwp
	wr_special	cwp, rt2, $4		# Move forward one window.
d294 6
a299 6
/*
 * rt1 == MACH_KPSW_CUR_MODE if we are in user mode and 0 otherwise.  If
 * we are in kernel mode then we can just return.  However, if we are in
 * user mode then we have to make sure that we have at least one page
 * of overflow stack available.
 */
d301 1
a301 1
	cmp_br_delayed	eq, rt1, $0, winOvFlow_Return
d303 1
a303 1
	ld_32		rt1, r0, $curStatePtr
d305 1
a305 1
	ld_32		rt1, rt1, $0
d307 4
a310 3
	ld_32		rt2, rt1, $MACH_MAX_SWP_OFFSET
	add_nt		rt3, GLOB_TMP1, $MACH_PAGE_SIZE
	cmp_br_delayed	le, rt2, rt3, winOvFlow_Return
d313 1
a313 15
	 * Need to allocate more memory.  This has to be done in a really
	 * gross way.  I want to switch to kernel mode in order to allocate
	 * memory but I can't switch to kernel mode because I am in user
	 * mode.  Thus the only way to get to kernel mode is to do a return
	 * from trap and then make the instruction that I return to do a
	 * cmp_trap to get back into the kernel.   Of course the cmp_trap
	 * will trash r10 and r16 in the current window so I need to save
	 * these registers at other locations in the current window so they
	 * don't get trashed.   Now the act of returning from the trap 
	 * means that interrupts are enabled which means that an interrupt
	 * can come in.  Therefore I need to save r10 and r16 in a place
	 * where they won't get trashed if an interrupt comes in.  The
	 * place to put them is in r14 and r15 which are registers that
	 * aren't used for anything in here except for parsing 
	 * instructions which won't happen.
d315 5
a319 4
	add_nt		r14, r10, $0	# Save the first and 2nd PCs
	add_nt		r15, r16, $0
	add_nt		r10, r0, $ExecNop
	return_trap	r10, $0
d324 2
a325 2
	add_nt		GLOB_TMP1, r16, r0
	return_trap	r10, $0
d329 11
a339 4
 * Window underflow fault handler.  If in user mode then the swp is validated
 * first.  If it is invalid then the trapping process is killed.  Also if
 * in user mode more memory is wired down if the trapping process doesn't
 * have the memory behind the new swp wired down.
d342 3
a344 3
	rd_kpsw		rt1
	and		rt1, rt1, $MACH_KPSW_CUR_MODE
	cmp_br_delayed	eq, rt1, r0, winUnFlow_RestoreWindow
d346 2
a347 1
	VERIFY_SWP(128)
d350 2
a351 2
        rd_special      rt1, cwp
	wr_special      cwp, rt1,  $-8          # move back two windows
d373 6
a378 7
/*
 * rt1 == MACH_KPSW_CUR_MODE if we are in user mode and 0 otherwise.  If
 * we are in kernel mode then we can just return.  However, if we are in
 * user mode then we have to see if we should free up a window overflow
 * stack page.
 */
	cmp_br_delayed	eq, rt1, $0, winUnFlow_Return
d380 1
a380 1
	ld_32		rt1, r0, $curStatePtr
d382 3
a384 4
	ld_32		rt1, rt1, $0
	rd_special	GLOB_TMP1, swp
	ld_32		rt2, rt1, $MACH_MIN_SWP_OFFSET
	cmp_br_delayed	gt, GLOB_TMP1, rt2, winUnFlow_Return
d386 3
d390 1
a390 2
	 * Need to get more memory for the window overflow.  See the
	 * window overflow code for a comment on how this works.
d392 5
a396 4
	add_nt		r14, r10, $0	# Save the first and 2nd PCs
	add_nt		r15, r16, $0
	add_nt		r10, r0, $ExecNop
	return_trap	r10, $0
d398 1
d401 2
a402 2
	add_nt		GLOB_TMP1, r16, r0
	return_trap	r10, $0
d406 8
a413 2
 * FPU Exception handler.  Currently we take either a user or kernel error
 * whichever is appropriate.
d416 3
a418 3
	rd_kpsw		rt1
	and		rt1, rt1, $MACH_KPSW_CUR_MODE
	cmp_br_delayed	eq, rt1, $0, fpuExcept_KernError
d425 8
a432 2
 * Illegal instruction handler.  Currently we take either a user or kernel error
 * whichever is appropriate.
d435 3
a437 3
	rd_kpsw		rt1
	and		rt1, rt1, $MACH_KPSW_CUR_MODE
	cmp_br_delayed	eq, rt1, $0, illegal_KernError
d444 8
a451 2
 * Fixnum Exception handler.  Currently we take either a user or kernel error
 * whichever is appropriate.
d454 3
a456 3
	rd_kpsw		rt1
	and		rt1, rt1, $MACH_KPSW_CUR_MODE
	cmp_br_delayed	eq, rt1, $0, fixnum_KernError
d463 8
a470 2
 * Overflow fault handler.  Currently we take either a user or kernel error
 * whichever is appropriate.
d473 3
a475 3
	rd_kpsw		rt1
	and		rt1, rt1, $MACH_KPSW_CUR_MODE
	cmp_br_delayed	eq, rt1, $0, overflow_KernError
d481 10
d492 10
d505 9
d518 2
a519 2
	ld_external	rt1, r0, $MACH_FE_STATUS_0|MACH_RD_REG
	ld_external	rt2, r0, $MACH_FE_STATUS_1|MACH_RD_REG
d521 2
a522 2
	insert		rt1, rt1, rt2
	ld_external	rt2, r0, $MACH_FE_STATUS_2|MACH_RD_REG
d524 2
a525 2
	insert		rt1, rt1, rt2
	ld_external	rt2, r0, $MACH_FE_STATUS_3|MACH_RD_REG
d527 1
a527 1
	insert		rt1, rt1, rt2
d532 1
a532 1
	cmp_br_delayed	eq, rt1, r0, Interrupt
d536 2
a537 1
	 * four VM faults.
d539 3
a541 3
	extract		rt2, rt1, $2
	and		rt2, rt2, $0xf
	cmp_br_delayed	ne, rt2, 0, VMFault
d546 3
a548 3
	rd_kpsw		rt1
	and		rt1, rt1, $MACH_KPSW_PREV_MODE
	cmp_br_delayed	eq, rt1, $0, faultIntr_KernError
d550 1
a550 2
	VERIFY_SWP(0)
	SWITCH_TO_KERNEL_SPILL_STACK()
d554 9
d565 1
a565 1
	 * Save the insert register in temp reg 4.
d567 1
a567 1
	rd_insert	rt4
d572 2
a573 2
	ld_external	r27, r0, $MACH_INTR_STATUS_0|MACH_RD_REG
	ld_external	rt2, r0, $MACH_INTR_STATUS_1|MACH_RD_REG
d575 2
a576 2
	insert		r27, r27, rt2
	ld_external	rt2, r0, $MACH_INTR_STATUS_2|MACH_RD_REG
d578 2
a579 2
	insert		r27, r27, rt2
	ld_external	rt2, r0, $MACH_INTR_STATUS_3|MACH_RD_REG
d581 1
a581 1
	insert		r27, r27, rt2
d584 2
a585 1
	 * Disable interrupts but enable all other traps.
d587 6
a592 6
	read_kpsw	rt5
	and		rt2, rt5, $((~MACH_INTR_TRAP_ENA)&0x3fff)
	or		rt2, rt2, $MACH_ALL_TRAPS_ENA
	wr_kpsw		rt2
	and		rt2, rt5, $MACH_KPSW_PREV_MODE
	cmp_br_delayed	eq, rt2, $0, interrupt_KernMode
d599 1
a599 1
	 *	swp + page_size - 128 <= max_swp_offset
d601 4
a604 4
	 * This is 128 bytes different then the standard check (VERIFY_SWP)
	 * because we may interrupt a process after it has taken a window
	 * overflow or underflow fault but before it has had a chance to
	 * allocate more memory for the window stack.
d606 3
a608 3
	ld_32		rt1, r0, $curStatePtr
	rd_special	rt2, swp
	ld_32		rt3, rt1, $MACH_MIN_SWP_OFFSET
d610 1
a610 1
	cmp_br_delayed	gt, rt3, rt2, interrupt_BadSWP
d612 3
a614 3
	ld_32		rt3, rt1, $MACH_MAX_SWP_OFFSET
	add_nt		rt2, rt2, $(MACH_PAGE_SIZE - 128)
	cmp_br_delayed	ge, rt3, rt2, interrupt_GoodSWP
d625 3
a627 3
	read_kpsw	rt1
	or		rt1, rt1, $MACH_KPSW_INTR_TRAP_ENA
	write_kpsw	rt1
d637 2
a638 2
	ld_32		r4, rt1, $MACH_KERN_STACK_END
	add_nt		rt1, r4, $0
d642 1
a642 1
	add_nt		r4, rt1, $0
d654 4
a657 4
	wr_insert	rt4
	wr_kpsw		rt5
	add_nt		GLOB_TMP1, r16, $0
	return_trap	r10, $0
d660 1
d662 2
d666 4
a669 1
 *	Handle virtual memory faults.
d673 2
a674 3
	 * Handle a VM fault.  Note that the type of fault was stored in
	 * rt2 right before we were called so we save it right away in rt1
	 * because rt1 won't get corrupted by the parsing of the instruction.
d676 8
a683 11
	add_nt		rt1, rt2, $0
	/*
	 * Enable all other traps.
	 */
	read_kpsw	rt5
	add_nt		r31, rt5, $0		# 5th arg to MachVMFault is the
						#     kpsw
	or		rt2, rt2, $MACH_ALL_TRAPS_ENA
	wr_kpsw		rt2
	and		rt2, rt5, $MACH_KPSW_PREV_MODE
	cmp_br_delayed	eq, rt2, $0, vmFault_GetDataAddr
d687 6
a692 4
	FETCH_CUR_INSTRUCTION(rt2)
	extract		rt2, rt2, $3		# Opcode <31:25> -> <07:01>
	srl		rt2, rt2, $1		# Opcode <07:01> -> <06:00>
	and		rt2, rt2, $0xf0		# Get upper 4 bits.
d697 1
a697 1
	cmp_br_delayed	gt, rt2, $0x20, vmFault_NoData
d700 3
a702 1
	 * Get the data address.
d704 1
a704 1
	ld_32		r11, r0, $vmFault_GotDataAddrPtr
d710 1
a710 1
	 * We now have the data address in r14.
d712 1
a712 1
	add_nt		r29, r0, $1		# 3rd arg is TRUE to indicate
d714 2
a715 1
	add_nt		r30, r14, $0		# 4th arg is the data addr.
d719 2
a720 4
	add_nt		r29, r0, $0		# 3rd arg is FALSE
						#   (no data addr)
	cmp_br_delayed	always, vmFault_CallHandler
	Nop
d722 5
a726 4
	add_nt		r27, rt1, $0		# 1st arg is fault type.
	add_nt		r28, r10, $0		# 2nd arg is the faulting PC.
	and		rt2, rt5, $MACH_KPSW_PREV_MODE
	cmp_br_delayed	eq, rt2, $0, 1f
d744 2
a745 2
	st_external	rt1, r0, $MACH_FE_STATUS_2|MACH_WR_REG	
	wr_kpsw		rt5
d747 1
d750 1
a750 1
 * Compare trap handler -
d752 2
d756 2
d761 2
a762 2
        and             rt1, r17, $0x1ff        # Get trap number
	cmp_br_delayed	gt, rt1, $MACH_MAX_TRAP_TYPE, cmpTrap_BadTrapType
d764 5
a768 4
	sll		rt1, rt1, $3		# Multiple by 8 to get offset
	rd_special	rt2, pc
	add_nt		rt2, rt1, $16
	jump_reg	rt2, $0
d782 3
a784 3
	rd_kpsw		rt1
	and		rt2, rt1, $MACH_KPSW_PREV_MODE
	cmp_br_delayed	eq, rt2, $0, cmpTrap_KernError
d786 1
a786 10
	VERIFY_SWP(0)
	SAVE_STATE_AND_SWITCH_STACK()
	or		rt2, rt1, $MACH_KPSW_ALL_TRAP_ENA
	write_kpsw	rt2
	add_nt		r11, r0, $MACH_BAD_TRAP_TYPE
	call		_MachUserError$w
	Nop
	RESTORE_STATE()
	jump		ReturnTrap$w
	Nop
d792 2
d797 2
d803 2
d807 5
a811 3
 *	Handle a user error trap.  Before we were called the old r10 (firstPC
 *	at fault time) and r16 (secondPC) were saved in r14 and r15 
 *	respectively and the error type was stored in r13.
d816 3
a818 3
	add_nt		r10, r14, $0
	add_nt		r16, r15, $0
	add_nt		r11, r13, $0
d826 2
d832 2
d838 6
d846 2
a847 2
	rd_special	rt1, pc
	return		rt1, $12
d852 4
a855 4
	 * PCs were saved in r10 and r16.  Restore the stack pointer and
	 * then call the signal return handler with the old hold mask as
	 * an argument.  The signal return handler will check for other signals
	 * pending and return one of the normal ReturnTrap codes.
d857 2
a858 2
	add_nt		r4, rt1, $0
	add_nt		r27, rt2, $0
d867 2
d872 5
a876 1
 *	do has been stored in r11.
d882 1
a882 1
	cmp_br_delayed	eq, r11, $MACH_NORM_RETURN, returnTrap_NormReturn
d884 1
a884 1
	cmp_br_delayed	eq, r11, $MACH_FAILED_COPY, returnTrap_FailedCopy
d886 1
a886 1
	cmp_br_delayed	eq, r11, $MACH_CALL_SIG_HANDLER, returnTrap_CallSigHandler
d888 1
a888 1
	CALL_DEBUGGER_REG(r11)
d894 2
a895 2
	rd_special	rt1, pc
	return		rt1, $12
d901 1
a901 1
	add_nt		r27, r0, $0
d903 2
a904 5
	insert		r27, r0, $2
	or		rt5, rt5, $MACH_ALL_TRAPS_ENA
	and		rt5, rt5 $
	wr_kpsw		rt5
	return		r10, $0
d910 1
a910 1
	 * in r10 and r16.
d917 1
a917 1
	add_nt		rt1, r4, $0
d929 6
a934 6
	ld_32		rt1, r15, $MACH_NEW_FIRST_PC_OFFSET
	ld_32		r4, r15, $MACH_NEW_USER_SP_OFFSET
	add_nt		r10, r0, $SigReturnAddr
	ld_32		r11, r15, $MACH_SIG_NUM_OFFSET
	ld_32		r12, r15, $MACH_SIG_CODE_OFFSET
	ld_32		r13, r15, $MACH_OLD_HOLD_MASK_OFFSET
d940 1
a940 1
	jump_reg	rt2, $0
d945 2
a946 2
	 * Do a return from trap.  If the 2nd PC in r16 is zero then we
	 * don't do the jump to the 2nd PC because there is none.
d948 3
a950 3
	cmp_br_delayed	eq, r16, $0, returnTrap_No2ndPC
	add_nt		GLOB_TMP1, r16, $0
	return_trap	r10, $0
d953 1
a953 1
	return_trap	r10, $0
d962 3
a964 1
 *	jump to when done is passed in r11.
a965 1
 *	RET_ADDR:	r11 -- Address to return to when done.
d972 11
a982 7
 *	TRAP_INST:	r17 -- Trapping instruction.
 *	OPCODE:		r18 -- Opcode.
 *	PARSE_TEMP1:	r19 -- One temporary to use.
 *	PARSE_TEMP2:	r20 -- 2nd temporary to use.
 *	SAVED_R10:	r21 -- Place to save r10.
 *	SAVED_R14:	r22 -- Place to save r14.
 *	SAVED_R15:	r23 -- Place to save r15.
a984 1
#define	RET_ADDR		r11
d991 8
a998 7
#define	TRAP_INST		rt2
#define	OPCODE			rt3
#define	PARSE_TEMP1		rt4
#define	PARSE_TEMP2		rt5
#define	SAVED_R10		rt6
#define	SAVED_R14		rt7
#define	SAVED_R15		rt8
d1173 3
a1175 1
	jump_reg	r21, r0			# Go back to caller
@


1.1
log
@Initial revision
@
text
@d9 1
a9 1
|* rcs = $Header: loMem.s,v 5.6 88/05/05 17:54:35 nelson Exp $ SPRITE (Berkeley)
d16 87
a102 1
 * Temporary registers.  Note that the macros in machAsmDefs.h are allowed
d115 11
d168 9
a176 1
 * Store addresses of things that need to be loaded into registers.
d178 18
d202 3
a204 1
 * Jump table to return the operand from an instruction.
d206 14
d255 12
a266 1
 * Window overflow fault handler.  If in user mode then the swp is validated
d280 21
a300 21
	rd_special	r9, swp
	st_40           r26, r9, $0
	st_40           r11, r9, $8
        st_40           r12, r9, $16
        st_40           r13, r9, $24
        st_40           r14, r9, $32
        st_40           r15, r9, $40
        st_40           r16, r9, $48
        st_40           r17, r9, $56
        st_40           r18, r9, $64
        st_40           r19, r9, $72
        st_40           r20, r9, $80
        st_40           r21, r9, $88
        st_40           r22, r9, $96
        st_40           r23, r9, $104
        st_40           r24, r9, $112
        st_40           r25, r9, $120
	rd_special	r9, cwp
	wr_special	cwp, r9, $-4		# Move back one window.
	rd_special	r9, swp
	wr_special	swp, r9, $128		# swp = swp + 128
d313 2
d316 1
a316 1
	add_nt		rt3, r9, $MACH_PAGE_SIZE
d319 23
a341 2
	jump WinGetPage$w
	add_nt		r9, r9, $128
d344 1
a344 1
	add_nt		r9, r16, r0
d346 1
a346 1
	jump_reg	r9, $0
d361 1
a361 1
        rd_special	r9, swp
d364 19
a382 19
        wr_special      swp, r9, $-128
        ld_40           r10, r9,   $0
        ld_40           r11, r9,   $8
        ld_40           r12, r9,  $16
        ld_40           r13, r9,  $24
        ld_40           r14, r9,  $32
        ld_40           r15, r9,  $40
        ld_40           r16, r9,  $48
        ld_40           r17, r9,  $56
        ld_40           r18, r9,  $64
        ld_40           r19, r9,  $72
        ld_40           r20, r9,  $80
        ld_40           r21, r9,  $88
        ld_40           r22, r9,  $96
        ld_40           r23, r9, $104
        ld_40           r24, r9, $112
        ld_40           r25, r9, $120
        rd_special      r9, cwp
        wr_special      cwp,  r9, $8          # move back ahead two windows
d394 3
a396 1
	rd_special	r9, swp
d398 1
a398 1
	cmp_br_delayed	gt, r9, rt2, winUnFlow_Return
d400 9
a408 2
	jump WinGetPage$w
	add_nt		r9, r9, $-128
d411 1
a411 1
	add_nt		r9, r16, r0
d413 1
a413 1
	jump_reg	r9, $0
d416 2
a417 2
 * FPU Exception handler.  Currently we kill the user process if in user
 * mode or enter the kernel debugger if in kernel mode.
d429 2
a430 2
 * Illegal instruction handler.  Currently we kill the user process if in user
 * mode or enter the kernel debugger if in kernel mode.
d442 2
a443 2
 * Fixnum Exception handler.  Currently we kill the user process if in user
 * mode or enter the kernel debugger if in kernel mode.
d455 2
a456 2
 * Overflow fault handler.  Currently we kill the user process if in user
 * mode or enter the kernel debugger if in kernel mode.
a470 21
/*
 * Call the C routine to get a new saved window stack page wired down.
 * Enable traps and switch to kernel mode before calling the allocator
 * because we will take a window overflow.  r9 is assumed to contain the
 * new swp.
 */
WinGetPage:
	ld_32		rt1, r0, $curStatePtr		# Switch to the
	add_nt		rt2, r4, $0			#   kernel's stack
	ld_32		r4, rt1, $MACH_KERN_STACK_END	#   after saving the
	Nop						#   user sp.
	MOD_KPSW(MACH_KPSW_ALL_TRAPS_ENA, MACH_KPSW_CUR_MODE)
	add_nt		r27, r9, $0
	call		_MachGetWindowPage$w
	Nop
	SET_KPSW(MACH_KPSW_CUR_MODE)
	add_nt		r4, rt2, $0			# Restore the user sp
	add_nt		r9, r16, r0
	return_trap	r10, $0
	jump_reg	r9, $0

d513 4
d545 7
a551 1
	 *	min_swp_offset <= swp <= max_swp_offset + page_size.
d560 1
a560 1
	add_nt		rt2, rt2, $MACH_PAGE_SIZE
d573 1
a573 1
	or		rt1, rt1, $MACH_INTR_TRAP_ENA
d575 1
a575 1
	add_nt		r27, r0, $MACH_USER_BAD_SWP
d599 1
a599 1
	 * Restore saved KPSW and return from trap.
d601 1
d603 1
a603 1
	add_nt		r9, r16, $0
d605 1
a605 1
	jump_reg	r9, $0
d620 1
a620 1
	 * Disable faults but enable all other traps.
d623 2
a624 1
	and		rt2, rt5, $((~MACH_FAULT_TRAP_ENA)&0x3fff)
d632 1
a632 1
	ld_32		rt2, r10, $0		# Fetch instruction.
d669 2
a670 6
	/*
	 * User process so switch to the kernel spill stack.
	 */
	add_nt		rt2, r4, $0
	SWITCH_TO_KERNEL_SPILL_STACK()
	call		MachVMFault$w
d672 1
d674 1
a674 1
	add_nt		r4, rt2, $0
d679 1
a679 1
	call		MachVMFault$w
d682 2
a683 4
	/*
	 * Return from the trap handler which involves clearing the fault
	 * bits in the FE status register, restoring the kpsw and 
	 * then returning.
d687 1
a687 3
	add_nt		r9, r16, $0
	return_trap	r10, $0
	jump_reg	r9, $0
d689 6
d696 35
d732 3
d736 144
d919 1
a919 25

#ifdef BARB
	/*
	 * First, make sure we have the right address.  In barb, the address
	 * may claim to be 0x20000 or so, but we really want the right segment.
	 * if (barb_addr >= 0x20000 && barb_addr < 0x40000000)
	 * barb_addr = barb_addr - 0x20000 + 0x40000000
	 */
	ld_constant(PARSE_TEMP1, 0x20000)
	ld_constant(PARSE_TEMP2, 0x40000000)
	cmp_br_delayed	lt, r10, PARSE_TEMP1, addr_okay_bz
	nop
	cmp_br_delayed  ge, r10, PARSE_TEMP2, addr_okay_bz
	nop
	sub		PARSE_TEMP1, r10, PARSE_TEMP1
	add		PARSE_TEMP1, PARSE_TEMP1, PARSE_TEMP2
	jump		addr_okay$w
	nop
addr_okay_bz:
	add_nt		PARSE_TEMP1, r10, $0
addr_okay:
	ld_32		TRAP_INST, PARSE_TEMP1, $0 # recover trapping instr
#else		
	ld_32		TRAP_INST, r10,   $0	# recover trapping instr
#endif
@
